{"version":3,"file":"apache-arrow-util.6310f9af5345c722b930.js","sources":["webpack:///webpack:///./node_modules/apache-arrow/Arrow.dom.js","webpack:///webpack:///./node_modules/apache-arrow/Arrow.js","webpack:///webpack:///./node_modules/apache-arrow/builder.js","webpack:///webpack:///./node_modules/apache-arrow/builder/binary.js","webpack:///webpack:///./node_modules/apache-arrow/builder/bool.js","webpack:///webpack:///./node_modules/apache-arrow/builder/buffer.js","webpack:///webpack:///./node_modules/apache-arrow/builder/date.js","webpack:///webpack:///./node_modules/apache-arrow/builder/decimal.js","webpack:///webpack:///./node_modules/apache-arrow/builder/dictionary.js","webpack:///webpack:///./node_modules/apache-arrow/builder/fixedsizebinary.js","webpack:///webpack:///./node_modules/apache-arrow/builder/fixedsizelist.js","webpack:///webpack:///./node_modules/apache-arrow/builder/float.js","webpack:///webpack:///./node_modules/apache-arrow/builder/index.js","webpack:///webpack:///./node_modules/apache-arrow/builder/int.js","webpack:///webpack:///./node_modules/apache-arrow/builder/interval.js","webpack:///webpack:///./node_modules/apache-arrow/builder/list.js","webpack:///webpack:///./node_modules/apache-arrow/builder/map.js","webpack:///webpack:///./node_modules/apache-arrow/builder/null.js","webpack:///webpack:///./node_modules/apache-arrow/builder/run.js","webpack:///webpack:///./node_modules/apache-arrow/builder/struct.js","webpack:///webpack:///./node_modules/apache-arrow/builder/time.js","webpack:///webpack:///./node_modules/apache-arrow/builder/timestamp.js","webpack:///webpack:///./node_modules/apache-arrow/builder/union.js","webpack:///webpack:///./node_modules/apache-arrow/builder/utf8.js","webpack:///webpack:///./node_modules/apache-arrow/builder/valid.js","webpack:///webpack:///./node_modules/apache-arrow/column.js","webpack:///webpack:///./node_modules/apache-arrow/compute/dataframe.js","webpack:///webpack:///./node_modules/apache-arrow/compute/predicate.js","webpack:///webpack:///./node_modules/apache-arrow/data.js","webpack:///webpack:///./node_modules/apache-arrow/enum.js","webpack:///webpack:///./node_modules/apache-arrow/fb/File.js","webpack:///webpack:///./node_modules/apache-arrow/fb/Message.js","webpack:///webpack:///./node_modules/apache-arrow/fb/Schema.js","webpack:///webpack:///./node_modules/apache-arrow/io/adapters.js","webpack:///webpack:///./node_modules/apache-arrow/io/file.js","webpack:///webpack:///./node_modules/apache-arrow/io/interfaces.js","webpack:///webpack:///./node_modules/apache-arrow/io/stream.js","webpack:///webpack:///./node_modules/apache-arrow/io/whatwg/builder.js","webpack:///webpack:///./node_modules/apache-arrow/io/whatwg/iterable.js","webpack:///webpack:///./node_modules/apache-arrow/io/whatwg/reader.js","webpack:///webpack:///./node_modules/apache-arrow/io/whatwg/writer.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/message.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/metadata/file.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/metadata/json.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/metadata/message.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/reader.js","webpack:///webpack:///./node_modules/apache-arrow/ipc/writer.js","webpack:///webpack:///./node_modules/apache-arrow/recordbatch.js","webpack:///webpack:///./node_modules/apache-arrow/schema.js","webpack:///webpack:///./node_modules/apache-arrow/table.js","webpack:///webpack:///./node_modules/apache-arrow/type.js","webpack:///webpack:///./node_modules/apache-arrow/util/args.js","webpack:///webpack:///./node_modules/apache-arrow/util/bit.js","webpack:///webpack:///./node_modules/apache-arrow/util/bn.js","webpack:///webpack:///./node_modules/apache-arrow/util/buffer.js","webpack:///webpack:///./node_modules/apache-arrow/util/compat.js","webpack:///webpack:///./node_modules/apache-arrow/util/fn.js","webpack:///webpack:///./node_modules/apache-arrow/util/int.js","webpack:///webpack:///./node_modules/apache-arrow/util/math.js","webpack:///webpack:///./node_modules/apache-arrow/util/pretty.js","webpack:///webpack:///./node_modules/apache-arrow/util/recordbatch.js","webpack:///webpack:///./node_modules/apache-arrow/util/utf8.js","webpack:///webpack:///./node_modules/apache-arrow/util/vector.js","webpack:///webpack:///./node_modules/apache-arrow/vector.js","webpack:///webpack:///./node_modules/apache-arrow/vector/base.js","webpack:///webpack:///./node_modules/apache-arrow/vector/binary.js","webpack:///webpack:///./node_modules/apache-arrow/vector/bool.js","webpack:///webpack:///./node_modules/apache-arrow/vector/chunked.js","webpack:///webpack:///./node_modules/apache-arrow/vector/date.js","webpack:///webpack:///./node_modules/apache-arrow/vector/decimal.js","webpack:///webpack:///./node_modules/apache-arrow/vector/dictionary.js","webpack:///webpack:///./node_modules/apache-arrow/vector/fixedsizebinary.js","webpack:///webpack:///./node_modules/apache-arrow/vector/fixedsizelist.js","webpack:///webpack:///./node_modules/apache-arrow/vector/float.js","webpack:///webpack:///./node_modules/apache-arrow/vector/index.js","webpack:///webpack:///./node_modules/apache-arrow/vector/int.js","webpack:///webpack:///./node_modules/apache-arrow/vector/interval.js","webpack:///webpack:///./node_modules/apache-arrow/vector/list.js","webpack:///webpack:///./node_modules/apache-arrow/vector/map.js","webpack:///webpack:///./node_modules/apache-arrow/vector/null.js","webpack:///webpack:///./node_modules/apache-arrow/vector/row.js","webpack:///webpack:///./node_modules/apache-arrow/vector/struct.js","webpack:///webpack:///./node_modules/apache-arrow/vector/time.js","webpack:///webpack:///./node_modules/apache-arrow/vector/timestamp.js","webpack:///webpack:///./node_modules/apache-arrow/vector/union.js","webpack:///webpack:///./node_modules/apache-arrow/vector/utf8.js","webpack:///webpack:///./node_modules/apache-arrow/visitor.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/builderctor.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/bytewidth.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/get.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/indexof.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/iterator.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/jsontypeassembler.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/jsonvectorassembler.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/set.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/toarray.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/typeassembler.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/typecomparator.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/vectorassembler.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/vectorctor.js","webpack:///webpack:///./node_modules/apache-arrow/visitor/vectorloader.js","webpack:///webpack:///./node_modules/flatbuffers/js/flatbuffers.mjs","webpack:///webpack:///./node_modules/text-encoding-utf-8/lib/encoding.lib.js","webpack:///webpack:///d:/Code/Go/src/github.com/bkzy/grafana/packages/grafana-data/src/dataframe/ArrowDataFrame.ts"],"sourcesContent":["\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst adapters_1 = require(\"./io/adapters\");\nconst index_1 = require(\"./builder/index\");\nconst reader_1 = require(\"./ipc/reader\");\nconst writer_1 = require(\"./ipc/writer\");\nconst iterable_1 = require(\"./io/whatwg/iterable\");\nconst builder_1 = require(\"./io/whatwg/builder\");\nconst reader_2 = require(\"./io/whatwg/reader\");\nconst writer_2 = require(\"./io/whatwg/writer\");\nadapters_1.default.toDOMStream = iterable_1.toDOMStream;\nindex_1.Builder['throughDOM'] = builder_1.builderThroughDOMStream;\nreader_1.RecordBatchReader['throughDOM'] = reader_2.recordBatchReaderThroughDOMStream;\nwriter_1.RecordBatchWriter['throughDOM'] = writer_2.recordBatchWriterThroughDOMStream;\nvar Arrow_1 = require(\"./Arrow\");\nexports.ArrowType = Arrow_1.ArrowType;\nexports.DateUnit = Arrow_1.DateUnit;\nexports.IntervalUnit = Arrow_1.IntervalUnit;\nexports.MessageHeader = Arrow_1.MessageHeader;\nexports.MetadataVersion = Arrow_1.MetadataVersion;\nexports.Precision = Arrow_1.Precision;\nexports.TimeUnit = Arrow_1.TimeUnit;\nexports.Type = Arrow_1.Type;\nexports.UnionMode = Arrow_1.UnionMode;\nexports.BufferType = Arrow_1.BufferType;\nexports.Data = Arrow_1.Data;\nexports.DataType = Arrow_1.DataType;\nexports.Null = Arrow_1.Null;\nexports.Bool = Arrow_1.Bool;\nexports.Int = Arrow_1.Int;\nexports.Int8 = Arrow_1.Int8;\nexports.Int16 = Arrow_1.Int16;\nexports.Int32 = Arrow_1.Int32;\nexports.Int64 = Arrow_1.Int64;\nexports.Uint8 = Arrow_1.Uint8;\nexports.Uint16 = Arrow_1.Uint16;\nexports.Uint32 = Arrow_1.Uint32;\nexports.Uint64 = Arrow_1.Uint64;\nexports.Float = Arrow_1.Float;\nexports.Float16 = Arrow_1.Float16;\nexports.Float32 = Arrow_1.Float32;\nexports.Float64 = Arrow_1.Float64;\nexports.Utf8 = Arrow_1.Utf8;\nexports.Binary = Arrow_1.Binary;\nexports.FixedSizeBinary = Arrow_1.FixedSizeBinary;\nexports.Date_ = Arrow_1.Date_;\nexports.DateDay = Arrow_1.DateDay;\nexports.DateMillisecond = Arrow_1.DateMillisecond;\nexports.Timestamp = Arrow_1.Timestamp;\nexports.TimestampSecond = Arrow_1.TimestampSecond;\nexports.TimestampMillisecond = Arrow_1.TimestampMillisecond;\nexports.TimestampMicrosecond = Arrow_1.TimestampMicrosecond;\nexports.TimestampNanosecond = Arrow_1.TimestampNanosecond;\nexports.Time = Arrow_1.Time;\nexports.TimeSecond = Arrow_1.TimeSecond;\nexports.TimeMillisecond = Arrow_1.TimeMillisecond;\nexports.TimeMicrosecond = Arrow_1.TimeMicrosecond;\nexports.TimeNanosecond = Arrow_1.TimeNanosecond;\nexports.Decimal = Arrow_1.Decimal;\nexports.List = Arrow_1.List;\nexports.Struct = Arrow_1.Struct;\nexports.Union = Arrow_1.Union;\nexports.DenseUnion = Arrow_1.DenseUnion;\nexports.SparseUnion = Arrow_1.SparseUnion;\nexports.Dictionary = Arrow_1.Dictionary;\nexports.Interval = Arrow_1.Interval;\nexports.IntervalDayTime = Arrow_1.IntervalDayTime;\nexports.IntervalYearMonth = Arrow_1.IntervalYearMonth;\nexports.FixedSizeList = Arrow_1.FixedSizeList;\nexports.Map_ = Arrow_1.Map_;\nexports.Table = Arrow_1.Table;\nexports.Column = Arrow_1.Column;\nexports.Schema = Arrow_1.Schema;\nexports.Field = Arrow_1.Field;\nexports.Visitor = Arrow_1.Visitor;\nexports.Vector = Arrow_1.Vector;\nexports.BaseVector = Arrow_1.BaseVector;\nexports.BinaryVector = Arrow_1.BinaryVector;\nexports.BoolVector = Arrow_1.BoolVector;\nexports.Chunked = Arrow_1.Chunked;\nexports.DateVector = Arrow_1.DateVector;\nexports.DateDayVector = Arrow_1.DateDayVector;\nexports.DateMillisecondVector = Arrow_1.DateMillisecondVector;\nexports.DecimalVector = Arrow_1.DecimalVector;\nexports.DictionaryVector = Arrow_1.DictionaryVector;\nexports.FixedSizeBinaryVector = Arrow_1.FixedSizeBinaryVector;\nexports.FixedSizeListVector = Arrow_1.FixedSizeListVector;\nexports.FloatVector = Arrow_1.FloatVector;\nexports.Float16Vector = Arrow_1.Float16Vector;\nexports.Float32Vector = Arrow_1.Float32Vector;\nexports.Float64Vector = Arrow_1.Float64Vector;\nexports.IntervalVector = Arrow_1.IntervalVector;\nexports.IntervalDayTimeVector = Arrow_1.IntervalDayTimeVector;\nexports.IntervalYearMonthVector = Arrow_1.IntervalYearMonthVector;\nexports.IntVector = Arrow_1.IntVector;\nexports.Int8Vector = Arrow_1.Int8Vector;\nexports.Int16Vector = Arrow_1.Int16Vector;\nexports.Int32Vector = Arrow_1.Int32Vector;\nexports.Int64Vector = Arrow_1.Int64Vector;\nexports.Uint8Vector = Arrow_1.Uint8Vector;\nexports.Uint16Vector = Arrow_1.Uint16Vector;\nexports.Uint32Vector = Arrow_1.Uint32Vector;\nexports.Uint64Vector = Arrow_1.Uint64Vector;\nexports.ListVector = Arrow_1.ListVector;\nexports.MapVector = Arrow_1.MapVector;\nexports.NullVector = Arrow_1.NullVector;\nexports.StructVector = Arrow_1.StructVector;\nexports.TimestampVector = Arrow_1.TimestampVector;\nexports.TimestampSecondVector = Arrow_1.TimestampSecondVector;\nexports.TimestampMillisecondVector = Arrow_1.TimestampMillisecondVector;\nexports.TimestampMicrosecondVector = Arrow_1.TimestampMicrosecondVector;\nexports.TimestampNanosecondVector = Arrow_1.TimestampNanosecondVector;\nexports.TimeVector = Arrow_1.TimeVector;\nexports.TimeSecondVector = Arrow_1.TimeSecondVector;\nexports.TimeMillisecondVector = Arrow_1.TimeMillisecondVector;\nexports.TimeMicrosecondVector = Arrow_1.TimeMicrosecondVector;\nexports.TimeNanosecondVector = Arrow_1.TimeNanosecondVector;\nexports.UnionVector = Arrow_1.UnionVector;\nexports.DenseUnionVector = Arrow_1.DenseUnionVector;\nexports.SparseUnionVector = Arrow_1.SparseUnionVector;\nexports.Utf8Vector = Arrow_1.Utf8Vector;\nexports.ByteStream = Arrow_1.ByteStream;\nexports.AsyncByteStream = Arrow_1.AsyncByteStream;\nexports.AsyncByteQueue = Arrow_1.AsyncByteQueue;\nexports.RecordBatchReader = Arrow_1.RecordBatchReader;\nexports.RecordBatchFileReader = Arrow_1.RecordBatchFileReader;\nexports.RecordBatchStreamReader = Arrow_1.RecordBatchStreamReader;\nexports.AsyncRecordBatchFileReader = Arrow_1.AsyncRecordBatchFileReader;\nexports.AsyncRecordBatchStreamReader = Arrow_1.AsyncRecordBatchStreamReader;\nexports.RecordBatchWriter = Arrow_1.RecordBatchWriter;\nexports.RecordBatchFileWriter = Arrow_1.RecordBatchFileWriter;\nexports.RecordBatchStreamWriter = Arrow_1.RecordBatchStreamWriter;\nexports.RecordBatchJSONWriter = Arrow_1.RecordBatchJSONWriter;\nexports.MessageReader = Arrow_1.MessageReader;\nexports.AsyncMessageReader = Arrow_1.AsyncMessageReader;\nexports.JSONMessageReader = Arrow_1.JSONMessageReader;\nexports.Message = Arrow_1.Message;\nexports.RecordBatch = Arrow_1.RecordBatch;\nexports.DataFrame = Arrow_1.DataFrame;\nexports.FilteredDataFrame = Arrow_1.FilteredDataFrame;\nexports.CountByResult = Arrow_1.CountByResult;\nexports.predicate = Arrow_1.predicate;\nexports.util = Arrow_1.util;\nexports.Builder = Arrow_1.Builder;\nexports.BinaryBuilder = Arrow_1.BinaryBuilder;\nexports.BoolBuilder = Arrow_1.BoolBuilder;\nexports.DateBuilder = Arrow_1.DateBuilder;\nexports.DateDayBuilder = Arrow_1.DateDayBuilder;\nexports.DateMillisecondBuilder = Arrow_1.DateMillisecondBuilder;\nexports.DecimalBuilder = Arrow_1.DecimalBuilder;\nexports.DictionaryBuilder = Arrow_1.DictionaryBuilder;\nexports.FixedSizeBinaryBuilder = Arrow_1.FixedSizeBinaryBuilder;\nexports.FixedSizeListBuilder = Arrow_1.FixedSizeListBuilder;\nexports.FloatBuilder = Arrow_1.FloatBuilder;\nexports.Float16Builder = Arrow_1.Float16Builder;\nexports.Float32Builder = Arrow_1.Float32Builder;\nexports.Float64Builder = Arrow_1.Float64Builder;\nexports.IntervalBuilder = Arrow_1.IntervalBuilder;\nexports.IntervalDayTimeBuilder = Arrow_1.IntervalDayTimeBuilder;\nexports.IntervalYearMonthBuilder = Arrow_1.IntervalYearMonthBuilder;\nexports.IntBuilder = Arrow_1.IntBuilder;\nexports.Int8Builder = Arrow_1.Int8Builder;\nexports.Int16Builder = Arrow_1.Int16Builder;\nexports.Int32Builder = Arrow_1.Int32Builder;\nexports.Int64Builder = Arrow_1.Int64Builder;\nexports.Uint8Builder = Arrow_1.Uint8Builder;\nexports.Uint16Builder = Arrow_1.Uint16Builder;\nexports.Uint32Builder = Arrow_1.Uint32Builder;\nexports.Uint64Builder = Arrow_1.Uint64Builder;\nexports.ListBuilder = Arrow_1.ListBuilder;\nexports.MapBuilder = Arrow_1.MapBuilder;\nexports.NullBuilder = Arrow_1.NullBuilder;\nexports.StructBuilder = Arrow_1.StructBuilder;\nexports.TimestampBuilder = Arrow_1.TimestampBuilder;\nexports.TimestampSecondBuilder = Arrow_1.TimestampSecondBuilder;\nexports.TimestampMillisecondBuilder = Arrow_1.TimestampMillisecondBuilder;\nexports.TimestampMicrosecondBuilder = Arrow_1.TimestampMicrosecondBuilder;\nexports.TimestampNanosecondBuilder = Arrow_1.TimestampNanosecondBuilder;\nexports.TimeBuilder = Arrow_1.TimeBuilder;\nexports.TimeSecondBuilder = Arrow_1.TimeSecondBuilder;\nexports.TimeMillisecondBuilder = Arrow_1.TimeMillisecondBuilder;\nexports.TimeMicrosecondBuilder = Arrow_1.TimeMicrosecondBuilder;\nexports.TimeNanosecondBuilder = Arrow_1.TimeNanosecondBuilder;\nexports.UnionBuilder = Arrow_1.UnionBuilder;\nexports.DenseUnionBuilder = Arrow_1.DenseUnionBuilder;\nexports.SparseUnionBuilder = Arrow_1.SparseUnionBuilder;\nexports.Utf8Builder = Arrow_1.Utf8Builder;\n\n//# sourceMappingURL=Arrow.dom.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar enum_1 = require(\"./enum\");\nexports.ArrowType = enum_1.ArrowType;\nexports.DateUnit = enum_1.DateUnit;\nexports.IntervalUnit = enum_1.IntervalUnit;\nexports.MessageHeader = enum_1.MessageHeader;\nexports.MetadataVersion = enum_1.MetadataVersion;\nexports.Precision = enum_1.Precision;\nexports.TimeUnit = enum_1.TimeUnit;\nexports.Type = enum_1.Type;\nexports.UnionMode = enum_1.UnionMode;\nexports.BufferType = enum_1.BufferType;\nvar data_1 = require(\"./data\");\nexports.Data = data_1.Data;\nvar type_1 = require(\"./type\");\nexports.DataType = type_1.DataType;\nexports.Null = type_1.Null;\nexports.Bool = type_1.Bool;\nexports.Int = type_1.Int;\nexports.Int8 = type_1.Int8;\nexports.Int16 = type_1.Int16;\nexports.Int32 = type_1.Int32;\nexports.Int64 = type_1.Int64;\nexports.Uint8 = type_1.Uint8;\nexports.Uint16 = type_1.Uint16;\nexports.Uint32 = type_1.Uint32;\nexports.Uint64 = type_1.Uint64;\nexports.Float = type_1.Float;\nexports.Float16 = type_1.Float16;\nexports.Float32 = type_1.Float32;\nexports.Float64 = type_1.Float64;\nexports.Utf8 = type_1.Utf8;\nexports.Binary = type_1.Binary;\nexports.FixedSizeBinary = type_1.FixedSizeBinary;\nexports.Date_ = type_1.Date_;\nexports.DateDay = type_1.DateDay;\nexports.DateMillisecond = type_1.DateMillisecond;\nexports.Timestamp = type_1.Timestamp;\nexports.TimestampSecond = type_1.TimestampSecond;\nexports.TimestampMillisecond = type_1.TimestampMillisecond;\nexports.TimestampMicrosecond = type_1.TimestampMicrosecond;\nexports.TimestampNanosecond = type_1.TimestampNanosecond;\nexports.Time = type_1.Time;\nexports.TimeSecond = type_1.TimeSecond;\nexports.TimeMillisecond = type_1.TimeMillisecond;\nexports.TimeMicrosecond = type_1.TimeMicrosecond;\nexports.TimeNanosecond = type_1.TimeNanosecond;\nexports.Decimal = type_1.Decimal;\nexports.List = type_1.List;\nexports.Struct = type_1.Struct;\nexports.Union = type_1.Union;\nexports.DenseUnion = type_1.DenseUnion;\nexports.SparseUnion = type_1.SparseUnion;\nexports.Dictionary = type_1.Dictionary;\nexports.Interval = type_1.Interval;\nexports.IntervalDayTime = type_1.IntervalDayTime;\nexports.IntervalYearMonth = type_1.IntervalYearMonth;\nexports.FixedSizeList = type_1.FixedSizeList;\nexports.Map_ = type_1.Map_;\nvar table_1 = require(\"./table\");\nexports.Table = table_1.Table;\nvar column_1 = require(\"./column\");\nexports.Column = column_1.Column;\nvar visitor_1 = require(\"./visitor\");\nexports.Visitor = visitor_1.Visitor;\nvar schema_1 = require(\"./schema\");\nexports.Schema = schema_1.Schema;\nexports.Field = schema_1.Field;\nvar index_1 = require(\"./vector/index\");\nexports.Vector = index_1.Vector;\nexports.BaseVector = index_1.BaseVector;\nexports.BinaryVector = index_1.BinaryVector;\nexports.BoolVector = index_1.BoolVector;\nexports.Chunked = index_1.Chunked;\nexports.DateVector = index_1.DateVector;\nexports.DateDayVector = index_1.DateDayVector;\nexports.DateMillisecondVector = index_1.DateMillisecondVector;\nexports.DecimalVector = index_1.DecimalVector;\nexports.DictionaryVector = index_1.DictionaryVector;\nexports.FixedSizeBinaryVector = index_1.FixedSizeBinaryVector;\nexports.FixedSizeListVector = index_1.FixedSizeListVector;\nexports.FloatVector = index_1.FloatVector;\nexports.Float16Vector = index_1.Float16Vector;\nexports.Float32Vector = index_1.Float32Vector;\nexports.Float64Vector = index_1.Float64Vector;\nexports.IntervalVector = index_1.IntervalVector;\nexports.IntervalDayTimeVector = index_1.IntervalDayTimeVector;\nexports.IntervalYearMonthVector = index_1.IntervalYearMonthVector;\nexports.IntVector = index_1.IntVector;\nexports.Int8Vector = index_1.Int8Vector;\nexports.Int16Vector = index_1.Int16Vector;\nexports.Int32Vector = index_1.Int32Vector;\nexports.Int64Vector = index_1.Int64Vector;\nexports.Uint8Vector = index_1.Uint8Vector;\nexports.Uint16Vector = index_1.Uint16Vector;\nexports.Uint32Vector = index_1.Uint32Vector;\nexports.Uint64Vector = index_1.Uint64Vector;\nexports.ListVector = index_1.ListVector;\nexports.MapVector = index_1.MapVector;\nexports.NullVector = index_1.NullVector;\nexports.StructVector = index_1.StructVector;\nexports.TimestampVector = index_1.TimestampVector;\nexports.TimestampSecondVector = index_1.TimestampSecondVector;\nexports.TimestampMillisecondVector = index_1.TimestampMillisecondVector;\nexports.TimestampMicrosecondVector = index_1.TimestampMicrosecondVector;\nexports.TimestampNanosecondVector = index_1.TimestampNanosecondVector;\nexports.TimeVector = index_1.TimeVector;\nexports.TimeSecondVector = index_1.TimeSecondVector;\nexports.TimeMillisecondVector = index_1.TimeMillisecondVector;\nexports.TimeMicrosecondVector = index_1.TimeMicrosecondVector;\nexports.TimeNanosecondVector = index_1.TimeNanosecondVector;\nexports.UnionVector = index_1.UnionVector;\nexports.DenseUnionVector = index_1.DenseUnionVector;\nexports.SparseUnionVector = index_1.SparseUnionVector;\nexports.Utf8Vector = index_1.Utf8Vector;\nvar index_2 = require(\"./builder/index\");\nexports.Builder = index_2.Builder;\nexports.BinaryBuilder = index_2.BinaryBuilder;\nexports.BoolBuilder = index_2.BoolBuilder;\nexports.DateBuilder = index_2.DateBuilder;\nexports.DateDayBuilder = index_2.DateDayBuilder;\nexports.DateMillisecondBuilder = index_2.DateMillisecondBuilder;\nexports.DecimalBuilder = index_2.DecimalBuilder;\nexports.DictionaryBuilder = index_2.DictionaryBuilder;\nexports.FixedSizeBinaryBuilder = index_2.FixedSizeBinaryBuilder;\nexports.FixedSizeListBuilder = index_2.FixedSizeListBuilder;\nexports.FloatBuilder = index_2.FloatBuilder;\nexports.Float16Builder = index_2.Float16Builder;\nexports.Float32Builder = index_2.Float32Builder;\nexports.Float64Builder = index_2.Float64Builder;\nexports.IntervalBuilder = index_2.IntervalBuilder;\nexports.IntervalDayTimeBuilder = index_2.IntervalDayTimeBuilder;\nexports.IntervalYearMonthBuilder = index_2.IntervalYearMonthBuilder;\nexports.IntBuilder = index_2.IntBuilder;\nexports.Int8Builder = index_2.Int8Builder;\nexports.Int16Builder = index_2.Int16Builder;\nexports.Int32Builder = index_2.Int32Builder;\nexports.Int64Builder = index_2.Int64Builder;\nexports.Uint8Builder = index_2.Uint8Builder;\nexports.Uint16Builder = index_2.Uint16Builder;\nexports.Uint32Builder = index_2.Uint32Builder;\nexports.Uint64Builder = index_2.Uint64Builder;\nexports.ListBuilder = index_2.ListBuilder;\nexports.MapBuilder = index_2.MapBuilder;\nexports.NullBuilder = index_2.NullBuilder;\nexports.StructBuilder = index_2.StructBuilder;\nexports.TimestampBuilder = index_2.TimestampBuilder;\nexports.TimestampSecondBuilder = index_2.TimestampSecondBuilder;\nexports.TimestampMillisecondBuilder = index_2.TimestampMillisecondBuilder;\nexports.TimestampMicrosecondBuilder = index_2.TimestampMicrosecondBuilder;\nexports.TimestampNanosecondBuilder = index_2.TimestampNanosecondBuilder;\nexports.TimeBuilder = index_2.TimeBuilder;\nexports.TimeSecondBuilder = index_2.TimeSecondBuilder;\nexports.TimeMillisecondBuilder = index_2.TimeMillisecondBuilder;\nexports.TimeMicrosecondBuilder = index_2.TimeMicrosecondBuilder;\nexports.TimeNanosecondBuilder = index_2.TimeNanosecondBuilder;\nexports.UnionBuilder = index_2.UnionBuilder;\nexports.DenseUnionBuilder = index_2.DenseUnionBuilder;\nexports.SparseUnionBuilder = index_2.SparseUnionBuilder;\nexports.Utf8Builder = index_2.Utf8Builder;\nvar stream_1 = require(\"./io/stream\");\nexports.ByteStream = stream_1.ByteStream;\nexports.AsyncByteStream = stream_1.AsyncByteStream;\nexports.AsyncByteQueue = stream_1.AsyncByteQueue;\nvar reader_1 = require(\"./ipc/reader\");\nexports.RecordBatchReader = reader_1.RecordBatchReader;\nexports.RecordBatchFileReader = reader_1.RecordBatchFileReader;\nexports.RecordBatchStreamReader = reader_1.RecordBatchStreamReader;\nexports.AsyncRecordBatchFileReader = reader_1.AsyncRecordBatchFileReader;\nexports.AsyncRecordBatchStreamReader = reader_1.AsyncRecordBatchStreamReader;\nvar writer_1 = require(\"./ipc/writer\");\nexports.RecordBatchWriter = writer_1.RecordBatchWriter;\nexports.RecordBatchFileWriter = writer_1.RecordBatchFileWriter;\nexports.RecordBatchStreamWriter = writer_1.RecordBatchStreamWriter;\nexports.RecordBatchJSONWriter = writer_1.RecordBatchJSONWriter;\nvar message_1 = require(\"./ipc/message\");\nexports.MessageReader = message_1.MessageReader;\nexports.AsyncMessageReader = message_1.AsyncMessageReader;\nexports.JSONMessageReader = message_1.JSONMessageReader;\nvar message_2 = require(\"./ipc/metadata/message\");\nexports.Message = message_2.Message;\nvar recordbatch_1 = require(\"./recordbatch\");\nexports.RecordBatch = recordbatch_1.RecordBatch;\nvar dataframe_1 = require(\"./compute/dataframe\");\nexports.DataFrame = dataframe_1.DataFrame;\nexports.FilteredDataFrame = dataframe_1.FilteredDataFrame;\nexports.CountByResult = dataframe_1.CountByResult;\nconst util_bn_ = require(\"./util/bn\");\nconst util_int_ = require(\"./util/int\");\nconst util_bit_ = require(\"./util/bit\");\nconst util_math_ = require(\"./util/math\");\nconst util_buffer_ = require(\"./util/buffer\");\nconst util_vector_ = require(\"./util/vector\");\nconst predicate = require(\"./compute/predicate\");\nexports.predicate = predicate;\n/** @ignore */\nexports.util = {\n    ...util_bn_,\n    ...util_int_,\n    ...util_bit_,\n    ...util_math_,\n    ...util_buffer_,\n    ...util_vector_\n};\n\n//# sourceMappingURL=Arrow.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"./vector\");\nconst enum_1 = require(\"./enum\");\nconst data_1 = require(\"./data\");\nconst valid_1 = require(\"./builder/valid\");\nconst buffer_1 = require(\"./builder/buffer\");\nconst type_1 = require(\"./type\");\n/**\n * An abstract base class for types that construct Arrow Vectors from arbitrary JavaScript values.\n *\n * A `Builder` is responsible for writing arbitrary JavaScript values\n * to ArrayBuffers and/or child Builders according to the Arrow specification\n * for each DataType, creating or resizing the underlying ArrayBuffers as necessary.\n *\n * The `Builder` for each Arrow `DataType` handles converting and appending\n * values for a given `DataType`. The high-level {@link Builder.new `Builder.new()`} convenience\n * method creates the specific `Builder` subclass for the supplied `DataType`.\n *\n * Once created, `Builder` instances support both appending values to the end\n * of the `Builder`, and random-access writes to specific indices\n * (`Builder.prototype.append(value)` is a convenience method for\n * `builder.set(builder.length, value)`). Appending or setting values beyond the\n * Builder's current length may cause the builder to grow its underlying buffers\n * or child Builders (if applicable) to accommodate the new values.\n *\n * After enough values have been written to a `Builder`, `Builder.prototype.flush()`\n * will commit the values to the underlying ArrayBuffers (or child Builders). The\n * internal Builder state will be reset, and an instance of `Data<T>` is returned.\n * Alternatively, `Builder.prototype.toVector()` will flush the `Builder` and return\n * an instance of `Vector<T>` instead.\n *\n * When there are no more values to write, use `Builder.prototype.finish()` to\n * finalize the `Builder`. This does not reset the internal state, so it is\n * necessary to call `Builder.prototype.flush()` or `toVector()` one last time\n * if there are still values queued to be flushed.\n *\n * Note: calling `Builder.prototype.finish()` is required when using a `DictionaryBuilder`,\n * because this is when it flushes the values that have been enqueued in its internal\n * dictionary's `Builder`, and creates the `dictionaryVector` for the `Dictionary` `DataType`.\n *\n * ```ts\n * import { Builder, Utf8 } from 'apache-arrow';\n *\n * const utf8Builder = Builder.new({\n *     type: new Utf8(),\n *     nullValues: [null, 'n/a']\n * });\n *\n * utf8Builder\n *     .append('hello')\n *     .append('n/a')\n *     .append('world')\n *     .append(null);\n *\n * const utf8Vector = utf8Builder.finish().toVector();\n *\n * console.log(utf8Vector.toJSON());\n * // > [\"hello\", null, \"world\", null]\n * ```\n *\n * @typeparam T The `DataType` of this `Builder`.\n * @typeparam TNull The type(s) of values which will be considered null-value sentinels.\n */\nclass Builder {\n    /**\n     * Construct a builder with the given Arrow DataType with optional null values,\n     * which will be interpreted as \"null\" when set or appended to the `Builder`.\n     * @param {{ type: T, nullValues?: any[] }} options A `BuilderOptions` object used to create this `Builder`.\n     */\n    constructor({ 'type': type, 'nullValues': nulls }) {\n        /**\n         * The number of values written to the `Builder` that haven't been flushed yet.\n         * @readonly\n         */\n        this.length = 0;\n        /**\n         * A boolean indicating whether `Builder.prototype.finish()` has been called on this `Builder`.\n         * @readonly\n         */\n        this.finished = false;\n        this.type = type;\n        this.children = [];\n        this.nullValues = nulls;\n        this.stride = type_1.strideForType(type);\n        this._nulls = new buffer_1.BitmapBufferBuilder();\n        if (nulls && nulls.length > 0) {\n            this._isValid = valid_1.createIsValidFunction(nulls);\n        }\n    }\n    /**\n     * Create a `Builder` instance based on the `type` property of the supplied `options` object.\n     * @param {BuilderOptions<T, TNull>} options An object with a required `DataType` instance\n     * and other optional parameters to be passed to the `Builder` subclass for the given `type`.\n     *\n     * @typeparam T The `DataType` of the `Builder` to create.\n     * @typeparam TNull The type(s) of values which will be considered null-value sentinels.\n     * @nocollapse\n     */\n    // @ts-ignore\n    static new(options) { }\n    /** @nocollapse */\n    // @ts-ignore\n    static throughNode(options) {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    // @ts-ignore\n    static throughDOM(options) {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n    /**\n     * Transform a synchronous `Iterable` of arbitrary JavaScript values into a\n     * sequence of Arrow Vector<T> following the chunking semantics defined in\n     * the supplied `options` argument.\n     *\n     * This function returns a function that accepts an `Iterable` of values to\n     * transform. When called, this function returns an Iterator of `Vector<T>`.\n     *\n     * The resulting `Iterator<Vector<T>>` yields Vectors based on the\n     * `queueingStrategy` and `highWaterMark` specified in the `options` argument.\n     *\n     * * If `queueingStrategy` is `\"count\"` (or omitted), The `Iterator<Vector<T>>`\n     *   will flush the underlying `Builder` (and yield a new `Vector<T>`) once the\n     *   Builder's `length` reaches or exceeds the supplied `highWaterMark`.\n     * * If `queueingStrategy` is `\"bytes\"`, the `Iterator<Vector<T>>` will flush\n     *   the underlying `Builder` (and yield a new `Vector<T>`) once its `byteLength`\n     *   reaches or exceeds the supplied `highWaterMark`.\n     *\n     * @param {IterableBuilderOptions<T, TNull>} options An object of properties which determine the `Builder` to create and the chunking semantics to use.\n     * @returns A function which accepts a JavaScript `Iterable` of values to\n     *          write, and returns an `Iterator` that yields Vectors according\n     *          to the chunking semantics defined in the `options` argument.\n     * @nocollapse\n     */\n    static throughIterable(options) {\n        return throughIterable(options);\n    }\n    /**\n     * Transform an `AsyncIterable` of arbitrary JavaScript values into a\n     * sequence of Arrow Vector<T> following the chunking semantics defined in\n     * the supplied `options` argument.\n     *\n     * This function returns a function that accepts an `AsyncIterable` of values to\n     * transform. When called, this function returns an AsyncIterator of `Vector<T>`.\n     *\n     * The resulting `AsyncIterator<Vector<T>>` yields Vectors based on the\n     * `queueingStrategy` and `highWaterMark` specified in the `options` argument.\n     *\n     * * If `queueingStrategy` is `\"count\"` (or omitted), The `AsyncIterator<Vector<T>>`\n     *   will flush the underlying `Builder` (and yield a new `Vector<T>`) once the\n     *   Builder's `length` reaches or exceeds the supplied `highWaterMark`.\n     * * If `queueingStrategy` is `\"bytes\"`, the `AsyncIterator<Vector<T>>` will flush\n     *   the underlying `Builder` (and yield a new `Vector<T>`) once its `byteLength`\n     *   reaches or exceeds the supplied `highWaterMark`.\n     *\n     * @param {IterableBuilderOptions<T, TNull>} options An object of properties which determine the `Builder` to create and the chunking semantics to use.\n     * @returns A function which accepts a JavaScript `AsyncIterable` of values\n     *          to write, and returns an `AsyncIterator` that yields Vectors\n     *          according to the chunking semantics defined in the `options`\n     *          argument.\n     * @nocollapse\n     */\n    static throughAsyncIterable(options) {\n        return throughAsyncIterable(options);\n    }\n    /**\n     * Flush the `Builder` and return a `Vector<T>`.\n     * @returns {Vector<T>} A `Vector<T>` of the flushed values.\n     */\n    toVector() { return vector_1.Vector.new(this.flush()); }\n    get ArrayType() { return this.type.ArrayType; }\n    get nullCount() { return this._nulls.numInvalid; }\n    get numChildren() { return this.children.length; }\n    /**\n     * @returns The aggregate length (in bytes) of the values that have been written.\n     */\n    get byteLength() {\n        let size = 0;\n        this._offsets && (size += this._offsets.byteLength);\n        this._values && (size += this._values.byteLength);\n        this._nulls && (size += this._nulls.byteLength);\n        this._typeIds && (size += this._typeIds.byteLength);\n        return this.children.reduce((size, child) => size + child.byteLength, size);\n    }\n    /**\n     * @returns The aggregate number of rows that have been reserved to write new values.\n     */\n    get reservedLength() {\n        return this._nulls.reservedLength;\n    }\n    /**\n     * @returns The aggregate length (in bytes) that has been reserved to write new values.\n     */\n    get reservedByteLength() {\n        let size = 0;\n        this._offsets && (size += this._offsets.reservedByteLength);\n        this._values && (size += this._values.reservedByteLength);\n        this._nulls && (size += this._nulls.reservedByteLength);\n        this._typeIds && (size += this._typeIds.reservedByteLength);\n        return this.children.reduce((size, child) => size + child.reservedByteLength, size);\n    }\n    get valueOffsets() { return this._offsets ? this._offsets.buffer : null; }\n    get values() { return this._values ? this._values.buffer : null; }\n    get nullBitmap() { return this._nulls ? this._nulls.buffer : null; }\n    get typeIds() { return this._typeIds ? this._typeIds.buffer : null; }\n    /**\n     * Appends a value (or null) to this `Builder`.\n     * This is equivalent to `builder.set(builder.length, value)`.\n     * @param {T['TValue'] | TNull } value The value to append.\n     */\n    append(value) { return this.set(this.length, value); }\n    /**\n     * Validates whether a value is valid (true), or null (false)\n     * @param {T['TValue'] | TNull } value The value to compare against null the value representations\n     */\n    // @ts-ignore\n    isValid(value) { return this._isValid(value); }\n    /**\n     * Write a value (or null-value sentinel) at the supplied index.\n     * If the value matches one of the null-value representations, a 1-bit is\n     * written to the null `BitmapBufferBuilder`. Otherwise, a 0 is written to\n     * the null `BitmapBufferBuilder`, and the value is passed to\n     * `Builder.prototype.setValue()`.\n     * @param {number} index The index of the value to write.\n     * @param {T['TValue'] | TNull } value The value to write at the supplied index.\n     * @returns {this} The updated `Builder` instance.\n     */\n    set(index, value) {\n        if (this.setValid(index, this.isValid(value))) {\n            this.setValue(index, value);\n        }\n        return this;\n    }\n    /**\n     * Write a value to the underlying buffers at the supplied index, bypassing\n     * the null-value check. This is a low-level method that\n     * @param {number} index\n     * @param {T['TValue'] | TNull } value\n     */\n    // @ts-ignore\n    setValue(index, value) { this._setValue(this, index, value); }\n    setValid(index, valid) {\n        this.length = this._nulls.set(index, +valid).length;\n        return valid;\n    }\n    // @ts-ignore\n    addChild(child, name = `${this.numChildren}`) {\n        throw new Error(`Cannot append children to non-nested type \"${this.type}\"`);\n    }\n    /**\n     * Retrieve the child `Builder` at the supplied `index`, or null if no child\n     * exists at that index.\n     * @param {number} index The index of the child `Builder` to retrieve.\n     * @returns {Builder | null} The child Builder at the supplied index or null.\n     */\n    getChildAt(index) {\n        return this.children[index] || null;\n    }\n    /**\n     * Commit all the values that have been written to their underlying\n     * ArrayBuffers, including any child Builders if applicable, and reset\n     * the internal `Builder` state.\n     * @returns A `Data<T>` of the buffers and childData representing the values written.\n     */\n    flush() {\n        const buffers = [];\n        const values = this._values;\n        const offsets = this._offsets;\n        const typeIds = this._typeIds;\n        const { length, nullCount } = this;\n        if (typeIds) { /* Unions */\n            buffers[enum_1.BufferType.TYPE] = typeIds.flush(length);\n            // DenseUnions\n            offsets && (buffers[enum_1.BufferType.OFFSET] = offsets.flush(length));\n        }\n        else if (offsets) { /* Variable-width primitives (Binary, Utf8) and Lists */\n            // Binary, Utf8\n            values && (buffers[enum_1.BufferType.DATA] = values.flush(offsets.last()));\n            buffers[enum_1.BufferType.OFFSET] = offsets.flush(length);\n        }\n        else if (values) { /* Fixed-width primitives (Int, Float, Decimal, Time, Timestamp, and Interval) */\n            buffers[enum_1.BufferType.DATA] = values.flush(length);\n        }\n        nullCount > 0 && (buffers[enum_1.BufferType.VALIDITY] = this._nulls.flush(length));\n        const data = data_1.Data.new(this.type, 0, length, nullCount, buffers, this.children.map((child) => child.flush()));\n        this.clear();\n        return data;\n    }\n    /**\n     * Finalize this `Builder`, and child builders if applicable.\n     * @returns {this} The finalized `Builder` instance.\n     */\n    finish() {\n        this.finished = true;\n        this.children.forEach((child) => child.finish());\n        return this;\n    }\n    /**\n     * Clear this Builder's internal state, including child Builders if applicable, and reset the length to 0.\n     * @returns {this} The cleared `Builder` instance.\n     */\n    clear() {\n        this.length = 0;\n        this._offsets && (this._offsets.clear());\n        this._values && (this._values.clear());\n        this._nulls && (this._nulls.clear());\n        this._typeIds && (this._typeIds.clear());\n        this.children.forEach((child) => child.clear());\n        return this;\n    }\n}\nexports.Builder = Builder;\nBuilder.prototype.length = 1;\nBuilder.prototype.stride = 1;\nBuilder.prototype.children = null;\nBuilder.prototype.finished = false;\nBuilder.prototype.nullValues = null;\nBuilder.prototype._isValid = () => true;\n/** @ignore */\nclass FixedWidthBuilder extends Builder {\n    constructor(opts) {\n        super(opts);\n        this._values = new buffer_1.DataBufferBuilder(new this.ArrayType(0), this.stride);\n    }\n    setValue(index, value) {\n        const values = this._values;\n        values.reserve(index - values.length + 1);\n        return super.setValue(index, value);\n    }\n}\nexports.FixedWidthBuilder = FixedWidthBuilder;\n/** @ignore */\nclass VariableWidthBuilder extends Builder {\n    constructor(opts) {\n        super(opts);\n        this._pendingLength = 0;\n        this._offsets = new buffer_1.OffsetsBufferBuilder();\n    }\n    setValue(index, value) {\n        const pending = this._pending || (this._pending = new Map());\n        const current = pending.get(index);\n        current && (this._pendingLength -= current.length);\n        this._pendingLength += value.length;\n        pending.set(index, value);\n    }\n    setValid(index, isValid) {\n        if (!super.setValid(index, isValid)) {\n            (this._pending || (this._pending = new Map())).set(index, undefined);\n            return false;\n        }\n        return true;\n    }\n    clear() {\n        this._pendingLength = 0;\n        this._pending = undefined;\n        return super.clear();\n    }\n    flush() {\n        this._flush();\n        return super.flush();\n    }\n    finish() {\n        this._flush();\n        return super.finish();\n    }\n    _flush() {\n        const pending = this._pending;\n        const pendingLength = this._pendingLength;\n        this._pendingLength = 0;\n        this._pending = undefined;\n        if (pending && pending.size > 0) {\n            this._flushPending(pending, pendingLength);\n        }\n        return this;\n    }\n}\nexports.VariableWidthBuilder = VariableWidthBuilder;\n/** @ignore */\nfunction throughIterable(options) {\n    const { ['queueingStrategy']: queueingStrategy = 'count' } = options;\n    const { ['highWaterMark']: highWaterMark = queueingStrategy !== 'bytes' ? 1000 : 2 ** 14 } = options;\n    const sizeProperty = queueingStrategy !== 'bytes' ? 'length' : 'byteLength';\n    return function* (source) {\n        let numChunks = 0;\n        let builder = Builder.new(options);\n        for (const value of source) {\n            if (builder.append(value)[sizeProperty] >= highWaterMark) {\n                ++numChunks && (yield builder.toVector());\n            }\n        }\n        if (builder.finish().length > 0 || numChunks === 0) {\n            yield builder.toVector();\n        }\n    };\n}\n/** @ignore */\nfunction throughAsyncIterable(options) {\n    const { ['queueingStrategy']: queueingStrategy = 'count' } = options;\n    const { ['highWaterMark']: highWaterMark = queueingStrategy !== 'bytes' ? 1000 : 2 ** 14 } = options;\n    const sizeProperty = queueingStrategy !== 'bytes' ? 'length' : 'byteLength';\n    return async function* (source) {\n        let numChunks = 0;\n        let builder = Builder.new(options);\n        for await (const value of source) {\n            if (builder.append(value)[sizeProperty] >= highWaterMark) {\n                ++numChunks && (yield builder.toVector());\n            }\n        }\n        if (builder.finish().length > 0 || numChunks === 0) {\n            yield builder.toVector();\n        }\n    };\n}\n\n//# sourceMappingURL=builder.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"../util/buffer\");\nconst buffer_2 = require(\"./buffer\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass BinaryBuilder extends builder_1.VariableWidthBuilder {\n    constructor(opts) {\n        super(opts);\n        this._values = new buffer_2.BufferBuilder(new Uint8Array(0));\n    }\n    get byteLength() {\n        let size = this._pendingLength + (this.length * 4);\n        this._offsets && (size += this._offsets.byteLength);\n        this._values && (size += this._values.byteLength);\n        this._nulls && (size += this._nulls.byteLength);\n        return size;\n    }\n    setValue(index, value) {\n        return super.setValue(index, buffer_1.toUint8Array(value));\n    }\n    _flushPending(pending, pendingLength) {\n        const offsets = this._offsets;\n        const data = this._values.reserve(pendingLength).buffer;\n        let index = 0, length = 0, offset = 0, value;\n        for ([index, value] of pending) {\n            if (value === undefined) {\n                offsets.set(index, 0);\n            }\n            else {\n                length = value.length;\n                data.set(value, offset);\n                offsets.set(index, length);\n                offset += length;\n            }\n        }\n    }\n}\nexports.BinaryBuilder = BinaryBuilder;\n\n//# sourceMappingURL=binary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"./buffer\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass BoolBuilder extends builder_1.Builder {\n    constructor(options) {\n        super(options);\n        this._values = new buffer_1.BitmapBufferBuilder();\n    }\n    setValue(index, value) {\n        this._values.set(index, +value);\n    }\n}\nexports.BoolBuilder = BoolBuilder;\n\n//# sourceMappingURL=bool.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"../util/buffer\");\nconst compat_1 = require(\"../util/compat\");\n/** @ignore */\nconst roundLengthUpToNearest64Bytes = (len, BPE) => ((((len * BPE) + 63) & ~63) || 64) / BPE;\n/** @ignore */\nconst sliceOrExtendArray = (arr, len = 0) => (arr.length >= len ? arr.subarray(0, len) : buffer_1.memcpy(new arr.constructor(len), arr, 0));\n/** @ignore */\nclass BufferBuilder {\n    constructor(buffer, stride = 1) {\n        this.buffer = buffer;\n        this.stride = stride;\n        this.BYTES_PER_ELEMENT = buffer.BYTES_PER_ELEMENT;\n        this.ArrayType = buffer.constructor;\n        this._resize(this.length = buffer.length / stride | 0);\n    }\n    get byteLength() { return this.length * this.stride * this.BYTES_PER_ELEMENT | 0; }\n    get reservedLength() { return this.buffer.length / this.stride; }\n    get reservedByteLength() { return this.buffer.byteLength; }\n    // @ts-ignore\n    set(index, value) { return this; }\n    append(value) { return this.set(this.length, value); }\n    reserve(extra) {\n        if (extra > 0) {\n            this.length += extra;\n            const stride = this.stride;\n            const length = this.length * stride;\n            const reserved = this.buffer.length;\n            if (length >= reserved) {\n                this._resize(reserved === 0\n                    ? roundLengthUpToNearest64Bytes(length * 1, this.BYTES_PER_ELEMENT)\n                    : roundLengthUpToNearest64Bytes(length * 2, this.BYTES_PER_ELEMENT));\n            }\n        }\n        return this;\n    }\n    flush(length = this.length) {\n        length = roundLengthUpToNearest64Bytes(length * this.stride, this.BYTES_PER_ELEMENT);\n        const array = sliceOrExtendArray(this.buffer, length);\n        this.clear();\n        return array;\n    }\n    clear() {\n        this.length = 0;\n        this._resize(0);\n        return this;\n    }\n    _resize(newLength) {\n        return this.buffer = buffer_1.memcpy(new this.ArrayType(newLength), this.buffer);\n    }\n}\nexports.BufferBuilder = BufferBuilder;\nBufferBuilder.prototype.offset = 0;\n/** @ignore */\nclass DataBufferBuilder extends BufferBuilder {\n    last() { return this.get(this.length - 1); }\n    get(index) { return this.buffer[index]; }\n    set(index, value) {\n        this.reserve(index - this.length + 1);\n        this.buffer[index * this.stride] = value;\n        return this;\n    }\n}\nexports.DataBufferBuilder = DataBufferBuilder;\n/** @ignore */\nclass BitmapBufferBuilder extends DataBufferBuilder {\n    constructor(data = new Uint8Array(0)) {\n        super(data, 1 / 8);\n        this.numValid = 0;\n    }\n    get numInvalid() { return this.length - this.numValid; }\n    get(idx) { return this.buffer[idx >> 3] >> idx % 8 & 1; }\n    set(idx, val) {\n        const { buffer } = this.reserve(idx - this.length + 1);\n        const byte = idx >> 3, bit = idx % 8, cur = buffer[byte] >> bit & 1;\n        // If `val` is truthy and the current bit is 0, flip it to 1 and increment `numValid`.\n        // If `val` is falsey and the current bit is 1, flip it to 0 and decrement `numValid`.\n        val ? cur === 0 && ((buffer[byte] |= (1 << bit)), ++this.numValid)\n            : cur === 1 && ((buffer[byte] &= ~(1 << bit)), --this.numValid);\n        return this;\n    }\n    clear() {\n        this.numValid = 0;\n        return super.clear();\n    }\n}\nexports.BitmapBufferBuilder = BitmapBufferBuilder;\n/** @ignore */\nclass OffsetsBufferBuilder extends DataBufferBuilder {\n    constructor(data = new Int32Array(1)) { super(data, 1); }\n    append(value) {\n        return this.set(this.length - 1, value);\n    }\n    set(index, value) {\n        const offset = this.length - 1;\n        const buffer = this.reserve(index - offset + 1).buffer;\n        if (offset < index++) {\n            buffer.fill(buffer[offset], offset, index);\n        }\n        buffer[index] = buffer[index - 1] + value;\n        return this;\n    }\n    flush(length = this.length - 1) {\n        if (length > this.length) {\n            this.set(length - 1, 0);\n        }\n        return super.flush(length + 1);\n    }\n}\nexports.OffsetsBufferBuilder = OffsetsBufferBuilder;\n/** @ignore */\nclass WideBufferBuilder extends BufferBuilder {\n    get ArrayType64() {\n        return this._ArrayType64 || (this._ArrayType64 = (this.buffer instanceof Int32Array ? compat_1.BigInt64Array : compat_1.BigUint64Array));\n    }\n    set(index, value) {\n        this.reserve(index - this.length + 1);\n        switch (typeof value) {\n            case 'bigint':\n                this.buffer64[index] = value;\n                break;\n            case 'number':\n                this.buffer[index * this.stride] = value;\n                break;\n            default: this.buffer.set(value, index * this.stride);\n        }\n        return this;\n    }\n    _resize(newLength) {\n        const data = super._resize(newLength);\n        const length = data.byteLength / (this.BYTES_PER_ELEMENT * this.stride);\n        if (compat_1.BigIntAvailable) {\n            this.buffer64 = new this.ArrayType64(data.buffer, data.byteOffset, length);\n        }\n        return data;\n    }\n}\nexports.WideBufferBuilder = WideBufferBuilder;\n\n//# sourceMappingURL=buffer.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass DateBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.DateBuilder = DateBuilder;\n/** @ignore */\nclass DateDayBuilder extends DateBuilder {\n}\nexports.DateDayBuilder = DateDayBuilder;\n/** @ignore */\nclass DateMillisecondBuilder extends DateBuilder {\n}\nexports.DateMillisecondBuilder = DateMillisecondBuilder;\n\n//# sourceMappingURL=date.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass DecimalBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.DecimalBuilder = DecimalBuilder;\n\n//# sourceMappingURL=decimal.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst type_1 = require(\"../type\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass DictionaryBuilder extends builder_1.Builder {\n    constructor({ 'type': type, 'nullValues': nulls, 'dictionaryHashFunction': hashFn }) {\n        super({ type: new type_1.Dictionary(type.dictionary, type.indices, type.id, type.isOrdered) });\n        this._nulls = null;\n        this._dictionaryOffset = 0;\n        this._keysToIndices = Object.create(null);\n        this.indices = builder_1.Builder.new({ 'type': this.type.indices, 'nullValues': nulls });\n        this.dictionary = builder_1.Builder.new({ 'type': this.type.dictionary, 'nullValues': null });\n        if (typeof hashFn === 'function') {\n            this.valueToKey = hashFn;\n        }\n    }\n    get values() { return this.indices.values; }\n    get nullCount() { return this.indices.nullCount; }\n    get nullBitmap() { return this.indices.nullBitmap; }\n    get byteLength() { return this.indices.byteLength + this.dictionary.byteLength; }\n    get reservedLength() { return this.indices.reservedLength + this.dictionary.reservedLength; }\n    get reservedByteLength() { return this.indices.reservedByteLength + this.dictionary.reservedByteLength; }\n    isValid(value) { return this.indices.isValid(value); }\n    setValid(index, valid) {\n        const indices = this.indices;\n        valid = indices.setValid(index, valid);\n        this.length = indices.length;\n        return valid;\n    }\n    setValue(index, value) {\n        let keysToIndices = this._keysToIndices;\n        let key = this.valueToKey(value);\n        let idx = keysToIndices[key];\n        if (idx === undefined) {\n            keysToIndices[key] = idx = this._dictionaryOffset + this.dictionary.append(value).length - 1;\n        }\n        return this.indices.setValue(index, idx);\n    }\n    flush() {\n        const type = this.type;\n        const prev = this._dictionary;\n        const curr = this.dictionary.toVector();\n        const data = this.indices.flush().clone(type);\n        data.dictionary = prev ? prev.concat(curr) : curr;\n        this.finished || (this._dictionaryOffset += curr.length);\n        this._dictionary = data.dictionary;\n        this.clear();\n        return data;\n    }\n    finish() {\n        this.indices.finish();\n        this.dictionary.finish();\n        this._dictionaryOffset = 0;\n        this._keysToIndices = Object.create(null);\n        return super.finish();\n    }\n    clear() {\n        this.indices.clear();\n        this.dictionary.clear();\n        return super.clear();\n    }\n    valueToKey(val) {\n        return typeof val === 'string' ? val : `${val}`;\n    }\n}\nexports.DictionaryBuilder = DictionaryBuilder;\n\n//# sourceMappingURL=dictionary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass FixedSizeBinaryBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.FixedSizeBinaryBuilder = FixedSizeBinaryBuilder;\n\n//# sourceMappingURL=fixedsizebinary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst run_1 = require(\"./run\");\nconst schema_1 = require(\"../schema\");\nconst builder_1 = require(\"../builder\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass FixedSizeListBuilder extends builder_1.Builder {\n    constructor() {\n        super(...arguments);\n        this._run = new run_1.Run();\n    }\n    setValue(index, value) {\n        super.setValue(index, this._run.bind(value));\n    }\n    addChild(child, name = '0') {\n        if (this.numChildren > 0) {\n            throw new Error('FixedSizeListBuilder can only have one child.');\n        }\n        const childIndex = this.children.push(child);\n        this.type = new type_1.FixedSizeList(this.type.listSize, new schema_1.Field(name, child.type, true));\n        return childIndex;\n    }\n    clear() {\n        this._run.clear();\n        return super.clear();\n    }\n}\nexports.FixedSizeListBuilder = FixedSizeListBuilder;\n\n//# sourceMappingURL=fixedsizelist.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst math_1 = require(\"../util/math\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass FloatBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.FloatBuilder = FloatBuilder;\n/** @ignore */\nclass Float16Builder extends FloatBuilder {\n    setValue(index, value) {\n        // convert JS float64 to a uint16\n        this._values.set(index, math_1.float64ToUint16(value));\n    }\n}\nexports.Float16Builder = Float16Builder;\n/** @ignore */\nclass Float32Builder extends FloatBuilder {\n    setValue(index, value) {\n        this._values.set(index, value);\n    }\n}\nexports.Float32Builder = Float32Builder;\n/** @ignore */\nclass Float64Builder extends FloatBuilder {\n    setValue(index, value) {\n        this._values.set(index, value);\n    }\n}\nexports.Float64Builder = Float64Builder;\n\n//# sourceMappingURL=float.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @ignore */\nvar builder_1 = require(\"../builder\");\nexports.Builder = builder_1.Builder;\nvar bool_1 = require(\"./bool\");\nexports.BoolBuilder = bool_1.BoolBuilder;\nvar null_1 = require(\"./null\");\nexports.NullBuilder = null_1.NullBuilder;\nvar date_1 = require(\"./date\");\nexports.DateBuilder = date_1.DateBuilder;\nexports.DateDayBuilder = date_1.DateDayBuilder;\nexports.DateMillisecondBuilder = date_1.DateMillisecondBuilder;\nvar decimal_1 = require(\"./decimal\");\nexports.DecimalBuilder = decimal_1.DecimalBuilder;\nvar dictionary_1 = require(\"./dictionary\");\nexports.DictionaryBuilder = dictionary_1.DictionaryBuilder;\nvar fixedsizebinary_1 = require(\"./fixedsizebinary\");\nexports.FixedSizeBinaryBuilder = fixedsizebinary_1.FixedSizeBinaryBuilder;\nvar float_1 = require(\"./float\");\nexports.FloatBuilder = float_1.FloatBuilder;\nexports.Float16Builder = float_1.Float16Builder;\nexports.Float32Builder = float_1.Float32Builder;\nexports.Float64Builder = float_1.Float64Builder;\nvar int_1 = require(\"./int\");\nexports.IntBuilder = int_1.IntBuilder;\nexports.Int8Builder = int_1.Int8Builder;\nexports.Int16Builder = int_1.Int16Builder;\nexports.Int32Builder = int_1.Int32Builder;\nexports.Int64Builder = int_1.Int64Builder;\nexports.Uint8Builder = int_1.Uint8Builder;\nexports.Uint16Builder = int_1.Uint16Builder;\nexports.Uint32Builder = int_1.Uint32Builder;\nexports.Uint64Builder = int_1.Uint64Builder;\nvar time_1 = require(\"./time\");\nexports.TimeBuilder = time_1.TimeBuilder;\nexports.TimeSecondBuilder = time_1.TimeSecondBuilder;\nexports.TimeMillisecondBuilder = time_1.TimeMillisecondBuilder;\nexports.TimeMicrosecondBuilder = time_1.TimeMicrosecondBuilder;\nexports.TimeNanosecondBuilder = time_1.TimeNanosecondBuilder;\nvar timestamp_1 = require(\"./timestamp\");\nexports.TimestampBuilder = timestamp_1.TimestampBuilder;\nexports.TimestampSecondBuilder = timestamp_1.TimestampSecondBuilder;\nexports.TimestampMillisecondBuilder = timestamp_1.TimestampMillisecondBuilder;\nexports.TimestampMicrosecondBuilder = timestamp_1.TimestampMicrosecondBuilder;\nexports.TimestampNanosecondBuilder = timestamp_1.TimestampNanosecondBuilder;\nvar interval_1 = require(\"./interval\");\nexports.IntervalBuilder = interval_1.IntervalBuilder;\nexports.IntervalDayTimeBuilder = interval_1.IntervalDayTimeBuilder;\nexports.IntervalYearMonthBuilder = interval_1.IntervalYearMonthBuilder;\nvar utf8_1 = require(\"./utf8\");\nexports.Utf8Builder = utf8_1.Utf8Builder;\nvar binary_1 = require(\"./binary\");\nexports.BinaryBuilder = binary_1.BinaryBuilder;\nvar list_1 = require(\"./list\");\nexports.ListBuilder = list_1.ListBuilder;\nvar fixedsizelist_1 = require(\"./fixedsizelist\");\nexports.FixedSizeListBuilder = fixedsizelist_1.FixedSizeListBuilder;\nvar map_1 = require(\"./map\");\nexports.MapBuilder = map_1.MapBuilder;\nvar struct_1 = require(\"./struct\");\nexports.StructBuilder = struct_1.StructBuilder;\nvar union_1 = require(\"./union\");\nexports.UnionBuilder = union_1.UnionBuilder;\nexports.SparseUnionBuilder = union_1.SparseUnionBuilder;\nexports.DenseUnionBuilder = union_1.DenseUnionBuilder;\nconst enum_1 = require(\"../enum\");\nconst utf8_2 = require(\"./utf8\");\nconst builder_2 = require(\"../builder\");\nconst set_1 = require(\"../visitor/set\");\nconst builderctor_1 = require(\"../visitor/builderctor\");\n/** @nocollapse */\nbuilder_2.Builder.new = newBuilder;\nfunction newBuilder(options) {\n    const type = options.type;\n    const builder = new (builderctor_1.instance.getVisitFn(type)())(options);\n    if (type.children && type.children.length > 0) {\n        const children = options['children'] || [];\n        const defaultOptions = { 'nullValues': options['nullValues'] };\n        const getChildOptions = Array.isArray(children)\n            ? ((_, i) => children[i] || defaultOptions)\n            : (({ name }) => children[name] || defaultOptions);\n        type.children.forEach((field, index) => {\n            const { type } = field;\n            const opts = getChildOptions(field, index);\n            builder.children.push(newBuilder({ ...opts, type }));\n        });\n    }\n    return builder;\n}\nObject.keys(enum_1.Type)\n    .map((T) => enum_1.Type[T])\n    .filter((T) => typeof T === 'number' && T !== enum_1.Type.NONE)\n    .forEach((typeId) => {\n    const BuilderCtor = builderctor_1.instance.visit(typeId);\n    BuilderCtor.prototype._setValue = set_1.instance.getVisitFn(typeId);\n});\nutf8_2.Utf8Builder.prototype._setValue = set_1.instance.visitBinary;\n\n//# sourceMappingURL=index.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst bn_1 = require(\"../util/bn\");\nconst buffer_1 = require(\"./buffer\");\nconst compat_1 = require(\"../util/compat\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass IntBuilder extends builder_1.FixedWidthBuilder {\n    setValue(index, value) {\n        this._values.set(index, value);\n    }\n}\nexports.IntBuilder = IntBuilder;\n/** @ignore */\nclass Int8Builder extends IntBuilder {\n}\nexports.Int8Builder = Int8Builder;\n/** @ignore */\nclass Int16Builder extends IntBuilder {\n}\nexports.Int16Builder = Int16Builder;\n/** @ignore */\nclass Int32Builder extends IntBuilder {\n}\nexports.Int32Builder = Int32Builder;\n/** @ignore */\nclass Int64Builder extends IntBuilder {\n    constructor(options) {\n        if (options['nullValues']) {\n            options['nullValues'] = options['nullValues'].map(toBigInt);\n        }\n        super(options);\n        this._values = new buffer_1.WideBufferBuilder(new Int32Array(0), 2);\n    }\n    get values64() { return this._values.buffer64; }\n    isValid(value) { return super.isValid(toBigInt(value)); }\n}\nexports.Int64Builder = Int64Builder;\n/** @ignore */\nclass Uint8Builder extends IntBuilder {\n}\nexports.Uint8Builder = Uint8Builder;\n/** @ignore */\nclass Uint16Builder extends IntBuilder {\n}\nexports.Uint16Builder = Uint16Builder;\n/** @ignore */\nclass Uint32Builder extends IntBuilder {\n}\nexports.Uint32Builder = Uint32Builder;\n/** @ignore */\nclass Uint64Builder extends IntBuilder {\n    constructor(options) {\n        if (options['nullValues']) {\n            options['nullValues'] = options['nullValues'].map(toBigInt);\n        }\n        super(options);\n        this._values = new buffer_1.WideBufferBuilder(new Uint32Array(0), 2);\n    }\n    get values64() { return this._values.buffer64; }\n    isValid(value) { return super.isValid(toBigInt(value)); }\n}\nexports.Uint64Builder = Uint64Builder;\nconst toBigInt = ((memo) => (value) => {\n    if (ArrayBuffer.isView(value)) {\n        memo.buffer = value.buffer;\n        memo.byteOffset = value.byteOffset;\n        memo.byteLength = value.byteLength;\n        value = bn_1.bignumToBigInt(memo);\n        memo.buffer = null;\n    }\n    return value;\n})({ 'BigIntArray': compat_1.BigInt64Array });\n\n//# sourceMappingURL=int.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass IntervalBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.IntervalBuilder = IntervalBuilder;\n/** @ignore */\nclass IntervalDayTimeBuilder extends IntervalBuilder {\n}\nexports.IntervalDayTimeBuilder = IntervalDayTimeBuilder;\n/** @ignore */\nclass IntervalYearMonthBuilder extends IntervalBuilder {\n}\nexports.IntervalYearMonthBuilder = IntervalYearMonthBuilder;\n\n//# sourceMappingURL=interval.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst run_1 = require(\"./run\");\nconst schema_1 = require(\"../schema\");\nconst type_1 = require(\"../type\");\nconst buffer_1 = require(\"./buffer\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass ListBuilder extends builder_1.VariableWidthBuilder {\n    constructor(opts) {\n        super(opts);\n        this._run = new run_1.Run();\n        this._offsets = new buffer_1.OffsetsBufferBuilder();\n    }\n    addChild(child, name = '0') {\n        if (this.numChildren > 0) {\n            throw new Error('ListBuilder can only have one child.');\n        }\n        this.children[this.numChildren] = child;\n        this.type = new type_1.List(new schema_1.Field(name, child.type, true));\n        return this.numChildren - 1;\n    }\n    clear() {\n        this._run.clear();\n        return super.clear();\n    }\n    _flushPending(pending) {\n        const run = this._run;\n        const offsets = this._offsets;\n        const setValue = this._setValue;\n        let index = 0, value;\n        for ([index, value] of pending) {\n            if (value === undefined) {\n                offsets.set(index, 0);\n            }\n            else {\n                offsets.set(index, value.length);\n                setValue(this, index, run.bind(value));\n            }\n        }\n    }\n}\nexports.ListBuilder = ListBuilder;\n\n//# sourceMappingURL=list.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst schema_1 = require(\"../schema\");\nconst type_1 = require(\"../type\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass MapBuilder extends builder_1.VariableWidthBuilder {\n    set(index, value) {\n        return super.set(index, value);\n    }\n    setValue(index, value) {\n        value = value instanceof Map ? value : new Map(Object.entries(value));\n        const pending = this._pending || (this._pending = new Map());\n        const current = pending.get(index);\n        current && (this._pendingLength -= current.size);\n        this._pendingLength += value.size;\n        pending.set(index, value);\n    }\n    addChild(child, name = `${this.numChildren}`) {\n        if (this.numChildren > 0) {\n            throw new Error('ListBuilder can only have one child.');\n        }\n        this.children[this.numChildren] = child;\n        this.type = new type_1.Map_(new schema_1.Field(name, child.type, true), this.type.keysSorted);\n        return this.numChildren - 1;\n    }\n    _flushPending(pending) {\n        const offsets = this._offsets;\n        const setValue = this._setValue;\n        pending.forEach((value, index) => {\n            if (value === undefined) {\n                offsets.set(index, 0);\n            }\n            else {\n                offsets.set(index, value.size);\n                setValue(this, index, value);\n            }\n        });\n    }\n}\nexports.MapBuilder = MapBuilder;\n\n//# sourceMappingURL=map.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass NullBuilder extends builder_1.Builder {\n    // @ts-ignore\n    setValue(index, value) { }\n    setValid(index, valid) {\n        this.length = Math.max(index + 1, this.length);\n        return valid;\n    }\n}\nexports.NullBuilder = NullBuilder;\n\n//# sourceMappingURL=null.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\n/** @ignore */\nclass Run {\n    get length() { return this._values.length; }\n    get(index) { return this._values[index]; }\n    clear() { this._values = null; return this; }\n    bind(values) {\n        if (values instanceof vector_1.Vector) {\n            return values;\n        }\n        this._values = values;\n        return this;\n    }\n}\nexports.Run = Run;\n\n//# sourceMappingURL=run.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst schema_1 = require(\"../schema\");\nconst builder_1 = require(\"../builder\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass StructBuilder extends builder_1.Builder {\n    addChild(child, name = `${this.numChildren}`) {\n        const childIndex = this.children.push(child);\n        this.type = new type_1.Struct([...this.type.children, new schema_1.Field(name, child.type, true)]);\n        return childIndex;\n    }\n}\nexports.StructBuilder = StructBuilder;\n\n//# sourceMappingURL=struct.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass TimeBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.TimeBuilder = TimeBuilder;\n/** @ignore */\nclass TimeSecondBuilder extends TimeBuilder {\n}\nexports.TimeSecondBuilder = TimeSecondBuilder;\n/** @ignore */\nclass TimeMillisecondBuilder extends TimeBuilder {\n}\nexports.TimeMillisecondBuilder = TimeMillisecondBuilder;\n/** @ignore */\nclass TimeMicrosecondBuilder extends TimeBuilder {\n}\nexports.TimeMicrosecondBuilder = TimeMicrosecondBuilder;\n/** @ignore */\nclass TimeNanosecondBuilder extends TimeBuilder {\n}\nexports.TimeNanosecondBuilder = TimeNanosecondBuilder;\n\n//# sourceMappingURL=time.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass TimestampBuilder extends builder_1.FixedWidthBuilder {\n}\nexports.TimestampBuilder = TimestampBuilder;\n/** @ignore */\nclass TimestampSecondBuilder extends TimestampBuilder {\n}\nexports.TimestampSecondBuilder = TimestampSecondBuilder;\n/** @ignore */\nclass TimestampMillisecondBuilder extends TimestampBuilder {\n}\nexports.TimestampMillisecondBuilder = TimestampMillisecondBuilder;\n/** @ignore */\nclass TimestampMicrosecondBuilder extends TimestampBuilder {\n}\nexports.TimestampMicrosecondBuilder = TimestampMicrosecondBuilder;\n/** @ignore */\nclass TimestampNanosecondBuilder extends TimestampBuilder {\n}\nexports.TimestampNanosecondBuilder = TimestampNanosecondBuilder;\n\n//# sourceMappingURL=timestamp.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst schema_1 = require(\"../schema\");\nconst buffer_1 = require(\"./buffer\");\nconst builder_1 = require(\"../builder\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass UnionBuilder extends builder_1.Builder {\n    constructor(options) {\n        super(options);\n        this._typeIds = new buffer_1.DataBufferBuilder(new Int8Array(0), 1);\n        if (typeof options['valueToChildTypeId'] === 'function') {\n            this._valueToChildTypeId = options['valueToChildTypeId'];\n        }\n    }\n    get typeIdToChildIndex() { return this.type.typeIdToChildIndex; }\n    append(value, childTypeId) {\n        return this.set(this.length, value, childTypeId);\n    }\n    set(index, value, childTypeId) {\n        if (childTypeId === undefined) {\n            childTypeId = this._valueToChildTypeId(this, value, index);\n        }\n        if (this.setValid(index, this.isValid(value))) {\n            this.setValue(index, value, childTypeId);\n        }\n        return this;\n    }\n    // @ts-ignore\n    setValue(index, value, childTypeId) {\n        this._typeIds.set(index, childTypeId);\n        super.setValue(index, value);\n    }\n    // @ts-ignore\n    addChild(child, name = `${this.children.length}`) {\n        const childTypeId = this.children.push(child);\n        const { type: { children, mode, typeIds } } = this;\n        const fields = [...children, new schema_1.Field(name, child.type)];\n        this.type = new type_1.Union(mode, [...typeIds, childTypeId], fields);\n        return childTypeId;\n    }\n    /** @ignore */\n    // @ts-ignore\n    _valueToChildTypeId(builder, value, offset) {\n        throw new Error(`Cannot map UnionBuilder value to child typeId. \\\nPass the \\`childTypeId\\` as the second argument to unionBuilder.append(), \\\nor supply a \\`valueToChildTypeId\\` function as part of the UnionBuilder constructor options.`);\n    }\n}\nexports.UnionBuilder = UnionBuilder;\n/** @ignore */\nclass SparseUnionBuilder extends UnionBuilder {\n}\nexports.SparseUnionBuilder = SparseUnionBuilder;\n/** @ignore */\nclass DenseUnionBuilder extends UnionBuilder {\n    constructor(options) {\n        super(options);\n        this._offsets = new buffer_1.DataBufferBuilder(new Int32Array(0));\n    }\n    /** @ignore */\n    setValue(index, value, childTypeId) {\n        const childIndex = this.type.typeIdToChildIndex[childTypeId];\n        this._offsets.set(index, this.getChildAt(childIndex).length);\n        return super.setValue(index, value, childTypeId);\n    }\n}\nexports.DenseUnionBuilder = DenseUnionBuilder;\n\n//# sourceMappingURL=union.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst utf8_1 = require(\"../util/utf8\");\nconst binary_1 = require(\"./binary\");\nconst buffer_1 = require(\"./buffer\");\nconst builder_1 = require(\"../builder\");\n/** @ignore */\nclass Utf8Builder extends builder_1.VariableWidthBuilder {\n    constructor(opts) {\n        super(opts);\n        this._values = new buffer_1.BufferBuilder(new Uint8Array(0));\n    }\n    get byteLength() {\n        let size = this._pendingLength + (this.length * 4);\n        this._offsets && (size += this._offsets.byteLength);\n        this._values && (size += this._values.byteLength);\n        this._nulls && (size += this._nulls.byteLength);\n        return size;\n    }\n    setValue(index, value) {\n        return super.setValue(index, utf8_1.encodeUtf8(value));\n    }\n    // @ts-ignore\n    _flushPending(pending, pendingLength) { }\n}\nexports.Utf8Builder = Utf8Builder;\nUtf8Builder.prototype._flushPending = binary_1.BinaryBuilder.prototype._flushPending;\n\n//# sourceMappingURL=utf8.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst pretty_1 = require(\"../util/pretty\");\nconst compat_1 = require(\"../util/compat\");\n/**\n * Dynamically compile the null values into an `isValid()` function whose\n * implementation is a switch statement. Microbenchmarks in v8 indicate\n * this approach is 25% faster than using an ES6 Map.\n *\n * @example\n * console.log(createIsValidFunction([null, 'N/A', NaN]));\n * `function (x) {\n *     if (x !== x) return false;\n *     switch (x) {\n *         case null:\n *         case \"N/A\":\n *             return false;\n *     }\n *     return true;\n * }`\n *\n * @ignore\n * @param nullValues\n */\nfunction createIsValidFunction(nullValues) {\n    if (!nullValues || nullValues.length <= 0) {\n        // @ts-ignore\n        return function isValid(value) { return true; };\n    }\n    let fnBody = '';\n    let noNaNs = nullValues.filter((x) => x === x);\n    if (noNaNs.length > 0) {\n        fnBody = `\n    switch (x) {${noNaNs.map((x) => `\n        case ${valueToCase(x)}:`).join('')}\n            return false;\n    }`;\n    }\n    // NaN doesn't equal anything including itself, so it doesn't work as a\n    // switch case. Instead we must explicitly check for NaN before the switch.\n    if (nullValues.length !== noNaNs.length) {\n        fnBody = `if (x !== x) return false;\\n${fnBody}`;\n    }\n    return new Function(`x`, `${fnBody}\\nreturn true;`);\n}\nexports.createIsValidFunction = createIsValidFunction;\n/** @ignore */\nfunction valueToCase(x) {\n    if (typeof x !== 'bigint') {\n        return pretty_1.valueToString(x);\n    }\n    else if (compat_1.BigIntAvailable) {\n        return `${pretty_1.valueToString(x)}n`;\n    }\n    return `\"${pretty_1.valueToString(x)}\"`;\n}\n\n//# sourceMappingURL=valid.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst schema_1 = require(\"./schema\");\nconst vector_1 = require(\"./vector\");\nconst chunked_1 = require(\"./vector/chunked\");\nclass Column extends chunked_1.Chunked {\n    constructor(field, vectors = [], offsets) {\n        vectors = chunked_1.Chunked.flatten(...vectors);\n        super(field.type, vectors, offsets);\n        this._field = field;\n        if (vectors.length === 1 && !(this instanceof SingleChunkColumn)) {\n            return new SingleChunkColumn(field, vectors[0], this._chunkOffsets);\n        }\n    }\n    /** @nocollapse */\n    static new(field, data, ...rest) {\n        const chunks = chunked_1.Chunked.flatten(Array.isArray(data) ? [...data, ...rest] :\n            data instanceof vector_1.Vector ? [data, ...rest] :\n                [vector_1.Vector.new(data, ...rest)]);\n        if (typeof field === 'string') {\n            const type = chunks[0].data.type;\n            field = new schema_1.Field(field, type, true);\n        }\n        else if (!field.nullable && chunks.some(({ nullCount }) => nullCount > 0)) {\n            field = field.clone({ nullable: true });\n        }\n        return new Column(field, chunks);\n    }\n    get field() { return this._field; }\n    get name() { return this._field.name; }\n    get nullable() { return this._field.nullable; }\n    get metadata() { return this._field.metadata; }\n    clone(chunks = this._chunks) {\n        return new Column(this._field, chunks);\n    }\n    getChildAt(index) {\n        if (index < 0 || index >= this.numChildren) {\n            return null;\n        }\n        let columns = this._children || (this._children = []);\n        let column, field, chunks;\n        if (column = columns[index]) {\n            return column;\n        }\n        if (field = (this.type.children || [])[index]) {\n            chunks = this._chunks\n                .map((vector) => vector.getChildAt(index))\n                .filter((vec) => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Column(field, chunks));\n            }\n        }\n        return null;\n    }\n}\nexports.Column = Column;\n/** @ignore */\nclass SingleChunkColumn extends Column {\n    constructor(field, vector, offsets) {\n        super(field, [vector], offsets);\n        this._chunk = vector;\n    }\n    search(index, then) {\n        return then ? then(this, 0, index) : [0, index];\n    }\n    isValid(index) {\n        return this._chunk.isValid(index);\n    }\n    get(index) {\n        return this._chunk.get(index);\n    }\n    set(index, value) {\n        this._chunk.set(index, value);\n    }\n    indexOf(element, offset) {\n        return this._chunk.indexOf(element, offset);\n    }\n}\n\n//# sourceMappingURL=column.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst table_1 = require(\"../table\");\nconst int_1 = require(\"../vector/int\");\nconst schema_1 = require(\"../schema\");\nconst predicate_1 = require(\"./predicate\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst type_1 = require(\"../type\");\ntable_1.Table.prototype.countBy = function (name) { return new DataFrame(this.chunks).countBy(name); };\ntable_1.Table.prototype.scan = function (next, bind) { return new DataFrame(this.chunks).scan(next, bind); };\ntable_1.Table.prototype.scanReverse = function (next, bind) { return new DataFrame(this.chunks).scanReverse(next, bind); };\ntable_1.Table.prototype.filter = function (predicate) { return new DataFrame(this.chunks).filter(predicate); };\nclass DataFrame extends table_1.Table {\n    filter(predicate) {\n        return new FilteredDataFrame(this.chunks, predicate);\n    }\n    scan(next, bind) {\n        const batches = this.chunks, numBatches = batches.length;\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            if (bind) {\n                bind(batch);\n            }\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                next(index, batch);\n            }\n        }\n    }\n    scanReverse(next, bind) {\n        const batches = this.chunks, numBatches = batches.length;\n        for (let batchIndex = numBatches; --batchIndex >= 0;) {\n            // load batches\n            const batch = batches[batchIndex];\n            if (bind) {\n                bind(batch);\n            }\n            // yield all indices\n            for (let index = batch.length; --index >= 0;) {\n                next(index, batch);\n            }\n        }\n    }\n    countBy(name) {\n        const batches = this.chunks, numBatches = batches.length;\n        const count_by = typeof name === 'string' ? new predicate_1.Col(name) : name;\n        // Assume that all dictionary batches are deltas, which means that the\n        // last record batch has the most complete dictionary\n        count_by.bind(batches[numBatches - 1]);\n        const vector = count_by.vector;\n        if (!type_1.DataType.isDictionary(vector.type)) {\n            throw new Error('countBy currently only supports dictionary-encoded columns');\n        }\n        const countByteLength = Math.ceil(Math.log(vector.length) / Math.log(256));\n        const CountsArrayType = countByteLength == 4 ? Uint32Array :\n            countByteLength >= 2 ? Uint16Array : Uint8Array;\n        const counts = new CountsArrayType(vector.dictionary.length);\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            // rebind the countBy Col\n            count_by.bind(batch);\n            const keys = count_by.vector.indices;\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                let key = keys.get(index);\n                if (key !== null) {\n                    counts[key]++;\n                }\n            }\n        }\n        return new CountByResult(vector.dictionary, int_1.IntVector.from(counts));\n    }\n}\nexports.DataFrame = DataFrame;\n/** @ignore */\nclass CountByResult extends table_1.Table {\n    constructor(values, counts) {\n        const schema = new schema_1.Schema([\n            new schema_1.Field('values', values.type),\n            new schema_1.Field('counts', counts.type)\n        ]);\n        super(new recordbatch_1.RecordBatch(schema, counts.length, [values, counts]));\n    }\n    toJSON() {\n        const values = this.getColumnAt(0);\n        const counts = this.getColumnAt(1);\n        const result = {};\n        for (let i = -1; ++i < this.length;) {\n            result[values.get(i)] = counts.get(i);\n        }\n        return result;\n    }\n}\nexports.CountByResult = CountByResult;\n/** @ignore */\nclass FilteredDataFrame extends DataFrame {\n    constructor(batches, predicate) {\n        super(batches);\n        this._predicate = predicate;\n    }\n    scan(next, bind) {\n        // inlined version of this:\n        // this.parent.scan((idx, columns) => {\n        //     if (this.predicate(idx, columns)) next(idx, columns);\n        // });\n        const batches = this._chunks;\n        const numBatches = batches.length;\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            // TODO: bind batches lazily\n            // If predicate doesn't match anything in the batch we don't need\n            // to bind the callback\n            if (bind) {\n                bind(batch);\n            }\n            const predicate = this._predicate.bind(batch);\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                if (predicate(index, batch)) {\n                    next(index, batch);\n                }\n            }\n        }\n    }\n    scanReverse(next, bind) {\n        const batches = this._chunks;\n        const numBatches = batches.length;\n        for (let batchIndex = numBatches; --batchIndex >= 0;) {\n            // load batches\n            const batch = batches[batchIndex];\n            // TODO: bind batches lazily\n            // If predicate doesn't match anything in the batch we don't need\n            // to bind the callback\n            if (bind) {\n                bind(batch);\n            }\n            const predicate = this._predicate.bind(batch);\n            // yield all indices\n            for (let index = batch.length; --index >= 0;) {\n                if (predicate(index, batch)) {\n                    next(index, batch);\n                }\n            }\n        }\n    }\n    count() {\n        // inlined version of this:\n        // let sum = 0;\n        // this.parent.scan((idx, columns) => {\n        //     if (this.predicate(idx, columns)) ++sum;\n        // });\n        // return sum;\n        let sum = 0;\n        const batches = this._chunks;\n        const numBatches = batches.length;\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            const predicate = this._predicate.bind(batch);\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                if (predicate(index, batch)) {\n                    ++sum;\n                }\n            }\n        }\n        return sum;\n    }\n    *[Symbol.iterator]() {\n        // inlined version of this:\n        // this.parent.scan((idx, columns) => {\n        //     if (this.predicate(idx, columns)) next(idx, columns);\n        // });\n        const batches = this._chunks;\n        const numBatches = batches.length;\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            // TODO: bind batches lazily\n            // If predicate doesn't match anything in the batch we don't need\n            // to bind the callback\n            const predicate = this._predicate.bind(batch);\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                if (predicate(index, batch)) {\n                    yield batch.get(index);\n                }\n            }\n        }\n    }\n    filter(predicate) {\n        return new FilteredDataFrame(this._chunks, this._predicate.and(predicate));\n    }\n    countBy(name) {\n        const batches = this._chunks, numBatches = batches.length;\n        const count_by = typeof name === 'string' ? new predicate_1.Col(name) : name;\n        // Assume that all dictionary batches are deltas, which means that the\n        // last record batch has the most complete dictionary\n        count_by.bind(batches[numBatches - 1]);\n        const vector = count_by.vector;\n        if (!type_1.DataType.isDictionary(vector.type)) {\n            throw new Error('countBy currently only supports dictionary-encoded columns');\n        }\n        const countByteLength = Math.ceil(Math.log(vector.length) / Math.log(256));\n        const CountsArrayType = countByteLength == 4 ? Uint32Array :\n            countByteLength >= 2 ? Uint16Array : Uint8Array;\n        const counts = new CountsArrayType(vector.dictionary.length);\n        for (let batchIndex = -1; ++batchIndex < numBatches;) {\n            // load batches\n            const batch = batches[batchIndex];\n            const predicate = this._predicate.bind(batch);\n            // rebind the countBy Col\n            count_by.bind(batch);\n            const keys = count_by.vector.indices;\n            // yield all indices\n            for (let index = -1, numRows = batch.length; ++index < numRows;) {\n                let key = keys.get(index);\n                if (key !== null && predicate(index, batch)) {\n                    counts[key]++;\n                }\n            }\n        }\n        return new CountByResult(vector.dictionary, int_1.IntVector.from(counts));\n    }\n}\nexports.FilteredDataFrame = FilteredDataFrame;\n\n//# sourceMappingURL=dataframe.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst dictionary_1 = require(\"../vector/dictionary\");\n/** @ignore */\nclass Value {\n    eq(other) {\n        if (!(other instanceof Value)) {\n            other = new Literal(other);\n        }\n        return new Equals(this, other);\n    }\n    le(other) {\n        if (!(other instanceof Value)) {\n            other = new Literal(other);\n        }\n        return new LTeq(this, other);\n    }\n    ge(other) {\n        if (!(other instanceof Value)) {\n            other = new Literal(other);\n        }\n        return new GTeq(this, other);\n    }\n    lt(other) {\n        return new Not(this.ge(other));\n    }\n    gt(other) {\n        return new Not(this.le(other));\n    }\n    ne(other) {\n        return new Not(this.eq(other));\n    }\n}\nexports.Value = Value;\n/** @ignore */\nclass Literal extends Value {\n    constructor(v) {\n        super();\n        this.v = v;\n    }\n}\nexports.Literal = Literal;\n/** @ignore */\nclass Col extends Value {\n    constructor(name) {\n        super();\n        this.name = name;\n    }\n    bind(batch) {\n        if (!this.colidx) {\n            // Assume column index doesn't change between calls to bind\n            //this.colidx = cols.findIndex(v => v.name.indexOf(this.name) != -1);\n            this.colidx = -1;\n            const fields = batch.schema.fields;\n            for (let idx = -1; ++idx < fields.length;) {\n                if (fields[idx].name === this.name) {\n                    this.colidx = idx;\n                    break;\n                }\n            }\n            if (this.colidx < 0) {\n                throw new Error(`Failed to bind Col \"${this.name}\"`);\n            }\n        }\n        const vec = this.vector = batch.getChildAt(this.colidx);\n        return (idx) => vec.get(idx);\n    }\n}\nexports.Col = Col;\n/** @ignore */\nclass Predicate {\n    and(...expr) { return new And(this, ...expr); }\n    or(...expr) { return new Or(this, ...expr); }\n    not() { return new Not(this); }\n}\nexports.Predicate = Predicate;\n/** @ignore */\nclass ComparisonPredicate extends Predicate {\n    constructor(left, right) {\n        super();\n        this.left = left;\n        this.right = right;\n    }\n    bind(batch) {\n        if (this.left instanceof Literal) {\n            if (this.right instanceof Literal) {\n                return this._bindLitLit(batch, this.left, this.right);\n            }\n            else { // right is a Col\n                return this._bindLitCol(batch, this.left, this.right);\n            }\n        }\n        else { // left is a Col\n            if (this.right instanceof Literal) {\n                return this._bindColLit(batch, this.left, this.right);\n            }\n            else { // right is a Col\n                return this._bindColCol(batch, this.left, this.right);\n            }\n        }\n    }\n}\nexports.ComparisonPredicate = ComparisonPredicate;\n/** @ignore */\nclass CombinationPredicate extends Predicate {\n    constructor(...children) {\n        super();\n        this.children = children;\n    }\n}\nexports.CombinationPredicate = CombinationPredicate;\n// add children to protoype so it doesn't get mangled in es2015/umd\nCombinationPredicate.prototype.children = Object.freeze([]); // freeze for safety\n/** @ignore */\nclass And extends CombinationPredicate {\n    constructor(...children) {\n        // Flatten any Ands\n        children = children.reduce((accum, p) => {\n            return accum.concat(p instanceof And ? p.children : p);\n        }, []);\n        super(...children);\n    }\n    bind(batch) {\n        const bound = this.children.map((p) => p.bind(batch));\n        return (idx, batch) => bound.every((p) => p(idx, batch));\n    }\n}\nexports.And = And;\n/** @ignore */\nclass Or extends CombinationPredicate {\n    constructor(...children) {\n        // Flatten any Ors\n        children = children.reduce((accum, p) => {\n            return accum.concat(p instanceof Or ? p.children : p);\n        }, []);\n        super(...children);\n    }\n    bind(batch) {\n        const bound = this.children.map((p) => p.bind(batch));\n        return (idx, batch) => bound.some((p) => p(idx, batch));\n    }\n}\nexports.Or = Or;\n/** @ignore */\nclass Equals extends ComparisonPredicate {\n    _bindLitLit(_batch, left, right) {\n        const rtrn = left.v == right.v;\n        return () => rtrn;\n    }\n    _bindColCol(batch, left, right) {\n        const left_func = left.bind(batch);\n        const right_func = right.bind(batch);\n        return (idx, batch) => left_func(idx, batch) == right_func(idx, batch);\n    }\n    _bindColLit(batch, col, lit) {\n        const col_func = col.bind(batch);\n        if (col.vector instanceof dictionary_1.DictionaryVector) {\n            let key;\n            const vector = col.vector;\n            if (vector.dictionary !== this.lastDictionary) {\n                key = vector.reverseLookup(lit.v);\n                this.lastDictionary = vector.dictionary;\n                this.lastKey = key;\n            }\n            else {\n                key = this.lastKey;\n            }\n            if (key === -1) {\n                // the value doesn't exist in the dictionary - always return\n                // false\n                // TODO: special-case of PredicateFunc that encapsulates this\n                // \"always false\" behavior. That way filtering operations don't\n                // have to bother checking\n                return () => false;\n            }\n            else {\n                return (idx) => {\n                    return vector.getKey(idx) === key;\n                };\n            }\n        }\n        else {\n            return (idx, cols) => col_func(idx, cols) == lit.v;\n        }\n    }\n    _bindLitCol(batch, lit, col) {\n        // Equals is comutative\n        return this._bindColLit(batch, col, lit);\n    }\n}\nexports.Equals = Equals;\n/** @ignore */\nclass LTeq extends ComparisonPredicate {\n    _bindLitLit(_batch, left, right) {\n        const rtrn = left.v <= right.v;\n        return () => rtrn;\n    }\n    _bindColCol(batch, left, right) {\n        const left_func = left.bind(batch);\n        const right_func = right.bind(batch);\n        return (idx, cols) => left_func(idx, cols) <= right_func(idx, cols);\n    }\n    _bindColLit(batch, col, lit) {\n        const col_func = col.bind(batch);\n        return (idx, cols) => col_func(idx, cols) <= lit.v;\n    }\n    _bindLitCol(batch, lit, col) {\n        const col_func = col.bind(batch);\n        return (idx, cols) => lit.v <= col_func(idx, cols);\n    }\n}\nexports.LTeq = LTeq;\n/** @ignore */\nclass GTeq extends ComparisonPredicate {\n    _bindLitLit(_batch, left, right) {\n        const rtrn = left.v >= right.v;\n        return () => rtrn;\n    }\n    _bindColCol(batch, left, right) {\n        const left_func = left.bind(batch);\n        const right_func = right.bind(batch);\n        return (idx, cols) => left_func(idx, cols) >= right_func(idx, cols);\n    }\n    _bindColLit(batch, col, lit) {\n        const col_func = col.bind(batch);\n        return (idx, cols) => col_func(idx, cols) >= lit.v;\n    }\n    _bindLitCol(batch, lit, col) {\n        const col_func = col.bind(batch);\n        return (idx, cols) => lit.v >= col_func(idx, cols);\n    }\n}\nexports.GTeq = GTeq;\n/** @ignore */\nclass Not extends Predicate {\n    constructor(child) {\n        super();\n        this.child = child;\n    }\n    bind(batch) {\n        const func = this.child.bind(batch);\n        return (idx, batch) => !func(idx, batch);\n    }\n}\nexports.Not = Not;\n/** @ignore */\nclass CustomPredicate extends Predicate {\n    constructor(next, bind_) {\n        super();\n        this.next = next;\n        this.bind_ = bind_;\n    }\n    bind(batch) {\n        this.bind_(batch);\n        return this.next;\n    }\n}\nexports.CustomPredicate = CustomPredicate;\nfunction lit(v) { return new Literal(v); }\nexports.lit = lit;\nfunction col(n) { return new Col(n); }\nexports.col = col;\nfunction and(...p) { return new And(...p); }\nexports.and = and;\nfunction or(...p) { return new Or(...p); }\nexports.or = or;\nfunction custom(next, bind) {\n    return new CustomPredicate(next, bind);\n}\nexports.custom = custom;\n\n//# sourceMappingURL=predicate.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst bit_1 = require(\"./util/bit\");\nconst bit_2 = require(\"./util/bit\");\nconst enum_1 = require(\"./enum\");\nconst type_1 = require(\"./type\");\nconst buffer_1 = require(\"./util/buffer\");\n/** @ignore */ exports.kUnknownNullCount = -1;\n/** @ignore */\nclass Data {\n    constructor(type, offset, length, nullCount, buffers, childData, dictionary) {\n        this.type = type;\n        this.dictionary = dictionary;\n        this.offset = Math.floor(Math.max(offset || 0, 0));\n        this.length = Math.floor(Math.max(length || 0, 0));\n        this._nullCount = Math.floor(Math.max(nullCount || 0, -1));\n        this.childData = (childData || []).map((x) => x instanceof Data ? x : x.data);\n        let buffer;\n        if (buffers instanceof Data) {\n            this.stride = buffers.stride;\n            this.values = buffers.values;\n            this.typeIds = buffers.typeIds;\n            this.nullBitmap = buffers.nullBitmap;\n            this.valueOffsets = buffers.valueOffsets;\n        }\n        else {\n            this.stride = type_1.strideForType(type);\n            if (buffers) {\n                (buffer = buffers[0]) && (this.valueOffsets = buffer);\n                (buffer = buffers[1]) && (this.values = buffer);\n                (buffer = buffers[2]) && (this.nullBitmap = buffer);\n                (buffer = buffers[3]) && (this.typeIds = buffer);\n            }\n        }\n    }\n    get typeId() { return this.type.typeId; }\n    get ArrayType() { return this.type.ArrayType; }\n    get buffers() {\n        return [this.valueOffsets, this.values, this.nullBitmap, this.typeIds];\n    }\n    get byteLength() {\n        let byteLength = 0;\n        let { valueOffsets, values, nullBitmap, typeIds } = this;\n        valueOffsets && (byteLength += valueOffsets.byteLength);\n        values && (byteLength += values.byteLength);\n        nullBitmap && (byteLength += nullBitmap.byteLength);\n        typeIds && (byteLength += typeIds.byteLength);\n        return this.childData.reduce((byteLength, child) => byteLength + child.byteLength, byteLength);\n    }\n    get nullCount() {\n        let nullCount = this._nullCount;\n        let nullBitmap;\n        if (nullCount <= exports.kUnknownNullCount && (nullBitmap = this.nullBitmap)) {\n            this._nullCount = nullCount = this.length - bit_2.popcnt_bit_range(nullBitmap, this.offset, this.offset + this.length);\n        }\n        return nullCount;\n    }\n    clone(type, offset = this.offset, length = this.length, nullCount = this._nullCount, buffers = this, childData = this.childData) {\n        return new Data(type, offset, length, nullCount, buffers, childData, this.dictionary);\n    }\n    slice(offset, length) {\n        const { stride, typeId, childData } = this;\n        // +true === 1, +false === 0, so this means\n        // we keep nullCount at 0 if it's already 0,\n        // otherwise set to the invalidated flag -1\n        const nullCount = +(this._nullCount === 0) - 1;\n        const childStride = typeId === 16 /* FixedSizeList */ ? stride : 1;\n        const buffers = this._sliceBuffers(offset, length, stride, typeId);\n        return this.clone(this.type, this.offset + offset, length, nullCount, buffers, \n        // Don't slice children if we have value offsets (the variable-width types)\n        (!childData.length || this.valueOffsets) ? childData : this._sliceChildren(childData, childStride * offset, childStride * length));\n    }\n    _changeLengthAndBackfillNullBitmap(newLength) {\n        if (this.typeId === enum_1.Type.Null) {\n            return this.clone(this.type, 0, newLength, 0);\n        }\n        const { length, nullCount } = this;\n        // start initialized with 0s (nulls), then fill from 0 to length with 1s (not null)\n        const bitmap = new Uint8Array(((newLength + 63) & ~63) >> 3).fill(255, 0, length >> 3);\n        // set all the bits in the last byte (up to bit `length - length % 8`) to 1 (not null)\n        bitmap[length >> 3] = (1 << (length - (length & ~7))) - 1;\n        // if we have a nullBitmap, truncate + slice and set it over the pre-filled 1s\n        if (nullCount > 0) {\n            bitmap.set(bit_1.truncateBitmap(this.offset, length, this.nullBitmap), 0);\n        }\n        const buffers = this.buffers;\n        buffers[enum_1.BufferType.VALIDITY] = bitmap;\n        return this.clone(this.type, 0, newLength, nullCount + (newLength - length), buffers);\n    }\n    _sliceBuffers(offset, length, stride, typeId) {\n        let arr, { buffers } = this;\n        // If typeIds exist, slice the typeIds buffer\n        (arr = buffers[enum_1.BufferType.TYPE]) && (buffers[enum_1.BufferType.TYPE] = arr.subarray(offset, offset + length));\n        // If offsets exist, only slice the offsets buffer\n        (arr = buffers[enum_1.BufferType.OFFSET]) && (buffers[enum_1.BufferType.OFFSET] = arr.subarray(offset, offset + length + 1)) ||\n            // Otherwise if no offsets, slice the data buffer. Don't slice the data vector for Booleans, since the offset goes by bits not bytes\n            (arr = buffers[enum_1.BufferType.DATA]) && (buffers[enum_1.BufferType.DATA] = typeId === 6 ? arr : arr.subarray(stride * offset, stride * (offset + length)));\n        return buffers;\n    }\n    _sliceChildren(childData, offset, length) {\n        return childData.map((child) => child.slice(offset, length));\n    }\n    //\n    // Convenience methods for creating Data instances for each of the Arrow Vector types\n    //\n    /** @nocollapse */\n    static new(type, offset, length, nullCount, buffers, childData, dictionary) {\n        if (buffers instanceof Data) {\n            buffers = buffers.buffers;\n        }\n        else if (!buffers) {\n            buffers = [];\n        }\n        switch (type.typeId) {\n            case enum_1.Type.Null: return Data.Null(type, offset, length);\n            case enum_1.Type.Int: return Data.Int(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Dictionary: return Data.Dictionary(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || [], dictionary);\n            case enum_1.Type.Float: return Data.Float(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Bool: return Data.Bool(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Decimal: return Data.Decimal(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Date: return Data.Date(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Time: return Data.Time(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Timestamp: return Data.Timestamp(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Interval: return Data.Interval(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.FixedSizeBinary: return Data.FixedSizeBinary(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Binary: return Data.Binary(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.OFFSET] || [], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.Utf8: return Data.Utf8(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.OFFSET] || [], buffers[enum_1.BufferType.DATA] || []);\n            case enum_1.Type.List: return Data.List(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.OFFSET] || [], (childData || [])[0]);\n            case enum_1.Type.FixedSizeList: return Data.FixedSizeList(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], (childData || [])[0]);\n            case enum_1.Type.Struct: return Data.Struct(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], childData || []);\n            case enum_1.Type.Map: return Data.Map(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.OFFSET] || [], (childData || [])[0]);\n            case enum_1.Type.Union: return Data.Union(type, offset, length, nullCount || 0, buffers[enum_1.BufferType.VALIDITY], buffers[enum_1.BufferType.TYPE] || [], buffers[enum_1.BufferType.OFFSET] || childData, childData);\n        }\n        throw new Error(`Unrecognized typeId ${type.typeId}`);\n    }\n    /** @nocollapse */\n    static Null(type, offset, length) {\n        return new Data(type, offset, length, 0);\n    }\n    /** @nocollapse */\n    static Int(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Dictionary(type, offset, length, nullCount, nullBitmap, data, dictionary) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.indices.ArrayType, data), buffer_1.toUint8Array(nullBitmap)], [], dictionary);\n    }\n    /** @nocollapse */\n    static Float(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Bool(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Decimal(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Date(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Time(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Timestamp(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Interval(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static FixedSizeBinary(type, offset, length, nullCount, nullBitmap, data) {\n        return new Data(type, offset, length, nullCount, [undefined, buffer_1.toArrayBufferView(type.ArrayType, data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Binary(type, offset, length, nullCount, nullBitmap, valueOffsets, data) {\n        return new Data(type, offset, length, nullCount, [buffer_1.toInt32Array(valueOffsets), buffer_1.toUint8Array(data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static Utf8(type, offset, length, nullCount, nullBitmap, valueOffsets, data) {\n        return new Data(type, offset, length, nullCount, [buffer_1.toInt32Array(valueOffsets), buffer_1.toUint8Array(data), buffer_1.toUint8Array(nullBitmap)]);\n    }\n    /** @nocollapse */\n    static List(type, offset, length, nullCount, nullBitmap, valueOffsets, child) {\n        return new Data(type, offset, length, nullCount, [buffer_1.toInt32Array(valueOffsets), undefined, buffer_1.toUint8Array(nullBitmap)], [child]);\n    }\n    /** @nocollapse */\n    static FixedSizeList(type, offset, length, nullCount, nullBitmap, child) {\n        return new Data(type, offset, length, nullCount, [undefined, undefined, buffer_1.toUint8Array(nullBitmap)], [child]);\n    }\n    /** @nocollapse */\n    static Struct(type, offset, length, nullCount, nullBitmap, children) {\n        return new Data(type, offset, length, nullCount, [undefined, undefined, buffer_1.toUint8Array(nullBitmap)], children);\n    }\n    /** @nocollapse */\n    static Map(type, offset, length, nullCount, nullBitmap, valueOffsets, child) {\n        return new Data(type, offset, length, nullCount, [buffer_1.toInt32Array(valueOffsets), undefined, buffer_1.toUint8Array(nullBitmap)], [child]);\n    }\n    /** @nocollapse */\n    static Union(type, offset, length, nullCount, nullBitmap, typeIds, valueOffsetsOrChildren, children) {\n        const buffers = [\n            undefined, undefined,\n            buffer_1.toUint8Array(nullBitmap),\n            buffer_1.toArrayBufferView(type.ArrayType, typeIds)\n        ];\n        if (type.mode === enum_1.UnionMode.Sparse) {\n            return new Data(type, offset, length, nullCount, buffers, valueOffsetsOrChildren);\n        }\n        buffers[enum_1.BufferType.OFFSET] = buffer_1.toInt32Array(valueOffsetsOrChildren);\n        return new Data(type, offset, length, nullCount, buffers, children);\n    }\n}\nexports.Data = Data;\nData.prototype.childData = Object.freeze([]);\n\n//# sourceMappingURL=data.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst Schema_ = require(\"./fb/Schema\");\nconst Message_ = require(\"./fb/Message\");\nexports.ArrowType = Schema_.org.apache.arrow.flatbuf.Type;\nexports.DateUnit = Schema_.org.apache.arrow.flatbuf.DateUnit;\nexports.TimeUnit = Schema_.org.apache.arrow.flatbuf.TimeUnit;\nexports.Precision = Schema_.org.apache.arrow.flatbuf.Precision;\nexports.UnionMode = Schema_.org.apache.arrow.flatbuf.UnionMode;\nexports.IntervalUnit = Schema_.org.apache.arrow.flatbuf.IntervalUnit;\nexports.MessageHeader = Message_.org.apache.arrow.flatbuf.MessageHeader;\nexports.MetadataVersion = Schema_.org.apache.arrow.flatbuf.MetadataVersion;\n/**\n * Main data type enumeration.\n *\n * Data types in this library are all *logical*. They can be expressed as\n * either a primitive physical type (bytes or bits of some fixed size), a\n * nested type consisting of other data types, or another data type (e.g. a\n * timestamp encoded as an int64).\n *\n * **Note**: Only enum values 0-17 (NONE through Map) are written to an Arrow\n * IPC payload.\n *\n * The rest of the values are specified here so TypeScript can narrow the type\n * signatures further beyond the base Arrow Types. The Arrow DataTypes include\n * metadata like `bitWidth` that impact the type signatures of the values we\n * accept and return.\n *\n * For example, the `Int8Vector` reads 1-byte numbers from an `Int8Array`, an\n * `Int32Vector` reads a 4-byte number from an `Int32Array`, and an `Int64Vector`\n * reads a pair of 4-byte lo, hi 32-bit integers as a zero-copy slice from the\n * underlying `Int32Array`.\n *\n * Library consumers benefit by knowing the narrowest type, since we can ensure\n * the types across all public methods are propagated, and never bail to `any`.\n * These values are _never_ used at runtime, and they will _never_ be written\n * to the flatbuffers metadata of serialized Arrow IPC payloads.\n */\nvar Type;\n(function (Type) {\n    /** The default placeholder type */\n    Type[Type[\"NONE\"] = 0] = \"NONE\";\n    /** A NULL type having no physical storage */\n    Type[Type[\"Null\"] = 1] = \"Null\";\n    /** Signed or unsigned 8, 16, 32, or 64-bit little-endian integer */\n    Type[Type[\"Int\"] = 2] = \"Int\";\n    /** 2, 4, or 8-byte floating point value */\n    Type[Type[\"Float\"] = 3] = \"Float\";\n    /** Variable-length bytes (no guarantee of UTF8-ness) */\n    Type[Type[\"Binary\"] = 4] = \"Binary\";\n    /** UTF8 variable-length string as List<Char> */\n    Type[Type[\"Utf8\"] = 5] = \"Utf8\";\n    /** Boolean as 1 bit, LSB bit-packed ordering */\n    Type[Type[\"Bool\"] = 6] = \"Bool\";\n    /** Precision-and-scale-based decimal type. Storage type depends on the parameters. */\n    Type[Type[\"Decimal\"] = 7] = \"Decimal\";\n    /** int32_t days or int64_t milliseconds since the UNIX epoch */\n    Type[Type[\"Date\"] = 8] = \"Date\";\n    /** Time as signed 32 or 64-bit integer, representing either seconds, milliseconds, microseconds, or nanoseconds since midnight since midnight */\n    Type[Type[\"Time\"] = 9] = \"Time\";\n    /** Exact timestamp encoded with int64 since UNIX epoch (Default unit millisecond) */\n    Type[Type[\"Timestamp\"] = 10] = \"Timestamp\";\n    /** YEAR_MONTH or DAY_TIME interval in SQL style */\n    Type[Type[\"Interval\"] = 11] = \"Interval\";\n    /** A list of some logical data type */\n    Type[Type[\"List\"] = 12] = \"List\";\n    /** Struct of logical types */\n    Type[Type[\"Struct\"] = 13] = \"Struct\";\n    /** Union of logical types */\n    Type[Type[\"Union\"] = 14] = \"Union\";\n    /** Fixed-size binary. Each value occupies the same number of bytes */\n    Type[Type[\"FixedSizeBinary\"] = 15] = \"FixedSizeBinary\";\n    /** Fixed-size list. Each value occupies the same number of bytes */\n    Type[Type[\"FixedSizeList\"] = 16] = \"FixedSizeList\";\n    /** Map of named logical types */\n    Type[Type[\"Map\"] = 17] = \"Map\";\n    /** Dictionary aka Category type */\n    Type[Type[\"Dictionary\"] = -1] = \"Dictionary\";\n    Type[Type[\"Int8\"] = -2] = \"Int8\";\n    Type[Type[\"Int16\"] = -3] = \"Int16\";\n    Type[Type[\"Int32\"] = -4] = \"Int32\";\n    Type[Type[\"Int64\"] = -5] = \"Int64\";\n    Type[Type[\"Uint8\"] = -6] = \"Uint8\";\n    Type[Type[\"Uint16\"] = -7] = \"Uint16\";\n    Type[Type[\"Uint32\"] = -8] = \"Uint32\";\n    Type[Type[\"Uint64\"] = -9] = \"Uint64\";\n    Type[Type[\"Float16\"] = -10] = \"Float16\";\n    Type[Type[\"Float32\"] = -11] = \"Float32\";\n    Type[Type[\"Float64\"] = -12] = \"Float64\";\n    Type[Type[\"DateDay\"] = -13] = \"DateDay\";\n    Type[Type[\"DateMillisecond\"] = -14] = \"DateMillisecond\";\n    Type[Type[\"TimestampSecond\"] = -15] = \"TimestampSecond\";\n    Type[Type[\"TimestampMillisecond\"] = -16] = \"TimestampMillisecond\";\n    Type[Type[\"TimestampMicrosecond\"] = -17] = \"TimestampMicrosecond\";\n    Type[Type[\"TimestampNanosecond\"] = -18] = \"TimestampNanosecond\";\n    Type[Type[\"TimeSecond\"] = -19] = \"TimeSecond\";\n    Type[Type[\"TimeMillisecond\"] = -20] = \"TimeMillisecond\";\n    Type[Type[\"TimeMicrosecond\"] = -21] = \"TimeMicrosecond\";\n    Type[Type[\"TimeNanosecond\"] = -22] = \"TimeNanosecond\";\n    Type[Type[\"DenseUnion\"] = -23] = \"DenseUnion\";\n    Type[Type[\"SparseUnion\"] = -24] = \"SparseUnion\";\n    Type[Type[\"IntervalDayTime\"] = -25] = \"IntervalDayTime\";\n    Type[Type[\"IntervalYearMonth\"] = -26] = \"IntervalYearMonth\";\n})(Type = exports.Type || (exports.Type = {}));\nvar BufferType;\n(function (BufferType) {\n    /**\n     * used in List type, Dense Union and variable length primitive types (String, Binary)\n     */\n    BufferType[BufferType[\"OFFSET\"] = 0] = \"OFFSET\";\n    /**\n     * actual data, either wixed width primitive types in slots or variable width delimited by an OFFSET vector\n     */\n    BufferType[BufferType[\"DATA\"] = 1] = \"DATA\";\n    /**\n     * Bit vector indicating if each value is null\n     */\n    BufferType[BufferType[\"VALIDITY\"] = 2] = \"VALIDITY\";\n    /**\n     * Type vector used in Union type\n     */\n    BufferType[BufferType[\"TYPE\"] = 3] = \"TYPE\";\n})(BufferType = exports.BufferType || (exports.BufferType = {}));\n\n//# sourceMappingURL=enum.js.map\n","\"use strict\";\n// automatically generated by the FlatBuffers compiler, do not modify\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst NS7624605610262437867 = require(\"./Schema\");\n/**\n * ----------------------------------------------------------------------\n * Arrow File metadata\n *\n *\n * @constructor\n */\nvar org;\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Footer {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Footer\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Footer= obj\n                     * @returns Footer\n                     */\n                    static getRootAsFooter(bb, obj) {\n                        return (obj || new Footer).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.MetadataVersion\n                     */\n                    version() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : NS7624605610262437867.org.apache.arrow.flatbuf.MetadataVersion.V1;\n                    }\n                    /**\n                     * @param org.apache.arrow.flatbuf.Schema= obj\n                     * @returns org.apache.arrow.flatbuf.Schema|null\n                     */\n                    schema(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? (obj || new NS7624605610262437867.org.apache.arrow.flatbuf.Schema).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n                    }\n                    /**\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.Block= obj\n                     * @returns org.apache.arrow.flatbuf.Block\n                     */\n                    dictionaries(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.Block).__init(this.bb.__vector(this.bb_pos + offset) + index * 24, this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    dictionariesLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.Block= obj\n                     * @returns org.apache.arrow.flatbuf.Block\n                     */\n                    recordBatches(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 10);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.Block).__init(this.bb.__vector(this.bb_pos + offset) + index * 24, this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    recordBatchesLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 10);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startFooter(builder) {\n                        builder.startObject(4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.MetadataVersion version\n                     */\n                    static addVersion(builder, version) {\n                        builder.addFieldInt16(0, version, NS7624605610262437867.org.apache.arrow.flatbuf.MetadataVersion.V1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset schemaOffset\n                     */\n                    static addSchema(builder, schemaOffset) {\n                        builder.addFieldOffset(1, schemaOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset dictionariesOffset\n                     */\n                    static addDictionaries(builder, dictionariesOffset) {\n                        builder.addFieldOffset(2, dictionariesOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startDictionariesVector(builder, numElems) {\n                        builder.startVector(24, numElems, 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset recordBatchesOffset\n                     */\n                    static addRecordBatches(builder, recordBatchesOffset) {\n                        builder.addFieldOffset(3, recordBatchesOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startRecordBatchesVector(builder, numElems) {\n                        builder.startVector(24, numElems, 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endFooter(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset offset\n                     */\n                    static finishFooterBuffer(builder, offset) {\n                        builder.finish(offset);\n                    }\n                    static createFooter(builder, version, schemaOffset, dictionariesOffset, recordBatchesOffset) {\n                        Footer.startFooter(builder);\n                        Footer.addVersion(builder, version);\n                        Footer.addSchema(builder, schemaOffset);\n                        Footer.addDictionaries(builder, dictionariesOffset);\n                        Footer.addRecordBatches(builder, recordBatchesOffset);\n                        return Footer.endFooter(builder);\n                    }\n                }\n                flatbuf.Footer = Footer;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Block {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Block\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * Index to the start of the RecordBlock (note this is past the Message header)\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    offset() {\n                        return this.bb.readInt64(this.bb_pos);\n                    }\n                    /**\n                     * Length of the metadata\n                     *\n                     * @returns number\n                     */\n                    metaDataLength() {\n                        return this.bb.readInt32(this.bb_pos + 8);\n                    }\n                    /**\n                     * Length of the data (this is aligned so there can be a gap between this and\n                     * the metatdata).\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    bodyLength() {\n                        return this.bb.readInt64(this.bb_pos + 16);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long offset\n                     * @param number metaDataLength\n                     * @param flatbuffers.Long bodyLength\n                     * @returns flatbuffers.Offset\n                     */\n                    static createBlock(builder, offset, metaDataLength, bodyLength) {\n                        builder.prep(8, 24);\n                        builder.writeInt64(bodyLength);\n                        builder.pad(4);\n                        builder.writeInt32(metaDataLength);\n                        builder.writeInt64(offset);\n                        return builder.offset();\n                    }\n                }\n                flatbuf.Block = Block;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n\n//# sourceMappingURL=File.js.map\n","\"use strict\";\n// automatically generated by the FlatBuffers compiler, do not modify\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst NS7624605610262437867 = require(\"./Schema\");\nvar org;\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                flatbuf.Schema = NS7624605610262437867.org.apache.arrow.flatbuf.Schema;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * The root Message type\n * This union enables us to easily send different message types without\n * redundant storage, and in the future we can easily add new message types.\n *\n * Arrow implementations do not need to implement all of the message types,\n * which may include experimental metadata types. For maximum compatibility,\n * it is best to send data using RecordBatch\n *\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let MessageHeader;\n                (function (MessageHeader) {\n                    MessageHeader[MessageHeader[\"NONE\"] = 0] = \"NONE\";\n                    MessageHeader[MessageHeader[\"Schema\"] = 1] = \"Schema\";\n                    MessageHeader[MessageHeader[\"DictionaryBatch\"] = 2] = \"DictionaryBatch\";\n                    MessageHeader[MessageHeader[\"RecordBatch\"] = 3] = \"RecordBatch\";\n                    MessageHeader[MessageHeader[\"Tensor\"] = 4] = \"Tensor\";\n                    MessageHeader[MessageHeader[\"SparseTensor\"] = 5] = \"SparseTensor\";\n                })(MessageHeader = flatbuf.MessageHeader || (flatbuf.MessageHeader = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * Data structures for describing a table row batch (a collection of\n * equal-length Arrow arrays)\n * Metadata about a field at some level of a nested type tree (but not\n * its children).\n *\n * For example, a List<Int16> with values [[1, 2, 3], null, [4], [5, 6], null]\n * would have {length: 5, null_count: 2} for its List node, and {length: 6,\n * null_count: 0} for its Int16 node, as separate FieldNode structs\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class FieldNode {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns FieldNode\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * The number of value slots in the Arrow array at this level of a nested\n                     * tree\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    length() {\n                        return this.bb.readInt64(this.bb_pos);\n                    }\n                    /**\n                     * The number of observed nulls. Fields with null_count == 0 may choose not\n                     * to write their physical validity bitmap out as a materialized buffer,\n                     * instead setting the length of the bitmap buffer to 0.\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    nullCount() {\n                        return this.bb.readInt64(this.bb_pos + 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long length\n                     * @param flatbuffers.Long null_count\n                     * @returns flatbuffers.Offset\n                     */\n                    static createFieldNode(builder, length, null_count) {\n                        builder.prep(8, 16);\n                        builder.writeInt64(null_count);\n                        builder.writeInt64(length);\n                        return builder.offset();\n                    }\n                }\n                flatbuf.FieldNode = FieldNode;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * A data header describing the shared memory layout of a \"record\" or \"row\"\n * batch. Some systems call this a \"row batch\" internally and others a \"record\n * batch\".\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class RecordBatch {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns RecordBatch\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param RecordBatch= obj\n                     * @returns RecordBatch\n                     */\n                    static getRootAsRecordBatch(bb, obj) {\n                        return (obj || new RecordBatch).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * number of records / rows. The arrays in the batch should all have this\n                     * length\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    length() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt64(this.bb_pos + offset) : this.bb.createLong(0, 0);\n                    }\n                    /**\n                     * Nodes correspond to the pre-ordered flattened logical schema\n                     *\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.FieldNode= obj\n                     * @returns org.apache.arrow.flatbuf.FieldNode\n                     */\n                    nodes(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.FieldNode).__init(this.bb.__vector(this.bb_pos + offset) + index * 16, this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    nodesLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * Buffers correspond to the pre-ordered flattened buffer tree\n                     *\n                     * The number of buffers appended to this list depends on the schema. For\n                     * example, most primitive arrays will have 2 buffers, 1 for the validity\n                     * bitmap and 1 for the values. For struct arrays, there will only be a\n                     * single buffer for the validity (nulls) bitmap\n                     *\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.Buffer= obj\n                     * @returns org.apache.arrow.flatbuf.Buffer\n                     */\n                    buffers(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? (obj || new NS7624605610262437867.org.apache.arrow.flatbuf.Buffer).__init(this.bb.__vector(this.bb_pos + offset) + index * 16, this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    buffersLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startRecordBatch(builder) {\n                        builder.startObject(3);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long length\n                     */\n                    static addLength(builder, length) {\n                        builder.addFieldInt64(0, length, builder.createLong(0, 0));\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset nodesOffset\n                     */\n                    static addNodes(builder, nodesOffset) {\n                        builder.addFieldOffset(1, nodesOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startNodesVector(builder, numElems) {\n                        builder.startVector(16, numElems, 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset buffersOffset\n                     */\n                    static addBuffers(builder, buffersOffset) {\n                        builder.addFieldOffset(2, buffersOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startBuffersVector(builder, numElems) {\n                        builder.startVector(16, numElems, 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endRecordBatch(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createRecordBatch(builder, length, nodesOffset, buffersOffset) {\n                        RecordBatch.startRecordBatch(builder);\n                        RecordBatch.addLength(builder, length);\n                        RecordBatch.addNodes(builder, nodesOffset);\n                        RecordBatch.addBuffers(builder, buffersOffset);\n                        return RecordBatch.endRecordBatch(builder);\n                    }\n                }\n                flatbuf.RecordBatch = RecordBatch;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * For sending dictionary encoding information. Any Field can be\n * dictionary-encoded, but in this case none of its children may be\n * dictionary-encoded.\n * There is one vector / column per dictionary, but that vector / column\n * may be spread across multiple dictionary batches by using the isDelta\n * flag\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class DictionaryBatch {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns DictionaryBatch\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param DictionaryBatch= obj\n                     * @returns DictionaryBatch\n                     */\n                    static getRootAsDictionaryBatch(bb, obj) {\n                        return (obj || new DictionaryBatch).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns flatbuffers.Long\n                     */\n                    id() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt64(this.bb_pos + offset) : this.bb.createLong(0, 0);\n                    }\n                    /**\n                     * @param org.apache.arrow.flatbuf.RecordBatch= obj\n                     * @returns org.apache.arrow.flatbuf.RecordBatch|null\n                     */\n                    data(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.RecordBatch).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n                    }\n                    /**\n                     * If isDelta is true the values in the dictionary are to be appended to a\n                     * dictionary with the indicated id\n                     *\n                     * @returns boolean\n                     */\n                    isDelta() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startDictionaryBatch(builder) {\n                        builder.startObject(3);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long id\n                     */\n                    static addId(builder, id) {\n                        builder.addFieldInt64(0, id, builder.createLong(0, 0));\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset dataOffset\n                     */\n                    static addData(builder, dataOffset) {\n                        builder.addFieldOffset(1, dataOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param boolean isDelta\n                     */\n                    static addIsDelta(builder, isDelta) {\n                        builder.addFieldInt8(2, +isDelta, +false);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endDictionaryBatch(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createDictionaryBatch(builder, id, dataOffset, isDelta) {\n                        DictionaryBatch.startDictionaryBatch(builder);\n                        DictionaryBatch.addId(builder, id);\n                        DictionaryBatch.addData(builder, dataOffset);\n                        DictionaryBatch.addIsDelta(builder, isDelta);\n                        return DictionaryBatch.endDictionaryBatch(builder);\n                    }\n                }\n                flatbuf.DictionaryBatch = DictionaryBatch;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Message {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Message\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Message= obj\n                     * @returns Message\n                     */\n                    static getRootAsMessage(bb, obj) {\n                        return (obj || new Message).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.MetadataVersion\n                     */\n                    version() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : NS7624605610262437867.org.apache.arrow.flatbuf.MetadataVersion.V1;\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.MessageHeader\n                     */\n                    headerType() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? /**  */ (this.bb.readUint8(this.bb_pos + offset)) : org.apache.arrow.flatbuf.MessageHeader.NONE;\n                    }\n                    /**\n                     * @param flatbuffers.Table obj\n                     * @returns ?flatbuffers.Table\n                     */\n                    header(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? this.bb.__union(obj, this.bb_pos + offset) : null;\n                    }\n                    /**\n                     * @returns flatbuffers.Long\n                     */\n                    bodyLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 10);\n                        return offset ? this.bb.readInt64(this.bb_pos + offset) : this.bb.createLong(0, 0);\n                    }\n                    /**\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.KeyValue= obj\n                     * @returns org.apache.arrow.flatbuf.KeyValue\n                     */\n                    customMetadata(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 12);\n                        return offset ? (obj || new NS7624605610262437867.org.apache.arrow.flatbuf.KeyValue).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + offset) + index * 4), this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    customMetadataLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 12);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startMessage(builder) {\n                        builder.startObject(5);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.MetadataVersion version\n                     */\n                    static addVersion(builder, version) {\n                        builder.addFieldInt16(0, version, NS7624605610262437867.org.apache.arrow.flatbuf.MetadataVersion.V1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.MessageHeader headerType\n                     */\n                    static addHeaderType(builder, headerType) {\n                        builder.addFieldInt8(1, headerType, org.apache.arrow.flatbuf.MessageHeader.NONE);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset headerOffset\n                     */\n                    static addHeader(builder, headerOffset) {\n                        builder.addFieldOffset(2, headerOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long bodyLength\n                     */\n                    static addBodyLength(builder, bodyLength) {\n                        builder.addFieldInt64(3, bodyLength, builder.createLong(0, 0));\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset customMetadataOffset\n                     */\n                    static addCustomMetadata(builder, customMetadataOffset) {\n                        builder.addFieldOffset(4, customMetadataOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<flatbuffers.Offset> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createCustomMetadataVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addOffset(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startCustomMetadataVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endMessage(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset offset\n                     */\n                    static finishMessageBuffer(builder, offset) {\n                        builder.finish(offset);\n                    }\n                    static createMessage(builder, version, headerType, headerOffset, bodyLength, customMetadataOffset) {\n                        Message.startMessage(builder);\n                        Message.addVersion(builder, version);\n                        Message.addHeaderType(builder, headerType);\n                        Message.addHeader(builder, headerOffset);\n                        Message.addBodyLength(builder, bodyLength);\n                        Message.addCustomMetadata(builder, customMetadataOffset);\n                        return Message.endMessage(builder);\n                    }\n                }\n                flatbuf.Message = Message;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n\n//# sourceMappingURL=Message.js.map\n","\"use strict\";\n/* tslint:disable:class-name */\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * @enum {number}\n */\nvar org;\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let MetadataVersion;\n                (function (MetadataVersion) {\n                    /**\n                     * 0.1.0\n                     */\n                    MetadataVersion[MetadataVersion[\"V1\"] = 0] = \"V1\";\n                    /**\n                     * 0.2.0\n                     */\n                    MetadataVersion[MetadataVersion[\"V2\"] = 1] = \"V2\";\n                    /**\n                     * 0.3.0 -> 0.7.1\n                     */\n                    MetadataVersion[MetadataVersion[\"V3\"] = 2] = \"V3\";\n                    /**\n                     * >= 0.8.0\n                     */\n                    MetadataVersion[MetadataVersion[\"V4\"] = 3] = \"V4\";\n                })(MetadataVersion = flatbuf.MetadataVersion || (flatbuf.MetadataVersion = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let UnionMode;\n                (function (UnionMode) {\n                    UnionMode[UnionMode[\"Sparse\"] = 0] = \"Sparse\";\n                    UnionMode[UnionMode[\"Dense\"] = 1] = \"Dense\";\n                })(UnionMode = flatbuf.UnionMode || (flatbuf.UnionMode = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let Precision;\n                (function (Precision) {\n                    Precision[Precision[\"HALF\"] = 0] = \"HALF\";\n                    Precision[Precision[\"SINGLE\"] = 1] = \"SINGLE\";\n                    Precision[Precision[\"DOUBLE\"] = 2] = \"DOUBLE\";\n                })(Precision = flatbuf.Precision || (flatbuf.Precision = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let DateUnit;\n                (function (DateUnit) {\n                    DateUnit[DateUnit[\"DAY\"] = 0] = \"DAY\";\n                    DateUnit[DateUnit[\"MILLISECOND\"] = 1] = \"MILLISECOND\";\n                })(DateUnit = flatbuf.DateUnit || (flatbuf.DateUnit = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let TimeUnit;\n                (function (TimeUnit) {\n                    TimeUnit[TimeUnit[\"SECOND\"] = 0] = \"SECOND\";\n                    TimeUnit[TimeUnit[\"MILLISECOND\"] = 1] = \"MILLISECOND\";\n                    TimeUnit[TimeUnit[\"MICROSECOND\"] = 2] = \"MICROSECOND\";\n                    TimeUnit[TimeUnit[\"NANOSECOND\"] = 3] = \"NANOSECOND\";\n                })(TimeUnit = flatbuf.TimeUnit || (flatbuf.TimeUnit = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let IntervalUnit;\n                (function (IntervalUnit) {\n                    IntervalUnit[IntervalUnit[\"YEAR_MONTH\"] = 0] = \"YEAR_MONTH\";\n                    IntervalUnit[IntervalUnit[\"DAY_TIME\"] = 1] = \"DAY_TIME\";\n                })(IntervalUnit = flatbuf.IntervalUnit || (flatbuf.IntervalUnit = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * Top-level Type value, enabling extensible type-specific metadata. We can\n * add new logical types to Type without breaking backwards compatibility\n *\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let Type;\n                (function (Type) {\n                    Type[Type[\"NONE\"] = 0] = \"NONE\";\n                    Type[Type[\"Null\"] = 1] = \"Null\";\n                    Type[Type[\"Int\"] = 2] = \"Int\";\n                    Type[Type[\"FloatingPoint\"] = 3] = \"FloatingPoint\";\n                    Type[Type[\"Binary\"] = 4] = \"Binary\";\n                    Type[Type[\"Utf8\"] = 5] = \"Utf8\";\n                    Type[Type[\"Bool\"] = 6] = \"Bool\";\n                    Type[Type[\"Decimal\"] = 7] = \"Decimal\";\n                    Type[Type[\"Date\"] = 8] = \"Date\";\n                    Type[Type[\"Time\"] = 9] = \"Time\";\n                    Type[Type[\"Timestamp\"] = 10] = \"Timestamp\";\n                    Type[Type[\"Interval\"] = 11] = \"Interval\";\n                    Type[Type[\"List\"] = 12] = \"List\";\n                    Type[Type[\"Struct_\"] = 13] = \"Struct_\";\n                    Type[Type[\"Union\"] = 14] = \"Union\";\n                    Type[Type[\"FixedSizeBinary\"] = 15] = \"FixedSizeBinary\";\n                    Type[Type[\"FixedSizeList\"] = 16] = \"FixedSizeList\";\n                    Type[Type[\"Map\"] = 17] = \"Map\";\n                    Type[Type[\"Duration\"] = 18] = \"Duration\";\n                    Type[Type[\"LargeBinary\"] = 19] = \"LargeBinary\";\n                    Type[Type[\"LargeUtf8\"] = 20] = \"LargeUtf8\";\n                    Type[Type[\"LargeList\"] = 21] = \"LargeList\";\n                })(Type = flatbuf.Type || (flatbuf.Type = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * Endianness of the platform producing the data\n *\n * @enum {number}\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                let Endianness;\n                (function (Endianness) {\n                    Endianness[Endianness[\"Little\"] = 0] = \"Little\";\n                    Endianness[Endianness[\"Big\"] = 1] = \"Big\";\n                })(Endianness = flatbuf.Endianness || (flatbuf.Endianness = {}));\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * These are stored in the flatbuffer in the Type union below\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Null {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Null\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Null= obj\n                     * @returns Null\n                     */\n                    static getRootAsNull(bb, obj) {\n                        return (obj || new Null).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startNull(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endNull(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createNull(builder) {\n                        Null.startNull(builder);\n                        return Null.endNull(builder);\n                    }\n                }\n                flatbuf.Null = Null;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * A Struct_ in the flatbuffer metadata is the same as an Arrow Struct\n * (according to the physical memory layout). We used Struct_ here as\n * Struct is a reserved word in Flatbuffers\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Struct_ {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Struct_\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Struct_= obj\n                     * @returns Struct_\n                     */\n                    static getRootAsStruct_(bb, obj) {\n                        return (obj || new Struct_).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startStruct_(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endStruct_(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createStruct_(builder) {\n                        Struct_.startStruct_(builder);\n                        return Struct_.endStruct_(builder);\n                    }\n                }\n                flatbuf.Struct_ = Struct_;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class List {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns List\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param List= obj\n                     * @returns List\n                     */\n                    static getRootAsList(bb, obj) {\n                        return (obj || new List).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startList(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endList(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createList(builder) {\n                        List.startList(builder);\n                        return List.endList(builder);\n                    }\n                }\n                flatbuf.List = List;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Same as List, but with 64-bit offsets, allowing to represent\n * extremely large data values.\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class LargeList {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns LargeList\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param LargeList= obj\n                     * @returns LargeList\n                     */\n                    static getRootAsLargeList(bb, obj) {\n                        return (obj || new LargeList).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startLargeList(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endLargeList(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createLargeList(builder) {\n                        LargeList.startLargeList(builder);\n                        return LargeList.endLargeList(builder);\n                    }\n                }\n                flatbuf.LargeList = LargeList;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class FixedSizeList {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns FixedSizeList\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param FixedSizeList= obj\n                     * @returns FixedSizeList\n                     */\n                    static getRootAsFixedSizeList(bb, obj) {\n                        return (obj || new FixedSizeList).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * Number of list items per value\n                     *\n                     * @returns number\n                     */\n                    listSize() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startFixedSizeList(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number listSize\n                     */\n                    static addListSize(builder, listSize) {\n                        builder.addFieldInt32(0, listSize, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endFixedSizeList(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createFixedSizeList(builder, listSize) {\n                        FixedSizeList.startFixedSizeList(builder);\n                        FixedSizeList.addListSize(builder, listSize);\n                        return FixedSizeList.endFixedSizeList(builder);\n                    }\n                }\n                flatbuf.FixedSizeList = FixedSizeList;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * A Map is a logical nested type that is represented as\n *\n * List<entry: Struct<key: K, value: V>>\n *\n * In this layout, the keys and values are each respectively contiguous. We do\n * not constrain the key and value types, so the application is responsible\n * for ensuring that the keys are hashable and unique. Whether the keys are sorted\n * may be set in the metadata for this field\n *\n * In a Field with Map type, the Field has a child Struct field, which then\n * has two children: key type and the second the value type. The names of the\n * child fields may be respectively \"entry\", \"key\", and \"value\", but this is\n * not enforced\n *\n * Map\n *   - child[0] entry: Struct\n *     - child[0] key: K\n *     - child[1] value: V\n *\n * Neither the \"entry\" field nor the \"key\" field may be nullable.\n *\n * The metadata is structured so that Arrow systems without special handling\n * for Map can make Map an alias for List. The \"layout\" attribute for the Map\n * field must have the same contents as a List.\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Map {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Map\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Map= obj\n                     * @returns Map\n                     */\n                    static getRootAsMap(bb, obj) {\n                        return (obj || new Map).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * Set to true if the keys within each value are sorted\n                     *\n                     * @returns boolean\n                     */\n                    keysSorted() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startMap(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param boolean keysSorted\n                     */\n                    static addKeysSorted(builder, keysSorted) {\n                        builder.addFieldInt8(0, +keysSorted, +false);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endMap(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createMap(builder, keysSorted) {\n                        Map.startMap(builder);\n                        Map.addKeysSorted(builder, keysSorted);\n                        return Map.endMap(builder);\n                    }\n                }\n                flatbuf.Map = Map;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * A union is a complex type with children in Field\n * By default ids in the type vector refer to the offsets in the children\n * optionally typeIds provides an indirection between the child offset and the type id\n * for each child typeIds[offset] is the id used in the type vector\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Union {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Union\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Union= obj\n                     * @returns Union\n                     */\n                    static getRootAsUnion(bb, obj) {\n                        return (obj || new Union).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.UnionMode\n                     */\n                    mode() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.UnionMode.Sparse;\n                    }\n                    /**\n                     * @param number index\n                     * @returns number\n                     */\n                    typeIds(index) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.readInt32(this.bb.__vector(this.bb_pos + offset) + index * 4) : 0;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    typeIdsLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @returns Int32Array\n                     */\n                    typeIdsArray() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? new Int32Array(this.bb.bytes().buffer, this.bb.bytes().byteOffset + this.bb.__vector(this.bb_pos + offset), this.bb.__vector_len(this.bb_pos + offset)) : null;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startUnion(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.UnionMode mode\n                     */\n                    static addMode(builder, mode) {\n                        builder.addFieldInt16(0, mode, org.apache.arrow.flatbuf.UnionMode.Sparse);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset typeIdsOffset\n                     */\n                    static addTypeIds(builder, typeIdsOffset) {\n                        builder.addFieldOffset(1, typeIdsOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<number> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createTypeIdsVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addInt32(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startTypeIdsVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endUnion(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createUnion(builder, mode, typeIdsOffset) {\n                        Union.startUnion(builder);\n                        Union.addMode(builder, mode);\n                        Union.addTypeIds(builder, typeIdsOffset);\n                        return Union.endUnion(builder);\n                    }\n                }\n                flatbuf.Union = Union;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Int {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Int\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Int= obj\n                     * @returns Int\n                     */\n                    static getRootAsInt(bb, obj) {\n                        return (obj || new Int).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns number\n                     */\n                    bitWidth() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @returns boolean\n                     */\n                    isSigned() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startInt(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number bitWidth\n                     */\n                    static addBitWidth(builder, bitWidth) {\n                        builder.addFieldInt32(0, bitWidth, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param boolean isSigned\n                     */\n                    static addIsSigned(builder, isSigned) {\n                        builder.addFieldInt8(1, +isSigned, +false);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endInt(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createInt(builder, bitWidth, isSigned) {\n                        Int.startInt(builder);\n                        Int.addBitWidth(builder, bitWidth);\n                        Int.addIsSigned(builder, isSigned);\n                        return Int.endInt(builder);\n                    }\n                }\n                flatbuf.Int = Int;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class FloatingPoint {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns FloatingPoint\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param FloatingPoint= obj\n                     * @returns FloatingPoint\n                     */\n                    static getRootAsFloatingPoint(bb, obj) {\n                        return (obj || new FloatingPoint).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.Precision\n                     */\n                    precision() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.Precision.HALF;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startFloatingPoint(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.Precision precision\n                     */\n                    static addPrecision(builder, precision) {\n                        builder.addFieldInt16(0, precision, org.apache.arrow.flatbuf.Precision.HALF);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endFloatingPoint(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createFloatingPoint(builder, precision) {\n                        FloatingPoint.startFloatingPoint(builder);\n                        FloatingPoint.addPrecision(builder, precision);\n                        return FloatingPoint.endFloatingPoint(builder);\n                    }\n                }\n                flatbuf.FloatingPoint = FloatingPoint;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Unicode with UTF-8 encoding\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Utf8 {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Utf8\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Utf8= obj\n                     * @returns Utf8\n                     */\n                    static getRootAsUtf8(bb, obj) {\n                        return (obj || new Utf8).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startUtf8(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endUtf8(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createUtf8(builder) {\n                        Utf8.startUtf8(builder);\n                        return Utf8.endUtf8(builder);\n                    }\n                }\n                flatbuf.Utf8 = Utf8;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Opaque binary data\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Binary {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Binary\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Binary= obj\n                     * @returns Binary\n                     */\n                    static getRootAsBinary(bb, obj) {\n                        return (obj || new Binary).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startBinary(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endBinary(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createBinary(builder) {\n                        Binary.startBinary(builder);\n                        return Binary.endBinary(builder);\n                    }\n                }\n                flatbuf.Binary = Binary;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Same as Utf8, but with 64-bit offsets, allowing to represent\n * extremely large data values.\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class LargeUtf8 {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns LargeUtf8\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param LargeUtf8= obj\n                     * @returns LargeUtf8\n                     */\n                    static getRootAsLargeUtf8(bb, obj) {\n                        return (obj || new LargeUtf8).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startLargeUtf8(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endLargeUtf8(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createLargeUtf8(builder) {\n                        LargeUtf8.startLargeUtf8(builder);\n                        return LargeUtf8.endLargeUtf8(builder);\n                    }\n                }\n                flatbuf.LargeUtf8 = LargeUtf8;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Same as Binary, but with 64-bit offsets, allowing to represent\n * extremely large data values.\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class LargeBinary {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns LargeBinary\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param LargeBinary= obj\n                     * @returns LargeBinary\n                     */\n                    static getRootAsLargeBinary(bb, obj) {\n                        return (obj || new LargeBinary).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startLargeBinary(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endLargeBinary(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createLargeBinary(builder) {\n                        LargeBinary.startLargeBinary(builder);\n                        return LargeBinary.endLargeBinary(builder);\n                    }\n                }\n                flatbuf.LargeBinary = LargeBinary;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class FixedSizeBinary {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns FixedSizeBinary\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param FixedSizeBinary= obj\n                     * @returns FixedSizeBinary\n                     */\n                    static getRootAsFixedSizeBinary(bb, obj) {\n                        return (obj || new FixedSizeBinary).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * Number of bytes per value\n                     *\n                     * @returns number\n                     */\n                    byteWidth() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startFixedSizeBinary(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number byteWidth\n                     */\n                    static addByteWidth(builder, byteWidth) {\n                        builder.addFieldInt32(0, byteWidth, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endFixedSizeBinary(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createFixedSizeBinary(builder, byteWidth) {\n                        FixedSizeBinary.startFixedSizeBinary(builder);\n                        FixedSizeBinary.addByteWidth(builder, byteWidth);\n                        return FixedSizeBinary.endFixedSizeBinary(builder);\n                    }\n                }\n                flatbuf.FixedSizeBinary = FixedSizeBinary;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Bool {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Bool\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Bool= obj\n                     * @returns Bool\n                     */\n                    static getRootAsBool(bb, obj) {\n                        return (obj || new Bool).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startBool(builder) {\n                        builder.startObject(0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endBool(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createBool(builder) {\n                        Bool.startBool(builder);\n                        return Bool.endBool(builder);\n                    }\n                }\n                flatbuf.Bool = Bool;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Decimal {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Decimal\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Decimal= obj\n                     * @returns Decimal\n                     */\n                    static getRootAsDecimal(bb, obj) {\n                        return (obj || new Decimal).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * Total number of decimal digits\n                     *\n                     * @returns number\n                     */\n                    precision() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * Number of digits after the decimal point \".\"\n                     *\n                     * @returns number\n                     */\n                    scale() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startDecimal(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number precision\n                     */\n                    static addPrecision(builder, precision) {\n                        builder.addFieldInt32(0, precision, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number scale\n                     */\n                    static addScale(builder, scale) {\n                        builder.addFieldInt32(1, scale, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endDecimal(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createDecimal(builder, precision, scale) {\n                        Decimal.startDecimal(builder);\n                        Decimal.addPrecision(builder, precision);\n                        Decimal.addScale(builder, scale);\n                        return Decimal.endDecimal(builder);\n                    }\n                }\n                flatbuf.Decimal = Decimal;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Date is either a 32-bit or 64-bit type representing elapsed time since UNIX\n * epoch (1970-01-01), stored in either of two units:\n *\n * * Milliseconds (64 bits) indicating UNIX time elapsed since the epoch (no\n *   leap seconds), where the values are evenly divisible by 86400000\n * * Days (32 bits) since the UNIX epoch\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Date {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Date\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Date= obj\n                     * @returns Date\n                     */\n                    static getRootAsDate(bb, obj) {\n                        return (obj || new Date).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.DateUnit\n                     */\n                    unit() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.DateUnit.MILLISECOND;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startDate(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.DateUnit unit\n                     */\n                    static addUnit(builder, unit) {\n                        builder.addFieldInt16(0, unit, org.apache.arrow.flatbuf.DateUnit.MILLISECOND);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endDate(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createDate(builder, unit) {\n                        Date.startDate(builder);\n                        Date.addUnit(builder, unit);\n                        return Date.endDate(builder);\n                    }\n                }\n                flatbuf.Date = Date;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Time type. The physical storage type depends on the unit\n * - SECOND and MILLISECOND: 32 bits\n * - MICROSECOND and NANOSECOND: 64 bits\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Time {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Time\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Time= obj\n                     * @returns Time\n                     */\n                    static getRootAsTime(bb, obj) {\n                        return (obj || new Time).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.TimeUnit\n                     */\n                    unit() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.TimeUnit.MILLISECOND;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    bitWidth() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.readInt32(this.bb_pos + offset) : 32;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startTime(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.TimeUnit unit\n                     */\n                    static addUnit(builder, unit) {\n                        builder.addFieldInt16(0, unit, org.apache.arrow.flatbuf.TimeUnit.MILLISECOND);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number bitWidth\n                     */\n                    static addBitWidth(builder, bitWidth) {\n                        builder.addFieldInt32(1, bitWidth, 32);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endTime(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createTime(builder, unit, bitWidth) {\n                        Time.startTime(builder);\n                        Time.addUnit(builder, unit);\n                        Time.addBitWidth(builder, bitWidth);\n                        return Time.endTime(builder);\n                    }\n                }\n                flatbuf.Time = Time;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * Time elapsed from the Unix epoch, 00:00:00.000 on 1 January 1970, excluding\n * leap seconds, as a 64-bit integer. Note that UNIX time does not include\n * leap seconds.\n *\n * The Timestamp metadata supports both \"time zone naive\" and \"time zone\n * aware\" timestamps. Read about the timezone attribute for more detail\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Timestamp {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Timestamp\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Timestamp= obj\n                     * @returns Timestamp\n                     */\n                    static getRootAsTimestamp(bb, obj) {\n                        return (obj || new Timestamp).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.TimeUnit\n                     */\n                    unit() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.TimeUnit.SECOND;\n                    }\n                    timezone(optionalEncoding) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.__string(this.bb_pos + offset, optionalEncoding) : null;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startTimestamp(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.TimeUnit unit\n                     */\n                    static addUnit(builder, unit) {\n                        builder.addFieldInt16(0, unit, org.apache.arrow.flatbuf.TimeUnit.SECOND);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset timezoneOffset\n                     */\n                    static addTimezone(builder, timezoneOffset) {\n                        builder.addFieldOffset(1, timezoneOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endTimestamp(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createTimestamp(builder, unit, timezoneOffset) {\n                        Timestamp.startTimestamp(builder);\n                        Timestamp.addUnit(builder, unit);\n                        Timestamp.addTimezone(builder, timezoneOffset);\n                        return Timestamp.endTimestamp(builder);\n                    }\n                }\n                flatbuf.Timestamp = Timestamp;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Interval {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Interval\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Interval= obj\n                     * @returns Interval\n                     */\n                    static getRootAsInterval(bb, obj) {\n                        return (obj || new Interval).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.IntervalUnit\n                     */\n                    unit() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.IntervalUnit.YEAR_MONTH;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startInterval(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.IntervalUnit unit\n                     */\n                    static addUnit(builder, unit) {\n                        builder.addFieldInt16(0, unit, org.apache.arrow.flatbuf.IntervalUnit.YEAR_MONTH);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endInterval(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createInterval(builder, unit) {\n                        Interval.startInterval(builder);\n                        Interval.addUnit(builder, unit);\n                        return Interval.endInterval(builder);\n                    }\n                }\n                flatbuf.Interval = Interval;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Duration {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Duration\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Duration= obj\n                     * @returns Duration\n                     */\n                    static getRootAsDuration(bb, obj) {\n                        return (obj || new Duration).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.TimeUnit\n                     */\n                    unit() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.TimeUnit.MILLISECOND;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startDuration(builder) {\n                        builder.startObject(1);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.TimeUnit unit\n                     */\n                    static addUnit(builder, unit) {\n                        builder.addFieldInt16(0, unit, org.apache.arrow.flatbuf.TimeUnit.MILLISECOND);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endDuration(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createDuration(builder, unit) {\n                        Duration.startDuration(builder);\n                        Duration.addUnit(builder, unit);\n                        return Duration.endDuration(builder);\n                    }\n                }\n                flatbuf.Duration = Duration;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * user defined key value pairs to add custom metadata to arrow\n * key namespacing is the responsibility of the user\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class KeyValue {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns KeyValue\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param KeyValue= obj\n                     * @returns KeyValue\n                     */\n                    static getRootAsKeyValue(bb, obj) {\n                        return (obj || new KeyValue).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    key(optionalEncoding) {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.__string(this.bb_pos + offset, optionalEncoding) : null;\n                    }\n                    value(optionalEncoding) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.__string(this.bb_pos + offset, optionalEncoding) : null;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startKeyValue(builder) {\n                        builder.startObject(2);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset keyOffset\n                     */\n                    static addKey(builder, keyOffset) {\n                        builder.addFieldOffset(0, keyOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset valueOffset\n                     */\n                    static addValue(builder, valueOffset) {\n                        builder.addFieldOffset(1, valueOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endKeyValue(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createKeyValue(builder, keyOffset, valueOffset) {\n                        KeyValue.startKeyValue(builder);\n                        KeyValue.addKey(builder, keyOffset);\n                        KeyValue.addValue(builder, valueOffset);\n                        return KeyValue.endKeyValue(builder);\n                    }\n                }\n                flatbuf.KeyValue = KeyValue;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * Dictionary encoding metadata\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class DictionaryEncoding {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns DictionaryEncoding\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param DictionaryEncoding= obj\n                     * @returns DictionaryEncoding\n                     */\n                    static getRootAsDictionaryEncoding(bb, obj) {\n                        return (obj || new DictionaryEncoding).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * The known dictionary id in the application where this data is used. In\n                     * the file or streaming formats, the dictionary ids are found in the\n                     * DictionaryBatch messages\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    id() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.readInt64(this.bb_pos + offset) : this.bb.createLong(0, 0);\n                    }\n                    /**\n                     * The dictionary indices are constrained to be positive integers. If this\n                     * field is null, the indices must be signed int32\n                     *\n                     * @param org.apache.arrow.flatbuf.Int= obj\n                     * @returns org.apache.arrow.flatbuf.Int|null\n                     */\n                    indexType(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.Int).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n                    }\n                    /**\n                     * By default, dictionaries are not ordered, or the order does not have\n                     * semantic meaning. In some statistical, applications, dictionary-encoding\n                     * is used to represent ordered categorical data, and we provide a way to\n                     * preserve that metadata here\n                     *\n                     * @returns boolean\n                     */\n                    isOrdered() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startDictionaryEncoding(builder) {\n                        builder.startObject(3);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long id\n                     */\n                    static addId(builder, id) {\n                        builder.addFieldInt64(0, id, builder.createLong(0, 0));\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset indexTypeOffset\n                     */\n                    static addIndexType(builder, indexTypeOffset) {\n                        builder.addFieldOffset(1, indexTypeOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param boolean isOrdered\n                     */\n                    static addIsOrdered(builder, isOrdered) {\n                        builder.addFieldInt8(2, +isOrdered, +false);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endDictionaryEncoding(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createDictionaryEncoding(builder, id, indexTypeOffset, isOrdered) {\n                        DictionaryEncoding.startDictionaryEncoding(builder);\n                        DictionaryEncoding.addId(builder, id);\n                        DictionaryEncoding.addIndexType(builder, indexTypeOffset);\n                        DictionaryEncoding.addIsOrdered(builder, isOrdered);\n                        return DictionaryEncoding.endDictionaryEncoding(builder);\n                    }\n                }\n                flatbuf.DictionaryEncoding = DictionaryEncoding;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * A field represents a named column in a record / row batch or child of a\n * nested type.\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Field {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Field\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Field= obj\n                     * @returns Field\n                     */\n                    static getRootAsField(bb, obj) {\n                        return (obj || new Field).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    name(optionalEncoding) {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? this.bb.__string(this.bb_pos + offset, optionalEncoding) : null;\n                    }\n                    /**\n                     * Whether or not this field can contain nulls. Should be true in general.\n                     *\n                     * @returns boolean\n                     */\n                    nullable() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? !!this.bb.readInt8(this.bb_pos + offset) : false;\n                    }\n                    /**\n                     * @returns org.apache.arrow.flatbuf.Type\n                     */\n                    typeType() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? /**  */ (this.bb.readUint8(this.bb_pos + offset)) : org.apache.arrow.flatbuf.Type.NONE;\n                    }\n                    /**\n                     * This is the type of the decoded value if the field is dictionary encoded.\n                     *\n                     * @param flatbuffers.Table obj\n                     * @returns ?flatbuffers.Table\n                     */\n                    type(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 10);\n                        return offset ? this.bb.__union(obj, this.bb_pos + offset) : null;\n                    }\n                    /**\n                     * Present only if the field is dictionary encoded.\n                     *\n                     * @param org.apache.arrow.flatbuf.DictionaryEncoding= obj\n                     * @returns org.apache.arrow.flatbuf.DictionaryEncoding|null\n                     */\n                    dictionary(obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 12);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.DictionaryEncoding).__init(this.bb.__indirect(this.bb_pos + offset), this.bb) : null;\n                    }\n                    /**\n                     * children apply only to nested data types like Struct, List and Union. For\n                     * primitive types children will have length 0.\n                     *\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.Field= obj\n                     * @returns org.apache.arrow.flatbuf.Field\n                     */\n                    children(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 14);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.Field).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + offset) + index * 4), this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    childrenLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 14);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * User-defined metadata\n                     *\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.KeyValue= obj\n                     * @returns org.apache.arrow.flatbuf.KeyValue\n                     */\n                    customMetadata(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 16);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.KeyValue).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + offset) + index * 4), this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    customMetadataLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 16);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startField(builder) {\n                        builder.startObject(7);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset nameOffset\n                     */\n                    static addName(builder, nameOffset) {\n                        builder.addFieldOffset(0, nameOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param boolean nullable\n                     */\n                    static addNullable(builder, nullable) {\n                        builder.addFieldInt8(1, +nullable, +false);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.Type typeType\n                     */\n                    static addTypeType(builder, typeType) {\n                        builder.addFieldInt8(2, typeType, org.apache.arrow.flatbuf.Type.NONE);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset typeOffset\n                     */\n                    static addType(builder, typeOffset) {\n                        builder.addFieldOffset(3, typeOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset dictionaryOffset\n                     */\n                    static addDictionary(builder, dictionaryOffset) {\n                        builder.addFieldOffset(4, dictionaryOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset childrenOffset\n                     */\n                    static addChildren(builder, childrenOffset) {\n                        builder.addFieldOffset(5, childrenOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<flatbuffers.Offset> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createChildrenVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addOffset(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startChildrenVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset customMetadataOffset\n                     */\n                    static addCustomMetadata(builder, customMetadataOffset) {\n                        builder.addFieldOffset(6, customMetadataOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<flatbuffers.Offset> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createCustomMetadataVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addOffset(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startCustomMetadataVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endField(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    static createField(builder, nameOffset, nullable, typeType, typeOffset, dictionaryOffset, childrenOffset, customMetadataOffset) {\n                        Field.startField(builder);\n                        Field.addName(builder, nameOffset);\n                        Field.addNullable(builder, nullable);\n                        Field.addTypeType(builder, typeType);\n                        Field.addType(builder, typeOffset);\n                        Field.addDictionary(builder, dictionaryOffset);\n                        Field.addChildren(builder, childrenOffset);\n                        Field.addCustomMetadata(builder, customMetadataOffset);\n                        return Field.endField(builder);\n                    }\n                }\n                flatbuf.Field = Field;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * A Buffer represents a single contiguous memory segment\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Buffer {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Buffer\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * The relative offset into the shared memory page where the bytes for this\n                     * buffer starts\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    offset() {\n                        return this.bb.readInt64(this.bb_pos);\n                    }\n                    /**\n                     * The absolute length (in bytes) of the memory buffer. The memory is found\n                     * from offset (inclusive) to offset + length (non-inclusive).\n                     *\n                     * @returns flatbuffers.Long\n                     */\n                    length() {\n                        return this.bb.readInt64(this.bb_pos + 8);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Long offset\n                     * @param flatbuffers.Long length\n                     * @returns flatbuffers.Offset\n                     */\n                    static createBuffer(builder, offset, length) {\n                        builder.prep(8, 16);\n                        builder.writeInt64(length);\n                        builder.writeInt64(offset);\n                        return builder.offset();\n                    }\n                }\n                flatbuf.Buffer = Buffer;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n/**\n * ----------------------------------------------------------------------\n * A Schema describes the columns in a row batch\n *\n * @constructor\n */\n(function (org) {\n    var apache;\n    (function (apache) {\n        var arrow;\n        (function (arrow) {\n            var flatbuf;\n            (function (flatbuf) {\n                class Schema {\n                    constructor() {\n                        this.bb = null;\n                        this.bb_pos = 0;\n                    }\n                    /**\n                     * @param number i\n                     * @param flatbuffers.ByteBuffer bb\n                     * @returns Schema\n                     */\n                    __init(i, bb) {\n                        this.bb_pos = i;\n                        this.bb = bb;\n                        return this;\n                    }\n                    /**\n                     * @param flatbuffers.ByteBuffer bb\n                     * @param Schema= obj\n                     * @returns Schema\n                     */\n                    static getRootAsSchema(bb, obj) {\n                        return (obj || new Schema).__init(bb.readInt32(bb.position()) + bb.position(), bb);\n                    }\n                    /**\n                     * endianness of the buffer\n                     * it is Little Endian by default\n                     * if endianness doesn't match the underlying system then the vectors need to be converted\n                     *\n                     * @returns org.apache.arrow.flatbuf.Endianness\n                     */\n                    endianness() {\n                        let offset = this.bb.__offset(this.bb_pos, 4);\n                        return offset ? /**  */ (this.bb.readInt16(this.bb_pos + offset)) : org.apache.arrow.flatbuf.Endianness.Little;\n                    }\n                    /**\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.Field= obj\n                     * @returns org.apache.arrow.flatbuf.Field\n                     */\n                    fields(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.Field).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + offset) + index * 4), this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    fieldsLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 6);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param number index\n                     * @param org.apache.arrow.flatbuf.KeyValue= obj\n                     * @returns org.apache.arrow.flatbuf.KeyValue\n                     */\n                    customMetadata(index, obj) {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? (obj || new org.apache.arrow.flatbuf.KeyValue).__init(this.bb.__indirect(this.bb.__vector(this.bb_pos + offset) + index * 4), this.bb) : null;\n                    }\n                    /**\n                     * @returns number\n                     */\n                    customMetadataLength() {\n                        let offset = this.bb.__offset(this.bb_pos, 8);\n                        return offset ? this.bb.__vector_len(this.bb_pos + offset) : 0;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     */\n                    static startSchema(builder) {\n                        builder.startObject(3);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param org.apache.arrow.flatbuf.Endianness endianness\n                     */\n                    static addEndianness(builder, endianness) {\n                        builder.addFieldInt16(0, endianness, org.apache.arrow.flatbuf.Endianness.Little);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset fieldsOffset\n                     */\n                    static addFields(builder, fieldsOffset) {\n                        builder.addFieldOffset(1, fieldsOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<flatbuffers.Offset> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createFieldsVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addOffset(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startFieldsVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset customMetadataOffset\n                     */\n                    static addCustomMetadata(builder, customMetadataOffset) {\n                        builder.addFieldOffset(2, customMetadataOffset, 0);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param Array.<flatbuffers.Offset> data\n                     * @returns flatbuffers.Offset\n                     */\n                    static createCustomMetadataVector(builder, data) {\n                        builder.startVector(4, data.length, 4);\n                        for (let i = data.length - 1; i >= 0; i--) {\n                            builder.addOffset(data[i]);\n                        }\n                        return builder.endVector();\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param number numElems\n                     */\n                    static startCustomMetadataVector(builder, numElems) {\n                        builder.startVector(4, numElems, 4);\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @returns flatbuffers.Offset\n                     */\n                    static endSchema(builder) {\n                        let offset = builder.endObject();\n                        return offset;\n                    }\n                    /**\n                     * @param flatbuffers.Builder builder\n                     * @param flatbuffers.Offset offset\n                     */\n                    static finishSchemaBuffer(builder, offset) {\n                        builder.finish(offset);\n                    }\n                    static createSchema(builder, endianness, fieldsOffset, customMetadataOffset) {\n                        Schema.startSchema(builder);\n                        Schema.addEndianness(builder, endianness);\n                        Schema.addFields(builder, fieldsOffset);\n                        Schema.addCustomMetadata(builder, customMetadataOffset);\n                        return Schema.endSchema(builder);\n                    }\n                }\n                flatbuf.Schema = Schema;\n            })(flatbuf = arrow.flatbuf || (arrow.flatbuf = {}));\n        })(arrow = apache.arrow || (apache.arrow = {}));\n    })(apache = org.apache || (org.apache = {}));\n})(org = exports.org || (exports.org = {}));\n\n//# sourceMappingURL=Schema.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"../util/buffer\");\n/** @ignore */\nexports.default = {\n    fromIterable(source) {\n        return pump(fromIterable(source));\n    },\n    fromAsyncIterable(source) {\n        return pump(fromAsyncIterable(source));\n    },\n    fromDOMStream(source) {\n        return pump(fromDOMStream(source));\n    },\n    fromNodeStream(stream) {\n        return pump(fromNodeStream(stream));\n    },\n    // @ts-ignore\n    toDOMStream(source, options) {\n        throw new Error(`\"toDOMStream\" not available in this environment`);\n    },\n    // @ts-ignore\n    toNodeStream(source, options) {\n        throw new Error(`\"toNodeStream\" not available in this environment`);\n    },\n};\n/** @ignore */\nconst pump = (iterator) => { iterator.next(); return iterator; };\n/** @ignore */\nfunction* fromIterable(source) {\n    let done, threw = false;\n    let buffers = [], buffer;\n    let cmd, size, bufferLength = 0;\n    function byteRange() {\n        if (cmd === 'peek') {\n            return buffer_1.joinUint8Arrays(buffers, size)[0];\n        }\n        [buffer, buffers, bufferLength] = buffer_1.joinUint8Arrays(buffers, size);\n        return buffer;\n    }\n    // Yield so the caller can inject the read command before creating the source Iterator\n    ({ cmd, size } = yield null);\n    // initialize the iterator\n    let it = buffer_1.toUint8ArrayIterator(source)[Symbol.iterator]();\n    try {\n        do {\n            // read the next value\n            ({ done, value: buffer } = isNaN(size - bufferLength) ?\n                it.next(undefined) : it.next(size - bufferLength));\n            // if chunk is not null or empty, push it onto the queue\n            if (!done && buffer.byteLength > 0) {\n                buffers.push(buffer);\n                bufferLength += buffer.byteLength;\n            }\n            // If we have enough bytes in our buffer, yield chunks until we don't\n            if (done || size <= bufferLength) {\n                do {\n                    ({ cmd, size } = yield byteRange());\n                } while (size < bufferLength);\n            }\n        } while (!done);\n    }\n    catch (e) {\n        (threw = true) && (typeof it.throw === 'function') && (it.throw(e));\n    }\n    finally {\n        (threw === false) && (typeof it.return === 'function') && (it.return());\n    }\n}\n/** @ignore */\nasync function* fromAsyncIterable(source) {\n    let done, threw = false;\n    let buffers = [], buffer;\n    let cmd, size, bufferLength = 0;\n    function byteRange() {\n        if (cmd === 'peek') {\n            return buffer_1.joinUint8Arrays(buffers, size)[0];\n        }\n        [buffer, buffers, bufferLength] = buffer_1.joinUint8Arrays(buffers, size);\n        return buffer;\n    }\n    // Yield so the caller can inject the read command before creating the source AsyncIterator\n    ({ cmd, size } = yield null);\n    // initialize the iterator\n    let it = buffer_1.toUint8ArrayAsyncIterator(source)[Symbol.asyncIterator]();\n    try {\n        do {\n            // read the next value\n            ({ done, value: buffer } = isNaN(size - bufferLength)\n                ? await it.next(undefined)\n                : await it.next(size - bufferLength));\n            // if chunk is not null or empty, push it onto the queue\n            if (!done && buffer.byteLength > 0) {\n                buffers.push(buffer);\n                bufferLength += buffer.byteLength;\n            }\n            // If we have enough bytes in our buffer, yield chunks until we don't\n            if (done || size <= bufferLength) {\n                do {\n                    ({ cmd, size } = yield byteRange());\n                } while (size < bufferLength);\n            }\n        } while (!done);\n    }\n    catch (e) {\n        (threw = true) && (typeof it.throw === 'function') && (await it.throw(e));\n    }\n    finally {\n        (threw === false) && (typeof it.return === 'function') && (await it.return());\n    }\n}\n// All this manual Uint8Array chunk management can be avoided if/when engines\n// add support for ArrayBuffer.transfer() or ArrayBuffer.prototype.realloc():\n// https://github.com/domenic/proposal-arraybuffer-transfer\n/** @ignore */\nasync function* fromDOMStream(source) {\n    let done = false, threw = false;\n    let buffers = [], buffer;\n    let cmd, size, bufferLength = 0;\n    function byteRange() {\n        if (cmd === 'peek') {\n            return buffer_1.joinUint8Arrays(buffers, size)[0];\n        }\n        [buffer, buffers, bufferLength] = buffer_1.joinUint8Arrays(buffers, size);\n        return buffer;\n    }\n    // Yield so the caller can inject the read command before we establish the ReadableStream lock\n    ({ cmd, size } = yield null);\n    // initialize the reader and lock the stream\n    let it = new AdaptiveByteReader(source);\n    try {\n        do {\n            // read the next value\n            ({ done, value: buffer } = isNaN(size - bufferLength)\n                ? await it['read'](undefined)\n                : await it['read'](size - bufferLength));\n            // if chunk is not null or empty, push it onto the queue\n            if (!done && buffer.byteLength > 0) {\n                buffers.push(buffer_1.toUint8Array(buffer));\n                bufferLength += buffer.byteLength;\n            }\n            // If we have enough bytes in our buffer, yield chunks until we don't\n            if (done || size <= bufferLength) {\n                do {\n                    ({ cmd, size } = yield byteRange());\n                } while (size < bufferLength);\n            }\n        } while (!done);\n    }\n    catch (e) {\n        (threw = true) && (await it['cancel'](e));\n    }\n    finally {\n        (threw === false) ? (await it['cancel']())\n            : source['locked'] && it.releaseLock();\n    }\n}\n/** @ignore */\nclass AdaptiveByteReader {\n    constructor(source) {\n        this.source = source;\n        this.byobReader = null;\n        this.defaultReader = null;\n        try {\n            this.supportsBYOB = !!(this.reader = this.getBYOBReader());\n        }\n        catch (e) {\n            this.supportsBYOB = !!!(this.reader = this.getDefaultReader());\n        }\n    }\n    get closed() {\n        return this.reader ? this.reader['closed'].catch(() => { }) : Promise.resolve();\n    }\n    releaseLock() {\n        if (this.reader) {\n            this.reader.releaseLock();\n        }\n        this.reader = this.byobReader = this.defaultReader = null;\n    }\n    async cancel(reason) {\n        const { reader, source } = this;\n        reader && (await reader['cancel'](reason).catch(() => { }));\n        source && (source['locked'] && this.releaseLock());\n    }\n    async read(size) {\n        if (size === 0) {\n            return { done: this.reader == null, value: new Uint8Array(0) };\n        }\n        const result = !this.supportsBYOB || typeof size !== 'number'\n            ? await this.getDefaultReader().read()\n            : await this.readFromBYOBReader(size);\n        !result.done && (result.value = buffer_1.toUint8Array(result));\n        return result;\n    }\n    getDefaultReader() {\n        if (this.byobReader) {\n            this.releaseLock();\n        }\n        if (!this.defaultReader) {\n            this.defaultReader = this.source['getReader']();\n            // We have to catch and swallow errors here to avoid uncaught promise rejection exceptions\n            // that seem to be raised when we call `releaseLock()` on this reader. I'm still mystified\n            // about why these errors are raised, but I'm sure there's some important spec reason that\n            // I haven't considered. I hate to employ such an anti-pattern here, but it seems like the\n            // only solution in this case :/\n            this.defaultReader['closed'].catch(() => { });\n        }\n        return (this.reader = this.defaultReader);\n    }\n    getBYOBReader() {\n        if (this.defaultReader) {\n            this.releaseLock();\n        }\n        if (!this.byobReader) {\n            this.byobReader = this.source['getReader']({ mode: 'byob' });\n            // We have to catch and swallow errors here to avoid uncaught promise rejection exceptions\n            // that seem to be raised when we call `releaseLock()` on this reader. I'm still mystified\n            // about why these errors are raised, but I'm sure there's some important spec reason that\n            // I haven't considered. I hate to employ such an anti-pattern here, but it seems like the\n            // only solution in this case :/\n            this.byobReader['closed'].catch(() => { });\n        }\n        return (this.reader = this.byobReader);\n    }\n    // This strategy plucked from the example in the streams spec:\n    // https://streams.spec.whatwg.org/#example-manual-read-bytes\n    async readFromBYOBReader(size) {\n        return await readInto(this.getBYOBReader(), new ArrayBuffer(size), 0, size);\n    }\n}\n/** @ignore */\nasync function readInto(reader, buffer, offset, size) {\n    if (offset >= size) {\n        return { done: false, value: new Uint8Array(buffer, 0, size) };\n    }\n    const { done, value } = await reader.read(new Uint8Array(buffer, offset, size - offset));\n    if (((offset += value.byteLength) < size) && !done) {\n        return await readInto(reader, value.buffer, offset, size);\n    }\n    return { done, value: new Uint8Array(value.buffer, 0, offset) };\n}\n/** @ignore */\nconst onEvent = (stream, event) => {\n    let handler = (_) => resolve([event, _]);\n    let resolve;\n    return [event, handler, new Promise((r) => (resolve = r) && stream['once'](event, handler))];\n};\n/** @ignore */\nasync function* fromNodeStream(stream) {\n    let events = [];\n    let event = 'error';\n    let done = false, err = null;\n    let cmd, size, bufferLength = 0;\n    let buffers = [], buffer;\n    function byteRange() {\n        if (cmd === 'peek') {\n            return buffer_1.joinUint8Arrays(buffers, size)[0];\n        }\n        [buffer, buffers, bufferLength] = buffer_1.joinUint8Arrays(buffers, size);\n        return buffer;\n    }\n    // Yield so the caller can inject the read command before we\n    // add the listener for the source stream's 'readable' event.\n    ({ cmd, size } = yield null);\n    // ignore stdin if it's a TTY\n    if (stream['isTTY']) {\n        return yield new Uint8Array(0);\n    }\n    try {\n        // initialize the stream event handlers\n        events[0] = onEvent(stream, 'end');\n        events[1] = onEvent(stream, 'error');\n        do {\n            events[2] = onEvent(stream, 'readable');\n            // wait on the first message event from the stream\n            [event, err] = await Promise.race(events.map((x) => x[2]));\n            // if the stream emitted an Error, rethrow it\n            if (event === 'error') {\n                break;\n            }\n            if (!(done = event === 'end')) {\n                // If the size is NaN, request to read everything in the stream's internal buffer\n                if (!isFinite(size - bufferLength)) {\n                    buffer = buffer_1.toUint8Array(stream['read'](undefined));\n                }\n                else {\n                    buffer = buffer_1.toUint8Array(stream['read'](size - bufferLength));\n                    // If the byteLength is 0, then the requested amount is more than the stream has\n                    // in its internal buffer. In this case the stream needs a \"kick\" to tell it to\n                    // continue emitting readable events, so request to read everything the stream\n                    // has in its internal buffer right now.\n                    if (buffer.byteLength < (size - bufferLength)) {\n                        buffer = buffer_1.toUint8Array(stream['read'](undefined));\n                    }\n                }\n                // if chunk is not null or empty, push it onto the queue\n                if (buffer.byteLength > 0) {\n                    buffers.push(buffer);\n                    bufferLength += buffer.byteLength;\n                }\n            }\n            // If we have enough bytes in our buffer, yield chunks until we don't\n            if (done || size <= bufferLength) {\n                do {\n                    ({ cmd, size } = yield byteRange());\n                } while (size < bufferLength);\n            }\n        } while (!done);\n    }\n    finally {\n        await cleanup(events, event === 'error' ? err : null);\n    }\n    function cleanup(events, err) {\n        buffer = buffers = null;\n        return new Promise(async (resolve, reject) => {\n            for (const [evt, fn] of events) {\n                stream['off'](evt, fn);\n            }\n            try {\n                // Some stream implementations don't call the destroy callback,\n                // because it's really a node-internal API. Just calling `destroy`\n                // here should be enough to conform to the ReadableStream contract\n                const destroy = stream['destroy'];\n                destroy && destroy.call(stream, err);\n                err = undefined;\n            }\n            catch (e) {\n                err = e || err;\n            }\n            finally {\n                err != null ? reject(err) : resolve();\n            }\n        });\n    }\n}\n\n//# sourceMappingURL=adapters.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst stream_1 = require(\"./stream\");\nconst buffer_1 = require(\"../util/buffer\");\n/** @ignore */\nclass RandomAccessFile extends stream_1.ByteStream {\n    constructor(buffer, byteLength) {\n        super();\n        this.position = 0;\n        this.buffer = buffer_1.toUint8Array(buffer);\n        this.size = typeof byteLength === 'undefined' ? this.buffer.byteLength : byteLength;\n    }\n    readInt32(position) {\n        const { buffer, byteOffset } = this.readAt(position, 4);\n        return new DataView(buffer, byteOffset).getInt32(0, true);\n    }\n    seek(position) {\n        this.position = Math.min(position, this.size);\n        return position < this.size;\n    }\n    read(nBytes) {\n        const { buffer, size, position } = this;\n        if (buffer && position < size) {\n            if (typeof nBytes !== 'number') {\n                nBytes = Infinity;\n            }\n            this.position = Math.min(size, position + Math.min(size - position, nBytes));\n            return buffer.subarray(position, this.position);\n        }\n        return null;\n    }\n    readAt(position, nBytes) {\n        const buf = this.buffer;\n        const end = Math.min(this.size, position + nBytes);\n        return buf ? buf.subarray(position, end) : new Uint8Array(nBytes);\n    }\n    close() { this.buffer && (this.buffer = null); }\n    throw(value) { this.close(); return { done: true, value }; }\n    return(value) { this.close(); return { done: true, value }; }\n}\nexports.RandomAccessFile = RandomAccessFile;\n/** @ignore */\nclass AsyncRandomAccessFile extends stream_1.AsyncByteStream {\n    constructor(file, byteLength) {\n        super();\n        this.position = 0;\n        this._handle = file;\n        if (typeof byteLength === 'number') {\n            this.size = byteLength;\n        }\n        else {\n            this._pending = (async () => {\n                this.size = (await file.stat()).size;\n                delete this._pending;\n            })();\n        }\n    }\n    async readInt32(position) {\n        const { buffer, byteOffset } = await this.readAt(position, 4);\n        return new DataView(buffer, byteOffset).getInt32(0, true);\n    }\n    async seek(position) {\n        this._pending && await this._pending;\n        this.position = Math.min(position, this.size);\n        return position < this.size;\n    }\n    async read(nBytes) {\n        this._pending && await this._pending;\n        const { _handle: file, size, position } = this;\n        if (file && position < size) {\n            if (typeof nBytes !== 'number') {\n                nBytes = Infinity;\n            }\n            let pos = position, offset = 0, bytesRead = 0;\n            let end = Math.min(size, pos + Math.min(size - pos, nBytes));\n            let buffer = new Uint8Array(Math.max(0, (this.position = end) - pos));\n            while ((pos += bytesRead) < end && (offset += bytesRead) < buffer.byteLength) {\n                ({ bytesRead } = await file.read(buffer, offset, buffer.byteLength - offset, pos));\n            }\n            return buffer;\n        }\n        return null;\n    }\n    async readAt(position, nBytes) {\n        this._pending && await this._pending;\n        const { _handle: file, size } = this;\n        if (file && (position + nBytes) < size) {\n            const end = Math.min(size, position + nBytes);\n            const buffer = new Uint8Array(end - position);\n            return (await file.read(buffer, 0, nBytes, position)).buffer;\n        }\n        return new Uint8Array(nBytes);\n    }\n    async close() { const f = this._handle; this._handle = null; f && await f.close(); }\n    async throw(value) { await this.close(); return { done: true, value }; }\n    async return(value) { await this.close(); return { done: true, value }; }\n}\nexports.AsyncRandomAccessFile = AsyncRandomAccessFile;\n\n//# sourceMappingURL=file.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst adapters_1 = require(\"./adapters\");\n/** @ignore */\nexports.ITERATOR_DONE = Object.freeze({ done: true, value: void (0) });\n/** @ignore */\nclass ArrowJSON {\n    // @ts-ignore\n    constructor(_json) {\n        this._json = _json;\n    }\n    get schema() { return this._json['schema']; }\n    get batches() { return (this._json['batches'] || []); }\n    get dictionaries() { return (this._json['dictionaries'] || []); }\n}\nexports.ArrowJSON = ArrowJSON;\n/** @ignore */\nclass ReadableInterop {\n    tee() {\n        return this._getDOMStream().tee();\n    }\n    pipe(writable, options) {\n        return this._getNodeStream().pipe(writable, options);\n    }\n    pipeTo(writable, options) { return this._getDOMStream().pipeTo(writable, options); }\n    pipeThrough(duplex, options) {\n        return this._getDOMStream().pipeThrough(duplex, options);\n    }\n    _getDOMStream() {\n        return this._DOMStream || (this._DOMStream = this.toDOMStream());\n    }\n    _getNodeStream() {\n        return this._nodeStream || (this._nodeStream = this.toNodeStream());\n    }\n}\nexports.ReadableInterop = ReadableInterop;\n/** @ignore */\nclass AsyncQueue extends ReadableInterop {\n    constructor() {\n        super();\n        this._values = [];\n        this.resolvers = [];\n        this._closedPromise = new Promise((r) => this._closedPromiseResolve = r);\n    }\n    get closed() { return this._closedPromise; }\n    async cancel(reason) { await this.return(reason); }\n    write(value) {\n        if (this._ensureOpen()) {\n            this.resolvers.length <= 0\n                ? (this._values.push(value))\n                : (this.resolvers.shift().resolve({ done: false, value }));\n        }\n    }\n    abort(value) {\n        if (this._closedPromiseResolve) {\n            this.resolvers.length <= 0\n                ? (this._error = { error: value })\n                : (this.resolvers.shift().reject({ done: true, value }));\n        }\n    }\n    close() {\n        if (this._closedPromiseResolve) {\n            const { resolvers } = this;\n            while (resolvers.length > 0) {\n                resolvers.shift().resolve(exports.ITERATOR_DONE);\n            }\n            this._closedPromiseResolve();\n            this._closedPromiseResolve = undefined;\n        }\n    }\n    [Symbol.asyncIterator]() { return this; }\n    toDOMStream(options) {\n        return adapters_1.default.toDOMStream((this._closedPromiseResolve || this._error)\n            ? this\n            : this._values, options);\n    }\n    toNodeStream(options) {\n        return adapters_1.default.toNodeStream((this._closedPromiseResolve || this._error)\n            ? this\n            : this._values, options);\n    }\n    async throw(_) { await this.abort(_); return exports.ITERATOR_DONE; }\n    async return(_) { await this.close(); return exports.ITERATOR_DONE; }\n    async read(size) { return (await this.next(size, 'read')).value; }\n    async peek(size) { return (await this.next(size, 'peek')).value; }\n    next(..._args) {\n        if (this._values.length > 0) {\n            return Promise.resolve({ done: false, value: this._values.shift() });\n        }\n        else if (this._error) {\n            return Promise.reject({ done: true, value: this._error.error });\n        }\n        else if (!this._closedPromiseResolve) {\n            return Promise.resolve(exports.ITERATOR_DONE);\n        }\n        else {\n            return new Promise((resolve, reject) => {\n                this.resolvers.push({ resolve, reject });\n            });\n        }\n    }\n    _ensureOpen() {\n        if (this._closedPromiseResolve) {\n            return true;\n        }\n        throw new Error(`${this} is closed`);\n    }\n}\nexports.AsyncQueue = AsyncQueue;\n\n//# sourceMappingURL=interfaces.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst adapters_1 = require(\"./adapters\");\nconst utf8_1 = require(\"../util/utf8\");\nconst interfaces_1 = require(\"./interfaces\");\nconst buffer_1 = require(\"../util/buffer\");\nconst compat_1 = require(\"../util/compat\");\n/** @ignore */\nclass AsyncByteQueue extends interfaces_1.AsyncQueue {\n    write(value) {\n        if ((value = buffer_1.toUint8Array(value)).byteLength > 0) {\n            return super.write(value);\n        }\n    }\n    toString(sync = false) {\n        return sync\n            ? utf8_1.decodeUtf8(this.toUint8Array(true))\n            : this.toUint8Array(false).then(utf8_1.decodeUtf8);\n    }\n    toUint8Array(sync = false) {\n        return sync ? buffer_1.joinUint8Arrays(this._values)[0] : (async () => {\n            let buffers = [], byteLength = 0;\n            for await (const chunk of this) {\n                buffers.push(chunk);\n                byteLength += chunk.byteLength;\n            }\n            return buffer_1.joinUint8Arrays(buffers, byteLength)[0];\n        })();\n    }\n}\nexports.AsyncByteQueue = AsyncByteQueue;\n/** @ignore */\nclass ByteStream {\n    constructor(source) {\n        if (source) {\n            this.source = new ByteStreamSource(adapters_1.default.fromIterable(source));\n        }\n    }\n    [Symbol.iterator]() { return this; }\n    next(value) { return this.source.next(value); }\n    throw(value) { return this.source.throw(value); }\n    return(value) { return this.source.return(value); }\n    peek(size) { return this.source.peek(size); }\n    read(size) { return this.source.read(size); }\n}\nexports.ByteStream = ByteStream;\n/** @ignore */\nclass AsyncByteStream {\n    constructor(source) {\n        if (source instanceof AsyncByteStream) {\n            this.source = source.source;\n        }\n        else if (source instanceof AsyncByteQueue) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromAsyncIterable(source));\n        }\n        else if (compat_1.isReadableNodeStream(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromNodeStream(source));\n        }\n        else if (compat_1.isReadableDOMStream(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromDOMStream(source));\n        }\n        else if (compat_1.isFetchResponse(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromDOMStream(source.body));\n        }\n        else if (compat_1.isIterable(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromIterable(source));\n        }\n        else if (compat_1.isPromise(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromAsyncIterable(source));\n        }\n        else if (compat_1.isAsyncIterable(source)) {\n            this.source = new AsyncByteStreamSource(adapters_1.default.fromAsyncIterable(source));\n        }\n    }\n    [Symbol.asyncIterator]() { return this; }\n    next(value) { return this.source.next(value); }\n    throw(value) { return this.source.throw(value); }\n    return(value) { return this.source.return(value); }\n    get closed() { return this.source.closed; }\n    cancel(reason) { return this.source.cancel(reason); }\n    peek(size) { return this.source.peek(size); }\n    read(size) { return this.source.read(size); }\n}\nexports.AsyncByteStream = AsyncByteStream;\n/** @ignore */\nclass ByteStreamSource {\n    constructor(source) {\n        this.source = source;\n    }\n    cancel(reason) { this.return(reason); }\n    peek(size) { return this.next(size, 'peek').value; }\n    read(size) { return this.next(size, 'read').value; }\n    next(size, cmd = 'read') { return this.source.next({ cmd, size }); }\n    throw(value) { return Object.create((this.source.throw && this.source.throw(value)) || interfaces_1.ITERATOR_DONE); }\n    return(value) { return Object.create((this.source.return && this.source.return(value)) || interfaces_1.ITERATOR_DONE); }\n}\n/** @ignore */\nclass AsyncByteStreamSource {\n    constructor(source) {\n        this.source = source;\n        this._closedPromise = new Promise((r) => this._closedPromiseResolve = r);\n    }\n    async cancel(reason) { await this.return(reason); }\n    get closed() { return this._closedPromise; }\n    async read(size) { return (await this.next(size, 'read')).value; }\n    async peek(size) { return (await this.next(size, 'peek')).value; }\n    async next(size, cmd = 'read') { return (await this.source.next({ cmd, size })); }\n    async throw(value) {\n        const result = (this.source.throw && await this.source.throw(value)) || interfaces_1.ITERATOR_DONE;\n        this._closedPromiseResolve && this._closedPromiseResolve();\n        this._closedPromiseResolve = undefined;\n        return Object.create(result);\n    }\n    async return(value) {\n        const result = (this.source.return && await this.source.return(value)) || interfaces_1.ITERATOR_DONE;\n        this._closedPromiseResolve && this._closedPromiseResolve();\n        this._closedPromiseResolve = undefined;\n        return Object.create(result);\n    }\n}\n\n//# sourceMappingURL=stream.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst index_1 = require(\"../../builder/index\");\n/** @ignore */\nfunction builderThroughDOMStream(options) {\n    return new BuilderTransform(options);\n}\nexports.builderThroughDOMStream = builderThroughDOMStream;\n/** @ignore */\nclass BuilderTransform {\n    constructor(options) {\n        // Access properties by string indexers to defeat closure compiler\n        this._numChunks = 0;\n        this._finished = false;\n        this._bufferedSize = 0;\n        const { ['readableStrategy']: readableStrategy, ['writableStrategy']: writableStrategy, ['queueingStrategy']: queueingStrategy = 'count', ...builderOptions } = options;\n        this._controller = null;\n        this._builder = index_1.Builder.new(builderOptions);\n        this._getSize = queueingStrategy !== 'bytes' ? chunkLength : chunkByteLength;\n        const { ['highWaterMark']: readableHighWaterMark = queueingStrategy === 'bytes' ? 2 ** 14 : 1000 } = { ...readableStrategy };\n        const { ['highWaterMark']: writableHighWaterMark = queueingStrategy === 'bytes' ? 2 ** 14 : 1000 } = { ...writableStrategy };\n        this['readable'] = new ReadableStream({\n            ['cancel']: () => { this._builder.clear(); },\n            ['pull']: (c) => { this._maybeFlush(this._builder, this._controller = c); },\n            ['start']: (c) => { this._maybeFlush(this._builder, this._controller = c); },\n        }, {\n            'highWaterMark': readableHighWaterMark,\n            'size': queueingStrategy !== 'bytes' ? chunkLength : chunkByteLength,\n        });\n        this['writable'] = new WritableStream({\n            ['abort']: () => { this._builder.clear(); },\n            ['write']: () => { this._maybeFlush(this._builder, this._controller); },\n            ['close']: () => { this._maybeFlush(this._builder.finish(), this._controller); },\n        }, {\n            'highWaterMark': writableHighWaterMark,\n            'size': (value) => this._writeValueAndReturnChunkSize(value),\n        });\n    }\n    _writeValueAndReturnChunkSize(value) {\n        const bufferedSize = this._bufferedSize;\n        this._bufferedSize = this._getSize(this._builder.append(value));\n        return this._bufferedSize - bufferedSize;\n    }\n    _maybeFlush(builder, controller) {\n        if (controller === null) {\n            return;\n        }\n        if (this._bufferedSize >= controller.desiredSize) {\n            ++this._numChunks && this._enqueue(controller, builder.toVector());\n        }\n        if (builder.finished) {\n            if (builder.length > 0 || this._numChunks === 0) {\n                ++this._numChunks && this._enqueue(controller, builder.toVector());\n            }\n            if (!this._finished && (this._finished = true)) {\n                this._enqueue(controller, null);\n            }\n        }\n    }\n    _enqueue(controller, chunk) {\n        this._bufferedSize = 0;\n        this._controller = null;\n        chunk === null ? controller.close() : controller.enqueue(chunk);\n    }\n}\nexports.BuilderTransform = BuilderTransform;\n/** @ignore */ const chunkLength = (chunk) => chunk.length;\n/** @ignore */ const chunkByteLength = (chunk) => chunk.byteLength;\n\n//# sourceMappingURL=builder.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"../../util/buffer\");\nconst compat_1 = require(\"../../util/compat\");\n/** @ignore */\nfunction toDOMStream(source, options) {\n    if (compat_1.isAsyncIterable(source)) {\n        return asyncIterableAsReadableDOMStream(source, options);\n    }\n    if (compat_1.isIterable(source)) {\n        return iterableAsReadableDOMStream(source, options);\n    }\n    /* istanbul ignore next */\n    throw new Error(`toDOMStream() must be called with an Iterable or AsyncIterable`);\n}\nexports.toDOMStream = toDOMStream;\n/** @ignore */\nfunction iterableAsReadableDOMStream(source, options) {\n    let it = null;\n    const bm = (options && options.type === 'bytes') || false;\n    const hwm = options && options.highWaterMark || (2 ** 24);\n    return new ReadableStream({\n        ...options,\n        start(controller) { next(controller, it || (it = source[Symbol.iterator]())); },\n        pull(controller) { it ? (next(controller, it)) : controller.close(); },\n        cancel() { (it && (it.return && it.return()) || true) && (it = null); }\n    }, { highWaterMark: bm ? hwm : undefined, ...options });\n    function next(controller, it) {\n        let buf;\n        let r = null;\n        let size = controller.desiredSize || null;\n        while (!(r = it.next(bm ? size : null)).done) {\n            if (ArrayBuffer.isView(r.value) && (buf = buffer_1.toUint8Array(r.value))) {\n                size != null && bm && (size = size - buf.byteLength + 1);\n                r.value = buf;\n            }\n            controller.enqueue(r.value);\n            if (size != null && --size <= 0) {\n                return;\n            }\n        }\n        controller.close();\n    }\n}\n/** @ignore */\nfunction asyncIterableAsReadableDOMStream(source, options) {\n    let it = null;\n    const bm = (options && options.type === 'bytes') || false;\n    const hwm = options && options.highWaterMark || (2 ** 24);\n    return new ReadableStream({\n        ...options,\n        async start(controller) { await next(controller, it || (it = source[Symbol.asyncIterator]())); },\n        async pull(controller) { it ? (await next(controller, it)) : controller.close(); },\n        async cancel() { (it && (it.return && await it.return()) || true) && (it = null); },\n    }, { highWaterMark: bm ? hwm : undefined, ...options });\n    async function next(controller, it) {\n        let buf;\n        let r = null;\n        let size = controller.desiredSize || null;\n        while (!(r = await it.next(bm ? size : null)).done) {\n            if (ArrayBuffer.isView(r.value) && (buf = buffer_1.toUint8Array(r.value))) {\n                size != null && bm && (size = size - buf.byteLength + 1);\n                r.value = buf;\n            }\n            controller.enqueue(r.value);\n            if (size != null && --size <= 0) {\n                return;\n            }\n        }\n        controller.close();\n    }\n}\n\n//# sourceMappingURL=iterable.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst stream_1 = require(\"../../io/stream\");\nconst reader_1 = require(\"../../ipc/reader\");\n/** @ignore */\nfunction recordBatchReaderThroughDOMStream(writableStrategy, readableStrategy) {\n    const queue = new stream_1.AsyncByteQueue();\n    let reader = null;\n    const readable = new ReadableStream({\n        async cancel() { await queue.close(); },\n        async start(controller) { await next(controller, reader || (reader = await open())); },\n        async pull(controller) { reader ? await next(controller, reader) : controller.close(); }\n    });\n    return { writable: new WritableStream(queue, { 'highWaterMark': 2 ** 14, ...writableStrategy }), readable };\n    async function open() {\n        return await (await reader_1.RecordBatchReader.from(queue)).open(readableStrategy);\n    }\n    async function next(controller, reader) {\n        let size = controller.desiredSize;\n        let r = null;\n        while (!(r = await reader.next()).done) {\n            controller.enqueue(r.value);\n            if (size != null && --size <= 0) {\n                return;\n            }\n        }\n        controller.close();\n    }\n}\nexports.recordBatchReaderThroughDOMStream = recordBatchReaderThroughDOMStream;\n\n//# sourceMappingURL=reader.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst stream_1 = require(\"../../io/stream\");\n/** @ignore */\nfunction recordBatchWriterThroughDOMStream(writableStrategy, readableStrategy) {\n    const writer = new this(writableStrategy);\n    const reader = new stream_1.AsyncByteStream(writer);\n    const readable = new ReadableStream({\n        type: 'bytes',\n        async cancel() { await reader.cancel(); },\n        async pull(controller) { await next(controller); },\n        async start(controller) { await next(controller); },\n    }, { 'highWaterMark': 2 ** 14, ...readableStrategy });\n    return { writable: new WritableStream(writer, writableStrategy), readable };\n    async function next(controller) {\n        let buf = null;\n        let size = controller.desiredSize;\n        while (buf = await reader.read(size || null)) {\n            controller.enqueue(buf);\n            if (size != null && (size -= buf.byteLength) <= 0) {\n                return;\n            }\n        }\n        controller.close();\n    }\n}\nexports.recordBatchWriterThroughDOMStream = recordBatchWriterThroughDOMStream;\n\n//# sourceMappingURL=writer.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst enum_1 = require(\"../enum\");\nconst flatbuffers_1 = require(\"flatbuffers\");\nvar ByteBuffer = flatbuffers_1.flatbuffers.ByteBuffer;\nconst message_1 = require(\"./metadata/message\");\nconst compat_1 = require(\"../util/compat\");\nconst file_1 = require(\"../io/file\");\nconst buffer_1 = require(\"../util/buffer\");\nconst stream_1 = require(\"../io/stream\");\nconst interfaces_1 = require(\"../io/interfaces\");\n/** @ignore */ const invalidMessageType = (type) => `Expected ${enum_1.MessageHeader[type]} Message in stream, but was null or length 0.`;\n/** @ignore */ const nullMessage = (type) => `Header pointer of flatbuffer-encoded ${enum_1.MessageHeader[type]} Message is null or length 0.`;\n/** @ignore */ const invalidMessageMetadata = (expected, actual) => `Expected to read ${expected} metadata bytes, but only read ${actual}.`;\n/** @ignore */ const invalidMessageBodyLength = (expected, actual) => `Expected to read ${expected} bytes for message body, but only read ${actual}.`;\n/** @ignore */\nclass MessageReader {\n    constructor(source) {\n        this.source = source instanceof stream_1.ByteStream ? source : new stream_1.ByteStream(source);\n    }\n    [Symbol.iterator]() { return this; }\n    next() {\n        let r;\n        if ((r = this.readMetadataLength()).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        // ARROW-6313: If the first 4 bytes are continuation indicator (-1), read\n        // the next 4 for the 32-bit metadata length. Otherwise, assume this is a\n        // pre-v0.15 message, where the first 4 bytes are the metadata length.\n        if ((r.value === -1) &&\n            (r = this.readMetadataLength()).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        if ((r = this.readMetadata(r.value)).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        return r;\n    }\n    throw(value) { return this.source.throw(value); }\n    return(value) { return this.source.return(value); }\n    readMessage(type) {\n        let r;\n        if ((r = this.next()).done) {\n            return null;\n        }\n        if ((type != null) && r.value.headerType !== type) {\n            throw new Error(invalidMessageType(type));\n        }\n        return r.value;\n    }\n    readMessageBody(bodyLength) {\n        if (bodyLength <= 0) {\n            return new Uint8Array(0);\n        }\n        const buf = buffer_1.toUint8Array(this.source.read(bodyLength));\n        if (buf.byteLength < bodyLength) {\n            throw new Error(invalidMessageBodyLength(bodyLength, buf.byteLength));\n        }\n        // 1. Work around bugs in fs.ReadStream's internal Buffer pooling, see: https://github.com/nodejs/node/issues/24817\n        // 2. Work around https://github.com/whatwg/streams/blob/0ebe4b042e467d9876d80ae045de3843092ad797/reference-implementation/lib/helpers.js#L126\n        return /* 1. */ (buf.byteOffset % 8 === 0) &&\n            /* 2. */ (buf.byteOffset + buf.byteLength) <= buf.buffer.byteLength ? buf : buf.slice();\n    }\n    readSchema(throwIfNull = false) {\n        const type = enum_1.MessageHeader.Schema;\n        const message = this.readMessage(type);\n        const schema = message && message.header();\n        if (throwIfNull && !schema) {\n            throw new Error(nullMessage(type));\n        }\n        return schema;\n    }\n    readMetadataLength() {\n        const buf = this.source.read(exports.PADDING);\n        const bb = buf && new ByteBuffer(buf);\n        const len = bb && bb.readInt32(0) || 0;\n        return { done: len === 0, value: len };\n    }\n    readMetadata(metadataLength) {\n        const buf = this.source.read(metadataLength);\n        if (!buf) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        if (buf.byteLength < metadataLength) {\n            throw new Error(invalidMessageMetadata(metadataLength, buf.byteLength));\n        }\n        return { done: false, value: message_1.Message.decode(buf) };\n    }\n}\nexports.MessageReader = MessageReader;\n/** @ignore */\nclass AsyncMessageReader {\n    constructor(source, byteLength) {\n        this.source = source instanceof stream_1.AsyncByteStream ? source\n            : compat_1.isFileHandle(source)\n                ? new file_1.AsyncRandomAccessFile(source, byteLength)\n                : new stream_1.AsyncByteStream(source);\n    }\n    [Symbol.asyncIterator]() { return this; }\n    async next() {\n        let r;\n        if ((r = await this.readMetadataLength()).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        // ARROW-6313: If the first 4 bytes are continuation indicator (-1), read\n        // the next 4 for the 32-bit metadata length. Otherwise, assume this is a\n        // pre-v0.15 message, where the first 4 bytes are the metadata length.\n        if ((r.value === -1) &&\n            (r = await this.readMetadataLength()).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        if ((r = await this.readMetadata(r.value)).done) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        return r;\n    }\n    async throw(value) { return await this.source.throw(value); }\n    async return(value) { return await this.source.return(value); }\n    async readMessage(type) {\n        let r;\n        if ((r = await this.next()).done) {\n            return null;\n        }\n        if ((type != null) && r.value.headerType !== type) {\n            throw new Error(invalidMessageType(type));\n        }\n        return r.value;\n    }\n    async readMessageBody(bodyLength) {\n        if (bodyLength <= 0) {\n            return new Uint8Array(0);\n        }\n        const buf = buffer_1.toUint8Array(await this.source.read(bodyLength));\n        if (buf.byteLength < bodyLength) {\n            throw new Error(invalidMessageBodyLength(bodyLength, buf.byteLength));\n        }\n        // 1. Work around bugs in fs.ReadStream's internal Buffer pooling, see: https://github.com/nodejs/node/issues/24817\n        // 2. Work around https://github.com/whatwg/streams/blob/0ebe4b042e467d9876d80ae045de3843092ad797/reference-implementation/lib/helpers.js#L126\n        return /* 1. */ (buf.byteOffset % 8 === 0) &&\n            /* 2. */ (buf.byteOffset + buf.byteLength) <= buf.buffer.byteLength ? buf : buf.slice();\n    }\n    async readSchema(throwIfNull = false) {\n        const type = enum_1.MessageHeader.Schema;\n        const message = await this.readMessage(type);\n        const schema = message && message.header();\n        if (throwIfNull && !schema) {\n            throw new Error(nullMessage(type));\n        }\n        return schema;\n    }\n    async readMetadataLength() {\n        const buf = await this.source.read(exports.PADDING);\n        const bb = buf && new ByteBuffer(buf);\n        const len = bb && bb.readInt32(0) || 0;\n        return { done: len === 0, value: len };\n    }\n    async readMetadata(metadataLength) {\n        const buf = await this.source.read(metadataLength);\n        if (!buf) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        if (buf.byteLength < metadataLength) {\n            throw new Error(invalidMessageMetadata(metadataLength, buf.byteLength));\n        }\n        return { done: false, value: message_1.Message.decode(buf) };\n    }\n}\nexports.AsyncMessageReader = AsyncMessageReader;\n/** @ignore */\nclass JSONMessageReader extends MessageReader {\n    constructor(source) {\n        super(new Uint8Array(0));\n        this._schema = false;\n        this._body = [];\n        this._batchIndex = 0;\n        this._dictionaryIndex = 0;\n        this._json = source instanceof interfaces_1.ArrowJSON ? source : new interfaces_1.ArrowJSON(source);\n    }\n    next() {\n        const { _json } = this;\n        if (!this._schema) {\n            this._schema = true;\n            const message = message_1.Message.fromJSON(_json.schema, enum_1.MessageHeader.Schema);\n            return { done: false, value: message };\n        }\n        if (this._dictionaryIndex < _json.dictionaries.length) {\n            const batch = _json.dictionaries[this._dictionaryIndex++];\n            this._body = batch['data']['columns'];\n            const message = message_1.Message.fromJSON(batch, enum_1.MessageHeader.DictionaryBatch);\n            return { done: false, value: message };\n        }\n        if (this._batchIndex < _json.batches.length) {\n            const batch = _json.batches[this._batchIndex++];\n            this._body = batch['columns'];\n            const message = message_1.Message.fromJSON(batch, enum_1.MessageHeader.RecordBatch);\n            return { done: false, value: message };\n        }\n        this._body = [];\n        return interfaces_1.ITERATOR_DONE;\n    }\n    readMessageBody(_bodyLength) {\n        return flattenDataSources(this._body);\n        function flattenDataSources(xs) {\n            return (xs || []).reduce((buffers, column) => [\n                ...buffers,\n                ...(column['VALIDITY'] && [column['VALIDITY']] || []),\n                ...(column['TYPE'] && [column['TYPE']] || []),\n                ...(column['OFFSET'] && [column['OFFSET']] || []),\n                ...(column['DATA'] && [column['DATA']] || []),\n                ...flattenDataSources(column['children'])\n            ], []);\n        }\n    }\n    readMessage(type) {\n        let r;\n        if ((r = this.next()).done) {\n            return null;\n        }\n        if ((type != null) && r.value.headerType !== type) {\n            throw new Error(invalidMessageType(type));\n        }\n        return r.value;\n    }\n    readSchema() {\n        const type = enum_1.MessageHeader.Schema;\n        const message = this.readMessage(type);\n        const schema = message && message.header();\n        if (!message || !schema) {\n            throw new Error(nullMessage(type));\n        }\n        return schema;\n    }\n}\nexports.JSONMessageReader = JSONMessageReader;\n/** @ignore */\nexports.PADDING = 4;\n/** @ignore */\nexports.MAGIC_STR = 'ARROW1';\n/** @ignore */\nexports.MAGIC = new Uint8Array(exports.MAGIC_STR.length);\nfor (let i = 0; i < exports.MAGIC_STR.length; i += 1 | 0) {\n    exports.MAGIC[i] = exports.MAGIC_STR.charCodeAt(i);\n}\n/** @ignore */\nfunction checkForMagicArrowString(buffer, index = 0) {\n    for (let i = -1, n = exports.MAGIC.length; ++i < n;) {\n        if (exports.MAGIC[i] !== buffer[index + i]) {\n            return false;\n        }\n    }\n    return true;\n}\nexports.checkForMagicArrowString = checkForMagicArrowString;\n/** @ignore */\nexports.magicLength = exports.MAGIC.length;\n/** @ignore */\nexports.magicAndPadding = exports.magicLength + exports.PADDING;\n/** @ignore */\nexports.magicX2AndPadding = exports.magicLength * 2 + exports.PADDING;\n\n//# sourceMappingURL=message.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/* tslint:disable:class-name */\nconst File_ = require(\"../../fb/File\");\nconst flatbuffers_1 = require(\"flatbuffers\");\nvar Long = flatbuffers_1.flatbuffers.Long;\nvar Builder = flatbuffers_1.flatbuffers.Builder;\nvar ByteBuffer = flatbuffers_1.flatbuffers.ByteBuffer;\nvar _Block = File_.org.apache.arrow.flatbuf.Block;\nvar _Footer = File_.org.apache.arrow.flatbuf.Footer;\nconst schema_1 = require(\"../../schema\");\nconst enum_1 = require(\"../../enum\");\nconst buffer_1 = require(\"../../util/buffer\");\n/** @ignore */\nclass Footer_ {\n    constructor(schema, version = enum_1.MetadataVersion.V4, recordBatches, dictionaryBatches) {\n        this.schema = schema;\n        this.version = version;\n        recordBatches && (this._recordBatches = recordBatches);\n        dictionaryBatches && (this._dictionaryBatches = dictionaryBatches);\n    }\n    /** @nocollapse */\n    static decode(buf) {\n        buf = new ByteBuffer(buffer_1.toUint8Array(buf));\n        const footer = _Footer.getRootAsFooter(buf);\n        const schema = schema_1.Schema.decode(footer.schema());\n        return new OffHeapFooter(schema, footer);\n    }\n    /** @nocollapse */\n    static encode(footer) {\n        const b = new Builder();\n        const schemaOffset = schema_1.Schema.encode(b, footer.schema);\n        _Footer.startRecordBatchesVector(b, footer.numRecordBatches);\n        [...footer.recordBatches()].slice().reverse().forEach((rb) => FileBlock.encode(b, rb));\n        const recordBatchesOffset = b.endVector();\n        _Footer.startDictionariesVector(b, footer.numDictionaries);\n        [...footer.dictionaryBatches()].slice().reverse().forEach((db) => FileBlock.encode(b, db));\n        const dictionaryBatchesOffset = b.endVector();\n        _Footer.startFooter(b);\n        _Footer.addSchema(b, schemaOffset);\n        _Footer.addVersion(b, enum_1.MetadataVersion.V4);\n        _Footer.addRecordBatches(b, recordBatchesOffset);\n        _Footer.addDictionaries(b, dictionaryBatchesOffset);\n        _Footer.finishFooterBuffer(b, _Footer.endFooter(b));\n        return b.asUint8Array();\n    }\n    get numRecordBatches() { return this._recordBatches.length; }\n    get numDictionaries() { return this._dictionaryBatches.length; }\n    *recordBatches() {\n        for (let block, i = -1, n = this.numRecordBatches; ++i < n;) {\n            if (block = this.getRecordBatch(i)) {\n                yield block;\n            }\n        }\n    }\n    *dictionaryBatches() {\n        for (let block, i = -1, n = this.numDictionaries; ++i < n;) {\n            if (block = this.getDictionaryBatch(i)) {\n                yield block;\n            }\n        }\n    }\n    getRecordBatch(index) {\n        return index >= 0\n            && index < this.numRecordBatches\n            && this._recordBatches[index] || null;\n    }\n    getDictionaryBatch(index) {\n        return index >= 0\n            && index < this.numDictionaries\n            && this._dictionaryBatches[index] || null;\n    }\n}\nexports.Footer = Footer_;\n/** @ignore */\nclass OffHeapFooter extends Footer_ {\n    constructor(schema, _footer) {\n        super(schema, _footer.version());\n        this._footer = _footer;\n    }\n    get numRecordBatches() { return this._footer.recordBatchesLength(); }\n    get numDictionaries() { return this._footer.dictionariesLength(); }\n    getRecordBatch(index) {\n        if (index >= 0 && index < this.numRecordBatches) {\n            const fileBlock = this._footer.recordBatches(index);\n            if (fileBlock) {\n                return FileBlock.decode(fileBlock);\n            }\n        }\n        return null;\n    }\n    getDictionaryBatch(index) {\n        if (index >= 0 && index < this.numDictionaries) {\n            const fileBlock = this._footer.dictionaries(index);\n            if (fileBlock) {\n                return FileBlock.decode(fileBlock);\n            }\n        }\n        return null;\n    }\n}\n/** @ignore */\nclass FileBlock {\n    /** @nocollapse */\n    static decode(block) {\n        return new FileBlock(block.metaDataLength(), block.bodyLength(), block.offset());\n    }\n    /** @nocollapse */\n    static encode(b, fileBlock) {\n        const { metaDataLength } = fileBlock;\n        const offset = new Long(fileBlock.offset, 0);\n        const bodyLength = new Long(fileBlock.bodyLength, 0);\n        return _Block.createBlock(b, offset, metaDataLength, bodyLength);\n    }\n    constructor(metaDataLength, bodyLength, offset) {\n        this.metaDataLength = metaDataLength;\n        this.offset = typeof offset === 'number' ? offset : offset.low;\n        this.bodyLength = typeof bodyLength === 'number' ? bodyLength : bodyLength.low;\n    }\n}\nexports.FileBlock = FileBlock;\n\n//# sourceMappingURL=file.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst schema_1 = require(\"../../schema\");\nconst type_1 = require(\"../../type\");\nconst message_1 = require(\"./message\");\nconst enum_1 = require(\"../../enum\");\n/** @ignore */\nfunction schemaFromJSON(_schema, dictionaries = new Map()) {\n    return new schema_1.Schema(schemaFieldsFromJSON(_schema, dictionaries), customMetadataFromJSON(_schema['customMetadata']), dictionaries);\n}\nexports.schemaFromJSON = schemaFromJSON;\n/** @ignore */\nfunction recordBatchFromJSON(b) {\n    return new message_1.RecordBatch(b['count'], fieldNodesFromJSON(b['columns']), buffersFromJSON(b['columns']));\n}\nexports.recordBatchFromJSON = recordBatchFromJSON;\n/** @ignore */\nfunction dictionaryBatchFromJSON(b) {\n    return new message_1.DictionaryBatch(recordBatchFromJSON(b['data']), b['id'], b['isDelta']);\n}\nexports.dictionaryBatchFromJSON = dictionaryBatchFromJSON;\n/** @ignore */\nfunction schemaFieldsFromJSON(_schema, dictionaries) {\n    return (_schema['fields'] || []).filter(Boolean).map((f) => schema_1.Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldChildrenFromJSON(_field, dictionaries) {\n    return (_field['children'] || []).filter(Boolean).map((f) => schema_1.Field.fromJSON(f, dictionaries));\n}\n/** @ignore */\nfunction fieldNodesFromJSON(xs) {\n    return (xs || []).reduce((fieldNodes, column) => [\n        ...fieldNodes,\n        new message_1.FieldNode(column['count'], nullCountFromJSON(column['VALIDITY'])),\n        ...fieldNodesFromJSON(column['children'])\n    ], []);\n}\n/** @ignore */\nfunction buffersFromJSON(xs, buffers = []) {\n    for (let i = -1, n = (xs || []).length; ++i < n;) {\n        const column = xs[i];\n        column['VALIDITY'] && buffers.push(new message_1.BufferRegion(buffers.length, column['VALIDITY'].length));\n        column['TYPE'] && buffers.push(new message_1.BufferRegion(buffers.length, column['TYPE'].length));\n        column['OFFSET'] && buffers.push(new message_1.BufferRegion(buffers.length, column['OFFSET'].length));\n        column['DATA'] && buffers.push(new message_1.BufferRegion(buffers.length, column['DATA'].length));\n        buffers = buffersFromJSON(column['children'], buffers);\n    }\n    return buffers;\n}\n/** @ignore */\nfunction nullCountFromJSON(validity) {\n    return (validity || []).reduce((sum, val) => sum + +(val === 0), 0);\n}\n/** @ignore */\nfunction fieldFromJSON(_field, dictionaries) {\n    let id;\n    let keys;\n    let field;\n    let dictMeta;\n    let type;\n    let dictType;\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = _field['dictionary'])) {\n        type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries));\n        field = new schema_1.Field(_field['name'], type, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta['id'])) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new type_1.Int32();\n        dictionaries.set(id, type = typeFromJSON(_field, fieldChildrenFromJSON(_field, dictionaries)));\n        dictType = new type_1.Dictionary(type, keys, id, dictMeta['isOrdered']);\n        field = new schema_1.Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta['indexType']) ? indexTypeFromJSON(keys) : new type_1.Int32();\n        dictType = new type_1.Dictionary(dictionaries.get(id), keys, id, dictMeta['isOrdered']);\n        field = new schema_1.Field(_field['name'], dictType, _field['nullable'], customMetadataFromJSON(_field['customMetadata']));\n    }\n    return field || null;\n}\nexports.fieldFromJSON = fieldFromJSON;\n/** @ignore */\nfunction customMetadataFromJSON(_metadata) {\n    return new Map(Object.entries(_metadata || {}));\n}\n/** @ignore */\nfunction indexTypeFromJSON(_type) {\n    return new type_1.Int(_type['isSigned'], _type['bitWidth']);\n}\n/** @ignore */\nfunction typeFromJSON(f, children) {\n    const typeId = f['type']['name'];\n    switch (typeId) {\n        case 'NONE': return new type_1.Null();\n        case 'null': return new type_1.Null();\n        case 'binary': return new type_1.Binary();\n        case 'utf8': return new type_1.Utf8();\n        case 'bool': return new type_1.Bool();\n        case 'list': return new type_1.List((children || [])[0]);\n        case 'struct': return new type_1.Struct(children || []);\n        case 'struct_': return new type_1.Struct(children || []);\n    }\n    switch (typeId) {\n        case 'int': {\n            const t = f['type'];\n            return new type_1.Int(t['isSigned'], t['bitWidth']);\n        }\n        case 'floatingpoint': {\n            const t = f['type'];\n            return new type_1.Float(enum_1.Precision[t['precision']]);\n        }\n        case 'decimal': {\n            const t = f['type'];\n            return new type_1.Decimal(t['scale'], t['precision']);\n        }\n        case 'date': {\n            const t = f['type'];\n            return new type_1.Date_(enum_1.DateUnit[t['unit']]);\n        }\n        case 'time': {\n            const t = f['type'];\n            return new type_1.Time(enum_1.TimeUnit[t['unit']], t['bitWidth']);\n        }\n        case 'timestamp': {\n            const t = f['type'];\n            return new type_1.Timestamp(enum_1.TimeUnit[t['unit']], t['timezone']);\n        }\n        case 'interval': {\n            const t = f['type'];\n            return new type_1.Interval(enum_1.IntervalUnit[t['unit']]);\n        }\n        case 'union': {\n            const t = f['type'];\n            return new type_1.Union(enum_1.UnionMode[t['mode']], (t['typeIds'] || []), children || []);\n        }\n        case 'fixedsizebinary': {\n            const t = f['type'];\n            return new type_1.FixedSizeBinary(t['byteWidth']);\n        }\n        case 'fixedsizelist': {\n            const t = f['type'];\n            return new type_1.FixedSizeList(t['listSize'], (children || [])[0]);\n        }\n        case 'map': {\n            const t = f['type'];\n            return new type_1.Map_((children || [])[0], t['keysSorted']);\n        }\n    }\n    throw new Error(`Unrecognized type: \"${typeId}\"`);\n}\n\n//# sourceMappingURL=json.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst flatbuffers_1 = require(\"flatbuffers\");\nconst Schema_ = require(\"../../fb/Schema\");\nconst Message_ = require(\"../../fb/Message\");\nconst schema_1 = require(\"../../schema\");\nconst buffer_1 = require(\"../../util/buffer\");\nconst enum_1 = require(\"../../enum\");\nconst typeassembler_1 = require(\"../../visitor/typeassembler\");\nconst json_1 = require(\"./json\");\nvar Long = flatbuffers_1.flatbuffers.Long;\nvar Builder = flatbuffers_1.flatbuffers.Builder;\nvar ByteBuffer = flatbuffers_1.flatbuffers.ByteBuffer;\nvar Type = Schema_.org.apache.arrow.flatbuf.Type;\nvar _Field = Schema_.org.apache.arrow.flatbuf.Field;\nvar _Schema = Schema_.org.apache.arrow.flatbuf.Schema;\nvar _Buffer = Schema_.org.apache.arrow.flatbuf.Buffer;\nvar _Message = Message_.org.apache.arrow.flatbuf.Message;\nvar _KeyValue = Schema_.org.apache.arrow.flatbuf.KeyValue;\nvar _FieldNode = Message_.org.apache.arrow.flatbuf.FieldNode;\nvar _Endianness = Schema_.org.apache.arrow.flatbuf.Endianness;\nvar _RecordBatch = Message_.org.apache.arrow.flatbuf.RecordBatch;\nvar _DictionaryBatch = Message_.org.apache.arrow.flatbuf.DictionaryBatch;\nconst type_1 = require(\"../../type\");\n/**\n * @ignore\n * @private\n **/\nclass Message {\n    constructor(bodyLength, version, headerType, header) {\n        this._version = version;\n        this._headerType = headerType;\n        this.body = new Uint8Array(0);\n        header && (this._createHeader = () => header);\n        this._bodyLength = typeof bodyLength === 'number' ? bodyLength : bodyLength.low;\n    }\n    /** @nocollapse */\n    static fromJSON(msg, headerType) {\n        const message = new Message(0, enum_1.MetadataVersion.V4, headerType);\n        message._createHeader = messageHeaderFromJSON(msg, headerType);\n        return message;\n    }\n    /** @nocollapse */\n    static decode(buf) {\n        buf = new ByteBuffer(buffer_1.toUint8Array(buf));\n        const _message = _Message.getRootAsMessage(buf);\n        const bodyLength = _message.bodyLength();\n        const version = _message.version();\n        const headerType = _message.headerType();\n        const message = new Message(bodyLength, version, headerType);\n        message._createHeader = decodeMessageHeader(_message, headerType);\n        return message;\n    }\n    /** @nocollapse */\n    static encode(message) {\n        let b = new Builder(), headerOffset = -1;\n        if (message.isSchema()) {\n            headerOffset = schema_1.Schema.encode(b, message.header());\n        }\n        else if (message.isRecordBatch()) {\n            headerOffset = RecordBatch.encode(b, message.header());\n        }\n        else if (message.isDictionaryBatch()) {\n            headerOffset = DictionaryBatch.encode(b, message.header());\n        }\n        _Message.startMessage(b);\n        _Message.addVersion(b, enum_1.MetadataVersion.V4);\n        _Message.addHeader(b, headerOffset);\n        _Message.addHeaderType(b, message.headerType);\n        _Message.addBodyLength(b, new Long(message.bodyLength, 0));\n        _Message.finishMessageBuffer(b, _Message.endMessage(b));\n        return b.asUint8Array();\n    }\n    /** @nocollapse */\n    static from(header, bodyLength = 0) {\n        if (header instanceof schema_1.Schema) {\n            return new Message(0, enum_1.MetadataVersion.V4, enum_1.MessageHeader.Schema, header);\n        }\n        if (header instanceof RecordBatch) {\n            return new Message(bodyLength, enum_1.MetadataVersion.V4, enum_1.MessageHeader.RecordBatch, header);\n        }\n        if (header instanceof DictionaryBatch) {\n            return new Message(bodyLength, enum_1.MetadataVersion.V4, enum_1.MessageHeader.DictionaryBatch, header);\n        }\n        throw new Error(`Unrecognized Message header: ${header}`);\n    }\n    get type() { return this.headerType; }\n    get version() { return this._version; }\n    get headerType() { return this._headerType; }\n    get bodyLength() { return this._bodyLength; }\n    header() { return this._createHeader(); }\n    isSchema() { return this.headerType === enum_1.MessageHeader.Schema; }\n    isRecordBatch() { return this.headerType === enum_1.MessageHeader.RecordBatch; }\n    isDictionaryBatch() { return this.headerType === enum_1.MessageHeader.DictionaryBatch; }\n}\nexports.Message = Message;\n/**\n * @ignore\n * @private\n **/\nclass RecordBatch {\n    get nodes() { return this._nodes; }\n    get length() { return this._length; }\n    get buffers() { return this._buffers; }\n    constructor(length, nodes, buffers) {\n        this._nodes = nodes;\n        this._buffers = buffers;\n        this._length = typeof length === 'number' ? length : length.low;\n    }\n}\nexports.RecordBatch = RecordBatch;\n/**\n * @ignore\n * @private\n **/\nclass DictionaryBatch {\n    get id() { return this._id; }\n    get data() { return this._data; }\n    get isDelta() { return this._isDelta; }\n    get length() { return this.data.length; }\n    get nodes() { return this.data.nodes; }\n    get buffers() { return this.data.buffers; }\n    constructor(data, id, isDelta = false) {\n        this._data = data;\n        this._isDelta = isDelta;\n        this._id = typeof id === 'number' ? id : id.low;\n    }\n}\nexports.DictionaryBatch = DictionaryBatch;\n/**\n * @ignore\n * @private\n **/\nclass BufferRegion {\n    constructor(offset, length) {\n        this.offset = typeof offset === 'number' ? offset : offset.low;\n        this.length = typeof length === 'number' ? length : length.low;\n    }\n}\nexports.BufferRegion = BufferRegion;\n/**\n * @ignore\n * @private\n **/\nclass FieldNode {\n    constructor(length, nullCount) {\n        this.length = typeof length === 'number' ? length : length.low;\n        this.nullCount = typeof nullCount === 'number' ? nullCount : nullCount.low;\n    }\n}\nexports.FieldNode = FieldNode;\n/** @ignore */\nfunction messageHeaderFromJSON(message, type) {\n    return (() => {\n        switch (type) {\n            case enum_1.MessageHeader.Schema: return schema_1.Schema.fromJSON(message);\n            case enum_1.MessageHeader.RecordBatch: return RecordBatch.fromJSON(message);\n            case enum_1.MessageHeader.DictionaryBatch: return DictionaryBatch.fromJSON(message);\n        }\n        throw new Error(`Unrecognized Message type: { name: ${enum_1.MessageHeader[type]}, type: ${type} }`);\n    });\n}\n/** @ignore */\nfunction decodeMessageHeader(message, type) {\n    return (() => {\n        switch (type) {\n            case enum_1.MessageHeader.Schema: return schema_1.Schema.decode(message.header(new _Schema()));\n            case enum_1.MessageHeader.RecordBatch: return RecordBatch.decode(message.header(new _RecordBatch()), message.version());\n            case enum_1.MessageHeader.DictionaryBatch: return DictionaryBatch.decode(message.header(new _DictionaryBatch()), message.version());\n        }\n        throw new Error(`Unrecognized Message type: { name: ${enum_1.MessageHeader[type]}, type: ${type} }`);\n    });\n}\nschema_1.Field['encode'] = encodeField;\nschema_1.Field['decode'] = decodeField;\nschema_1.Field['fromJSON'] = json_1.fieldFromJSON;\nschema_1.Schema['encode'] = encodeSchema;\nschema_1.Schema['decode'] = decodeSchema;\nschema_1.Schema['fromJSON'] = json_1.schemaFromJSON;\nRecordBatch['encode'] = encodeRecordBatch;\nRecordBatch['decode'] = decodeRecordBatch;\nRecordBatch['fromJSON'] = json_1.recordBatchFromJSON;\nDictionaryBatch['encode'] = encodeDictionaryBatch;\nDictionaryBatch['decode'] = decodeDictionaryBatch;\nDictionaryBatch['fromJSON'] = json_1.dictionaryBatchFromJSON;\nFieldNode['encode'] = encodeFieldNode;\nFieldNode['decode'] = decodeFieldNode;\nBufferRegion['encode'] = encodeBufferRegion;\nBufferRegion['decode'] = decodeBufferRegion;\n/** @ignore */\nfunction decodeSchema(_schema, dictionaries = new Map()) {\n    const fields = decodeSchemaFields(_schema, dictionaries);\n    return new schema_1.Schema(fields, decodeCustomMetadata(_schema), dictionaries);\n}\n/** @ignore */\nfunction decodeRecordBatch(batch, version = enum_1.MetadataVersion.V4) {\n    return new RecordBatch(batch.length(), decodeFieldNodes(batch), decodeBuffers(batch, version));\n}\n/** @ignore */\nfunction decodeDictionaryBatch(batch, version = enum_1.MetadataVersion.V4) {\n    return new DictionaryBatch(RecordBatch.decode(batch.data(), version), batch.id(), batch.isDelta());\n}\n/** @ignore */\nfunction decodeBufferRegion(b) {\n    return new BufferRegion(b.offset(), b.length());\n}\n/** @ignore */\nfunction decodeFieldNode(f) {\n    return new FieldNode(f.length(), f.nullCount());\n}\n/** @ignore */\nfunction decodeFieldNodes(batch) {\n    const nodes = [];\n    for (let f, i = -1, j = -1, n = batch.nodesLength(); ++i < n;) {\n        if (f = batch.nodes(i)) {\n            nodes[++j] = FieldNode.decode(f);\n        }\n    }\n    return nodes;\n}\n/** @ignore */\nfunction decodeBuffers(batch, version) {\n    const bufferRegions = [];\n    for (let b, i = -1, j = -1, n = batch.buffersLength(); ++i < n;) {\n        if (b = batch.buffers(i)) {\n            // If this Arrow buffer was written before version 4,\n            // advance the buffer's bb_pos 8 bytes to skip past\n            // the now-removed page_id field\n            if (version < enum_1.MetadataVersion.V4) {\n                b.bb_pos += (8 * (i + 1));\n            }\n            bufferRegions[++j] = BufferRegion.decode(b);\n        }\n    }\n    return bufferRegions;\n}\n/** @ignore */\nfunction decodeSchemaFields(schema, dictionaries) {\n    const fields = [];\n    for (let f, i = -1, j = -1, n = schema.fieldsLength(); ++i < n;) {\n        if (f = schema.fields(i)) {\n            fields[++j] = schema_1.Field.decode(f, dictionaries);\n        }\n    }\n    return fields;\n}\n/** @ignore */\nfunction decodeFieldChildren(field, dictionaries) {\n    const children = [];\n    for (let f, i = -1, j = -1, n = field.childrenLength(); ++i < n;) {\n        if (f = field.children(i)) {\n            children[++j] = schema_1.Field.decode(f, dictionaries);\n        }\n    }\n    return children;\n}\n/** @ignore */\nfunction decodeField(f, dictionaries) {\n    let id;\n    let field;\n    let type;\n    let keys;\n    let dictType;\n    let dictMeta;\n    // If no dictionary encoding\n    if (!dictionaries || !(dictMeta = f.dictionary())) {\n        type = decodeFieldType(f, decodeFieldChildren(f, dictionaries));\n        field = new schema_1.Field(f.name(), type, f.nullable(), decodeCustomMetadata(f));\n    }\n    // tslint:disable\n    // If dictionary encoded and the first time we've seen this dictionary id, decode\n    // the data type and child fields, then wrap in a Dictionary type and insert the\n    // data type into the dictionary types map.\n    else if (!dictionaries.has(id = dictMeta.id().low)) {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta.indexType()) ? decodeIndexType(keys) : new type_1.Int32();\n        dictionaries.set(id, type = decodeFieldType(f, decodeFieldChildren(f, dictionaries)));\n        dictType = new type_1.Dictionary(type, keys, id, dictMeta.isOrdered());\n        field = new schema_1.Field(f.name(), dictType, f.nullable(), decodeCustomMetadata(f));\n    }\n    // If dictionary encoded, and have already seen this dictionary Id in the schema, then reuse the\n    // data type and wrap in a new Dictionary type and field.\n    else {\n        // a dictionary index defaults to signed 32 bit int if unspecified\n        keys = (keys = dictMeta.indexType()) ? decodeIndexType(keys) : new type_1.Int32();\n        dictType = new type_1.Dictionary(dictionaries.get(id), keys, id, dictMeta.isOrdered());\n        field = new schema_1.Field(f.name(), dictType, f.nullable(), decodeCustomMetadata(f));\n    }\n    return field || null;\n}\n/** @ignore */\nfunction decodeCustomMetadata(parent) {\n    const data = new Map();\n    if (parent) {\n        for (let entry, key, i = -1, n = parent.customMetadataLength() | 0; ++i < n;) {\n            if ((entry = parent.customMetadata(i)) && (key = entry.key()) != null) {\n                data.set(key, entry.value());\n            }\n        }\n    }\n    return data;\n}\n/** @ignore */\nfunction decodeIndexType(_type) {\n    return new type_1.Int(_type.isSigned(), _type.bitWidth());\n}\n/** @ignore */\nfunction decodeFieldType(f, children) {\n    const typeId = f.typeType();\n    switch (typeId) {\n        case Type.NONE: return new type_1.Null();\n        case Type.Null: return new type_1.Null();\n        case Type.Binary: return new type_1.Binary();\n        case Type.Utf8: return new type_1.Utf8();\n        case Type.Bool: return new type_1.Bool();\n        case Type.List: return new type_1.List((children || [])[0]);\n        case Type.Struct_: return new type_1.Struct(children || []);\n    }\n    switch (typeId) {\n        case Type.Int: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Int());\n            return new type_1.Int(t.isSigned(), t.bitWidth());\n        }\n        case Type.FloatingPoint: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.FloatingPoint());\n            return new type_1.Float(t.precision());\n        }\n        case Type.Decimal: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Decimal());\n            return new type_1.Decimal(t.scale(), t.precision());\n        }\n        case Type.Date: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Date());\n            return new type_1.Date_(t.unit());\n        }\n        case Type.Time: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Time());\n            return new type_1.Time(t.unit(), t.bitWidth());\n        }\n        case Type.Timestamp: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Timestamp());\n            return new type_1.Timestamp(t.unit(), t.timezone());\n        }\n        case Type.Interval: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Interval());\n            return new type_1.Interval(t.unit());\n        }\n        case Type.Union: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Union());\n            return new type_1.Union(t.mode(), t.typeIdsArray() || [], children || []);\n        }\n        case Type.FixedSizeBinary: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.FixedSizeBinary());\n            return new type_1.FixedSizeBinary(t.byteWidth());\n        }\n        case Type.FixedSizeList: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.FixedSizeList());\n            return new type_1.FixedSizeList(t.listSize(), (children || [])[0]);\n        }\n        case Type.Map: {\n            const t = f.type(new Schema_.org.apache.arrow.flatbuf.Map());\n            return new type_1.Map_((children || [])[0], t.keysSorted());\n        }\n    }\n    throw new Error(`Unrecognized type: \"${Type[typeId]}\" (${typeId})`);\n}\n/** @ignore */\nfunction encodeSchema(b, schema) {\n    const fieldOffsets = schema.fields.map((f) => schema_1.Field.encode(b, f));\n    _Schema.startFieldsVector(b, fieldOffsets.length);\n    const fieldsVectorOffset = _Schema.createFieldsVector(b, fieldOffsets);\n    const metadataOffset = !(schema.metadata && schema.metadata.size > 0) ? -1 :\n        _Schema.createCustomMetadataVector(b, [...schema.metadata].map(([k, v]) => {\n            const key = b.createString(`${k}`);\n            const val = b.createString(`${v}`);\n            _KeyValue.startKeyValue(b);\n            _KeyValue.addKey(b, key);\n            _KeyValue.addValue(b, val);\n            return _KeyValue.endKeyValue(b);\n        }));\n    _Schema.startSchema(b);\n    _Schema.addFields(b, fieldsVectorOffset);\n    _Schema.addEndianness(b, platformIsLittleEndian ? _Endianness.Little : _Endianness.Big);\n    if (metadataOffset !== -1) {\n        _Schema.addCustomMetadata(b, metadataOffset);\n    }\n    return _Schema.endSchema(b);\n}\n/** @ignore */\nfunction encodeField(b, field) {\n    let nameOffset = -1;\n    let typeOffset = -1;\n    let dictionaryOffset = -1;\n    let type = field.type;\n    let typeId = field.typeId;\n    if (!type_1.DataType.isDictionary(type)) {\n        typeOffset = typeassembler_1.instance.visit(type, b);\n    }\n    else {\n        typeId = type.dictionary.typeId;\n        dictionaryOffset = typeassembler_1.instance.visit(type, b);\n        typeOffset = typeassembler_1.instance.visit(type.dictionary, b);\n    }\n    const childOffsets = (type.children || []).map((f) => schema_1.Field.encode(b, f));\n    const childrenVectorOffset = _Field.createChildrenVector(b, childOffsets);\n    const metadataOffset = !(field.metadata && field.metadata.size > 0) ? -1 :\n        _Field.createCustomMetadataVector(b, [...field.metadata].map(([k, v]) => {\n            const key = b.createString(`${k}`);\n            const val = b.createString(`${v}`);\n            _KeyValue.startKeyValue(b);\n            _KeyValue.addKey(b, key);\n            _KeyValue.addValue(b, val);\n            return _KeyValue.endKeyValue(b);\n        }));\n    if (field.name) {\n        nameOffset = b.createString(field.name);\n    }\n    _Field.startField(b);\n    _Field.addType(b, typeOffset);\n    _Field.addTypeType(b, typeId);\n    _Field.addChildren(b, childrenVectorOffset);\n    _Field.addNullable(b, !!field.nullable);\n    if (nameOffset !== -1) {\n        _Field.addName(b, nameOffset);\n    }\n    if (dictionaryOffset !== -1) {\n        _Field.addDictionary(b, dictionaryOffset);\n    }\n    if (metadataOffset !== -1) {\n        _Field.addCustomMetadata(b, metadataOffset);\n    }\n    return _Field.endField(b);\n}\n/** @ignore */\nfunction encodeRecordBatch(b, recordBatch) {\n    const nodes = recordBatch.nodes || [];\n    const buffers = recordBatch.buffers || [];\n    _RecordBatch.startNodesVector(b, nodes.length);\n    nodes.slice().reverse().forEach((n) => FieldNode.encode(b, n));\n    const nodesVectorOffset = b.endVector();\n    _RecordBatch.startBuffersVector(b, buffers.length);\n    buffers.slice().reverse().forEach((b_) => BufferRegion.encode(b, b_));\n    const buffersVectorOffset = b.endVector();\n    _RecordBatch.startRecordBatch(b);\n    _RecordBatch.addLength(b, new Long(recordBatch.length, 0));\n    _RecordBatch.addNodes(b, nodesVectorOffset);\n    _RecordBatch.addBuffers(b, buffersVectorOffset);\n    return _RecordBatch.endRecordBatch(b);\n}\n/** @ignore */\nfunction encodeDictionaryBatch(b, dictionaryBatch) {\n    const dataOffset = RecordBatch.encode(b, dictionaryBatch.data);\n    _DictionaryBatch.startDictionaryBatch(b);\n    _DictionaryBatch.addId(b, new Long(dictionaryBatch.id, 0));\n    _DictionaryBatch.addIsDelta(b, dictionaryBatch.isDelta);\n    _DictionaryBatch.addData(b, dataOffset);\n    return _DictionaryBatch.endDictionaryBatch(b);\n}\n/** @ignore */\nfunction encodeFieldNode(b, node) {\n    return _FieldNode.createFieldNode(b, new Long(node.length, 0), new Long(node.nullCount, 0));\n}\n/** @ignore */\nfunction encodeBufferRegion(b, node) {\n    return _Buffer.createBuffer(b, new Long(node.offset, 0), new Long(node.length, 0));\n}\n/** @ignore */\nconst platformIsLittleEndian = (function () {\n    const buffer = new ArrayBuffer(2);\n    new DataView(buffer).setInt16(0, 256, true /* littleEndian */);\n    // Int16Array uses the platform's endianness.\n    return new Int16Array(buffer)[0] === 256;\n})();\n\n//# sourceMappingURL=message.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\nconst enum_1 = require(\"../enum\");\nconst file_1 = require(\"./metadata/file\");\nconst adapters_1 = require(\"../io/adapters\");\nconst stream_1 = require(\"../io/stream\");\nconst file_2 = require(\"../io/file\");\nconst vectorloader_1 = require(\"../visitor/vectorloader\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst interfaces_1 = require(\"../io/interfaces\");\nconst message_1 = require(\"./message\");\nconst compat_1 = require(\"../util/compat\");\nclass RecordBatchReader extends interfaces_1.ReadableInterop {\n    constructor(impl) {\n        super();\n        this._impl = impl;\n    }\n    get closed() { return this._impl.closed; }\n    get schema() { return this._impl.schema; }\n    get autoDestroy() { return this._impl.autoDestroy; }\n    get dictionaries() { return this._impl.dictionaries; }\n    get numDictionaries() { return this._impl.numDictionaries; }\n    get numRecordBatches() { return this._impl.numRecordBatches; }\n    get footer() { return this._impl.isFile() ? this._impl.footer : null; }\n    isSync() { return this._impl.isSync(); }\n    isAsync() { return this._impl.isAsync(); }\n    isFile() { return this._impl.isFile(); }\n    isStream() { return this._impl.isStream(); }\n    next() {\n        return this._impl.next();\n    }\n    throw(value) {\n        return this._impl.throw(value);\n    }\n    return(value) {\n        return this._impl.return(value);\n    }\n    cancel() {\n        return this._impl.cancel();\n    }\n    reset(schema) {\n        this._impl.reset(schema);\n        this._DOMStream = undefined;\n        this._nodeStream = undefined;\n        return this;\n    }\n    open(options) {\n        const opening = this._impl.open(options);\n        return compat_1.isPromise(opening) ? opening.then(() => this) : this;\n    }\n    readRecordBatch(index) {\n        return this._impl.isFile() ? this._impl.readRecordBatch(index) : null;\n    }\n    [Symbol.iterator]() {\n        return this._impl[Symbol.iterator]();\n    }\n    [Symbol.asyncIterator]() {\n        return this._impl[Symbol.asyncIterator]();\n    }\n    toDOMStream() {\n        return adapters_1.default.toDOMStream((this.isSync()\n            ? { [Symbol.iterator]: () => this }\n            : { [Symbol.asyncIterator]: () => this }));\n    }\n    toNodeStream() {\n        return adapters_1.default.toNodeStream((this.isSync()\n            ? { [Symbol.iterator]: () => this }\n            : { [Symbol.asyncIterator]: () => this }), { objectMode: true });\n    }\n    /** @nocollapse */\n    // @ts-ignore\n    static throughNode(options) {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    static throughDOM(\n    // @ts-ignore\n    writableStrategy, \n    // @ts-ignore\n    readableStrategy) {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n    /** @nocollapse */\n    static from(source) {\n        if (source instanceof RecordBatchReader) {\n            return source;\n        }\n        else if (compat_1.isArrowJSON(source)) {\n            return fromArrowJSON(source);\n        }\n        else if (compat_1.isFileHandle(source)) {\n            return fromFileHandle(source);\n        }\n        else if (compat_1.isPromise(source)) {\n            return (async () => await RecordBatchReader.from(await source))();\n        }\n        else if (compat_1.isFetchResponse(source) || compat_1.isReadableDOMStream(source) || compat_1.isReadableNodeStream(source) || compat_1.isAsyncIterable(source)) {\n            return fromAsyncByteStream(new stream_1.AsyncByteStream(source));\n        }\n        return fromByteStream(new stream_1.ByteStream(source));\n    }\n    /** @nocollapse */\n    static readAll(source) {\n        if (source instanceof RecordBatchReader) {\n            return source.isSync() ? readAllSync(source) : readAllAsync(source);\n        }\n        else if (compat_1.isArrowJSON(source) || ArrayBuffer.isView(source) || compat_1.isIterable(source) || compat_1.isIteratorResult(source)) {\n            return readAllSync(source);\n        }\n        return readAllAsync(source);\n    }\n}\nexports.RecordBatchReader = RecordBatchReader;\n//\n// Since TS is a structural type system, we define the following subclass stubs\n// so that concrete types exist to associate with with the interfaces below.\n//\n// The implementation for each RecordBatchReader is hidden away in the set of\n// `RecordBatchReaderImpl` classes in the second half of this file. This allows\n// us to export a single RecordBatchReader class, and swap out the impl based\n// on the io primitives or underlying arrow (JSON, file, or stream) at runtime.\n//\n// Async/await makes our job a bit harder, since it forces everything to be\n// either fully sync or fully async. This is why the logic for the reader impls\n// has been duplicated into both sync and async variants. Since the RBR\n// delegates to its impl, an RBR with an AsyncRecordBatchFileReaderImpl for\n// example will return async/await-friendly Promises, but one with a (sync)\n// RecordBatchStreamReaderImpl will always return values. Nothing should be\n// different about their logic, aside from the async handling. This is also why\n// this code looks highly structured, as it should be nearly identical and easy\n// to follow.\n//\n/** @ignore */\nclass RecordBatchStreamReader extends RecordBatchReader {\n    constructor(_impl) {\n        super(_impl);\n        this._impl = _impl;\n    }\n    [Symbol.iterator]() { return this._impl[Symbol.iterator](); }\n    async *[Symbol.asyncIterator]() { yield* this[Symbol.iterator](); }\n}\nexports.RecordBatchStreamReader = RecordBatchStreamReader;\n/** @ignore */\nclass AsyncRecordBatchStreamReader extends RecordBatchReader {\n    constructor(_impl) {\n        super(_impl);\n        this._impl = _impl;\n    }\n    [Symbol.iterator]() { throw new Error(`AsyncRecordBatchStreamReader is not Iterable`); }\n    [Symbol.asyncIterator]() { return this._impl[Symbol.asyncIterator](); }\n}\nexports.AsyncRecordBatchStreamReader = AsyncRecordBatchStreamReader;\n/** @ignore */\nclass RecordBatchFileReader extends RecordBatchStreamReader {\n    constructor(_impl) {\n        super(_impl);\n        this._impl = _impl;\n    }\n}\nexports.RecordBatchFileReader = RecordBatchFileReader;\n/** @ignore */\nclass AsyncRecordBatchFileReader extends AsyncRecordBatchStreamReader {\n    constructor(_impl) {\n        super(_impl);\n        this._impl = _impl;\n    }\n}\nexports.AsyncRecordBatchFileReader = AsyncRecordBatchFileReader;\n/** @ignore */\nclass RecordBatchReaderImpl {\n    constructor(dictionaries = new Map()) {\n        this.closed = false;\n        this.autoDestroy = true;\n        this._dictionaryIndex = 0;\n        this._recordBatchIndex = 0;\n        this.dictionaries = dictionaries;\n    }\n    get numDictionaries() { return this._dictionaryIndex; }\n    get numRecordBatches() { return this._recordBatchIndex; }\n    isSync() { return false; }\n    isAsync() { return false; }\n    isFile() { return false; }\n    isStream() { return false; }\n    reset(schema) {\n        this._dictionaryIndex = 0;\n        this._recordBatchIndex = 0;\n        this.schema = schema;\n        this.dictionaries = new Map();\n        return this;\n    }\n    _loadRecordBatch(header, body) {\n        return new recordbatch_1.RecordBatch(this.schema, header.length, this._loadVectors(header, body, this.schema.fields));\n    }\n    _loadDictionaryBatch(header, body) {\n        const { id, isDelta, data } = header;\n        const { dictionaries, schema } = this;\n        const dictionary = dictionaries.get(id);\n        if (isDelta || !dictionary) {\n            const type = schema.dictionaries.get(id);\n            return (dictionary && isDelta ? dictionary.concat(vector_1.Vector.new(this._loadVectors(data, body, [type])[0])) :\n                vector_1.Vector.new(this._loadVectors(data, body, [type])[0]));\n        }\n        return dictionary;\n    }\n    _loadVectors(header, body, types) {\n        return new vectorloader_1.VectorLoader(body, header.nodes, header.buffers, this.dictionaries).visitMany(types);\n    }\n}\n/** @ignore */\nclass RecordBatchStreamReaderImpl extends RecordBatchReaderImpl {\n    constructor(source, dictionaries) {\n        super(dictionaries);\n        this._reader = !compat_1.isArrowJSON(source)\n            ? new message_1.MessageReader(this._handle = source)\n            : new message_1.JSONMessageReader(this._handle = source);\n    }\n    isSync() { return true; }\n    isStream() { return true; }\n    [Symbol.iterator]() {\n        return this;\n    }\n    cancel() {\n        if (!this.closed && (this.closed = true)) {\n            this.reset()._reader.return();\n            this._reader = null;\n            this.dictionaries = null;\n        }\n    }\n    open(options) {\n        if (!this.closed) {\n            this.autoDestroy = shouldAutoDestroy(this, options);\n            if (!(this.schema || (this.schema = this._reader.readSchema()))) {\n                this.cancel();\n            }\n        }\n        return this;\n    }\n    throw(value) {\n        if (!this.closed && this.autoDestroy && (this.closed = true)) {\n            return this.reset()._reader.throw(value);\n        }\n        return interfaces_1.ITERATOR_DONE;\n    }\n    return(value) {\n        if (!this.closed && this.autoDestroy && (this.closed = true)) {\n            return this.reset()._reader.return(value);\n        }\n        return interfaces_1.ITERATOR_DONE;\n    }\n    next() {\n        if (this.closed) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        let message, { _reader: reader } = this;\n        while (message = this._readNextMessageAndValidate()) {\n            if (message.isSchema()) {\n                this.reset(message.header());\n            }\n            else if (message.isRecordBatch()) {\n                this._recordBatchIndex++;\n                const header = message.header();\n                const buffer = reader.readMessageBody(message.bodyLength);\n                const recordBatch = this._loadRecordBatch(header, buffer);\n                return { done: false, value: recordBatch };\n            }\n            else if (message.isDictionaryBatch()) {\n                this._dictionaryIndex++;\n                const header = message.header();\n                const buffer = reader.readMessageBody(message.bodyLength);\n                const vector = this._loadDictionaryBatch(header, buffer);\n                this.dictionaries.set(header.id, vector);\n            }\n        }\n        if (this.schema && this._recordBatchIndex === 0) {\n            this._recordBatchIndex++;\n            return { done: false, value: new recordbatch_1._InternalEmptyPlaceholderRecordBatch(this.schema) };\n        }\n        return this.return();\n    }\n    _readNextMessageAndValidate(type) {\n        return this._reader.readMessage(type);\n    }\n}\n/** @ignore */\nclass AsyncRecordBatchStreamReaderImpl extends RecordBatchReaderImpl {\n    constructor(source, dictionaries) {\n        super(dictionaries);\n        this._reader = new message_1.AsyncMessageReader(this._handle = source);\n    }\n    isAsync() { return true; }\n    isStream() { return true; }\n    [Symbol.asyncIterator]() {\n        return this;\n    }\n    async cancel() {\n        if (!this.closed && (this.closed = true)) {\n            await this.reset()._reader.return();\n            this._reader = null;\n            this.dictionaries = null;\n        }\n    }\n    async open(options) {\n        if (!this.closed) {\n            this.autoDestroy = shouldAutoDestroy(this, options);\n            if (!(this.schema || (this.schema = (await this._reader.readSchema())))) {\n                await this.cancel();\n            }\n        }\n        return this;\n    }\n    async throw(value) {\n        if (!this.closed && this.autoDestroy && (this.closed = true)) {\n            return await this.reset()._reader.throw(value);\n        }\n        return interfaces_1.ITERATOR_DONE;\n    }\n    async return(value) {\n        if (!this.closed && this.autoDestroy && (this.closed = true)) {\n            return await this.reset()._reader.return(value);\n        }\n        return interfaces_1.ITERATOR_DONE;\n    }\n    async next() {\n        if (this.closed) {\n            return interfaces_1.ITERATOR_DONE;\n        }\n        let message, { _reader: reader } = this;\n        while (message = await this._readNextMessageAndValidate()) {\n            if (message.isSchema()) {\n                await this.reset(message.header());\n            }\n            else if (message.isRecordBatch()) {\n                this._recordBatchIndex++;\n                const header = message.header();\n                const buffer = await reader.readMessageBody(message.bodyLength);\n                const recordBatch = this._loadRecordBatch(header, buffer);\n                return { done: false, value: recordBatch };\n            }\n            else if (message.isDictionaryBatch()) {\n                this._dictionaryIndex++;\n                const header = message.header();\n                const buffer = await reader.readMessageBody(message.bodyLength);\n                const vector = this._loadDictionaryBatch(header, buffer);\n                this.dictionaries.set(header.id, vector);\n            }\n        }\n        if (this.schema && this._recordBatchIndex === 0) {\n            this._recordBatchIndex++;\n            return { done: false, value: new recordbatch_1._InternalEmptyPlaceholderRecordBatch(this.schema) };\n        }\n        return await this.return();\n    }\n    async _readNextMessageAndValidate(type) {\n        return await this._reader.readMessage(type);\n    }\n}\n/** @ignore */\nclass RecordBatchFileReaderImpl extends RecordBatchStreamReaderImpl {\n    constructor(source, dictionaries) {\n        super(source instanceof file_2.RandomAccessFile ? source : new file_2.RandomAccessFile(source), dictionaries);\n    }\n    get footer() { return this._footer; }\n    get numDictionaries() { return this._footer ? this._footer.numDictionaries : 0; }\n    get numRecordBatches() { return this._footer ? this._footer.numRecordBatches : 0; }\n    isSync() { return true; }\n    isFile() { return true; }\n    open(options) {\n        if (!this.closed && !this._footer) {\n            this.schema = (this._footer = this._readFooter()).schema;\n            for (const block of this._footer.dictionaryBatches()) {\n                block && this._readDictionaryBatch(this._dictionaryIndex++);\n            }\n        }\n        return super.open(options);\n    }\n    readRecordBatch(index) {\n        if (this.closed) {\n            return null;\n        }\n        if (!this._footer) {\n            this.open();\n        }\n        const block = this._footer && this._footer.getRecordBatch(index);\n        if (block && this._handle.seek(block.offset)) {\n            const message = this._reader.readMessage(enum_1.MessageHeader.RecordBatch);\n            if (message && message.isRecordBatch()) {\n                const header = message.header();\n                const buffer = this._reader.readMessageBody(message.bodyLength);\n                const recordBatch = this._loadRecordBatch(header, buffer);\n                return recordBatch;\n            }\n        }\n        return null;\n    }\n    _readDictionaryBatch(index) {\n        const block = this._footer && this._footer.getDictionaryBatch(index);\n        if (block && this._handle.seek(block.offset)) {\n            const message = this._reader.readMessage(enum_1.MessageHeader.DictionaryBatch);\n            if (message && message.isDictionaryBatch()) {\n                const header = message.header();\n                const buffer = this._reader.readMessageBody(message.bodyLength);\n                const vector = this._loadDictionaryBatch(header, buffer);\n                this.dictionaries.set(header.id, vector);\n            }\n        }\n    }\n    _readFooter() {\n        const { _handle } = this;\n        const offset = _handle.size - message_1.magicAndPadding;\n        const length = _handle.readInt32(offset);\n        const buffer = _handle.readAt(offset - length, length);\n        return file_1.Footer.decode(buffer);\n    }\n    _readNextMessageAndValidate(type) {\n        if (!this._footer) {\n            this.open();\n        }\n        if (this._footer && this._recordBatchIndex < this.numRecordBatches) {\n            const block = this._footer && this._footer.getRecordBatch(this._recordBatchIndex);\n            if (block && this._handle.seek(block.offset)) {\n                return this._reader.readMessage(type);\n            }\n        }\n        return null;\n    }\n}\n/** @ignore */\nclass AsyncRecordBatchFileReaderImpl extends AsyncRecordBatchStreamReaderImpl {\n    constructor(source, ...rest) {\n        const byteLength = typeof rest[0] !== 'number' ? rest.shift() : undefined;\n        const dictionaries = rest[0] instanceof Map ? rest.shift() : undefined;\n        super(source instanceof file_2.AsyncRandomAccessFile ? source : new file_2.AsyncRandomAccessFile(source, byteLength), dictionaries);\n    }\n    get footer() { return this._footer; }\n    get numDictionaries() { return this._footer ? this._footer.numDictionaries : 0; }\n    get numRecordBatches() { return this._footer ? this._footer.numRecordBatches : 0; }\n    isFile() { return true; }\n    isAsync() { return true; }\n    async open(options) {\n        if (!this.closed && !this._footer) {\n            this.schema = (this._footer = await this._readFooter()).schema;\n            for (const block of this._footer.dictionaryBatches()) {\n                block && await this._readDictionaryBatch(this._dictionaryIndex++);\n            }\n        }\n        return await super.open(options);\n    }\n    async readRecordBatch(index) {\n        if (this.closed) {\n            return null;\n        }\n        if (!this._footer) {\n            await this.open();\n        }\n        const block = this._footer && this._footer.getRecordBatch(index);\n        if (block && (await this._handle.seek(block.offset))) {\n            const message = await this._reader.readMessage(enum_1.MessageHeader.RecordBatch);\n            if (message && message.isRecordBatch()) {\n                const header = message.header();\n                const buffer = await this._reader.readMessageBody(message.bodyLength);\n                const recordBatch = this._loadRecordBatch(header, buffer);\n                return recordBatch;\n            }\n        }\n        return null;\n    }\n    async _readDictionaryBatch(index) {\n        const block = this._footer && this._footer.getDictionaryBatch(index);\n        if (block && (await this._handle.seek(block.offset))) {\n            const message = await this._reader.readMessage(enum_1.MessageHeader.DictionaryBatch);\n            if (message && message.isDictionaryBatch()) {\n                const header = message.header();\n                const buffer = await this._reader.readMessageBody(message.bodyLength);\n                const vector = this._loadDictionaryBatch(header, buffer);\n                this.dictionaries.set(header.id, vector);\n            }\n        }\n    }\n    async _readFooter() {\n        const { _handle } = this;\n        _handle._pending && await _handle._pending;\n        const offset = _handle.size - message_1.magicAndPadding;\n        const length = await _handle.readInt32(offset);\n        const buffer = await _handle.readAt(offset - length, length);\n        return file_1.Footer.decode(buffer);\n    }\n    async _readNextMessageAndValidate(type) {\n        if (!this._footer) {\n            await this.open();\n        }\n        if (this._footer && this._recordBatchIndex < this.numRecordBatches) {\n            const block = this._footer.getRecordBatch(this._recordBatchIndex);\n            if (block && await this._handle.seek(block.offset)) {\n                return await this._reader.readMessage(type);\n            }\n        }\n        return null;\n    }\n}\n/** @ignore */\nclass RecordBatchJSONReaderImpl extends RecordBatchStreamReaderImpl {\n    constructor(source, dictionaries) {\n        super(source, dictionaries);\n    }\n    _loadVectors(header, body, types) {\n        return new vectorloader_1.JSONVectorLoader(body, header.nodes, header.buffers, this.dictionaries).visitMany(types);\n    }\n}\n//\n// Define some helper functions and static implementations down here. There's\n// a bit of branching in the static methods that can lead to the same routines\n// being executed, so we've broken those out here for readability.\n//\n/** @ignore */\nfunction shouldAutoDestroy(self, options) {\n    return options && (typeof options['autoDestroy'] === 'boolean') ? options['autoDestroy'] : self['autoDestroy'];\n}\n/** @ignore */\nfunction* readAllSync(source) {\n    const reader = RecordBatchReader.from(source);\n    try {\n        if (!reader.open({ autoDestroy: false }).closed) {\n            do {\n                yield reader;\n            } while (!(reader.reset().open()).closed);\n        }\n    }\n    finally {\n        reader.cancel();\n    }\n}\n/** @ignore */\nasync function* readAllAsync(source) {\n    const reader = await RecordBatchReader.from(source);\n    try {\n        if (!(await reader.open({ autoDestroy: false })).closed) {\n            do {\n                yield reader;\n            } while (!(await reader.reset().open()).closed);\n        }\n    }\n    finally {\n        await reader.cancel();\n    }\n}\n/** @ignore */\nfunction fromArrowJSON(source) {\n    return new RecordBatchStreamReader(new RecordBatchJSONReaderImpl(source));\n}\n/** @ignore */\nfunction fromByteStream(source) {\n    const bytes = source.peek((message_1.magicLength + 7) & ~7);\n    return bytes && bytes.byteLength >= 4 ? !message_1.checkForMagicArrowString(bytes)\n        ? new RecordBatchStreamReader(new RecordBatchStreamReaderImpl(source))\n        : new RecordBatchFileReader(new RecordBatchFileReaderImpl(source.read()))\n        : new RecordBatchStreamReader(new RecordBatchStreamReaderImpl(function* () { }()));\n}\n/** @ignore */\nasync function fromAsyncByteStream(source) {\n    const bytes = await source.peek((message_1.magicLength + 7) & ~7);\n    return bytes && bytes.byteLength >= 4 ? !message_1.checkForMagicArrowString(bytes)\n        ? new AsyncRecordBatchStreamReader(new AsyncRecordBatchStreamReaderImpl(source))\n        : new RecordBatchFileReader(new RecordBatchFileReaderImpl(await source.read()))\n        : new AsyncRecordBatchStreamReader(new AsyncRecordBatchStreamReaderImpl(async function* () { }()));\n}\n/** @ignore */\nasync function fromFileHandle(source) {\n    const { size } = await source.stat();\n    const file = new file_2.AsyncRandomAccessFile(source, size);\n    if (size >= message_1.magicX2AndPadding) {\n        if (message_1.checkForMagicArrowString(await file.readAt(0, (message_1.magicLength + 7) & ~7))) {\n            return new AsyncRecordBatchFileReader(new AsyncRecordBatchFileReaderImpl(file));\n        }\n    }\n    return new AsyncRecordBatchStreamReader(new AsyncRecordBatchStreamReaderImpl(file));\n}\n\n//# sourceMappingURL=reader.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst table_1 = require(\"../table\");\nconst message_1 = require(\"./message\");\nconst column_1 = require(\"../column\");\nconst type_1 = require(\"../type\");\nconst schema_1 = require(\"../schema\");\nconst message_2 = require(\"./metadata/message\");\nconst metadata = require(\"./metadata/message\");\nconst file_1 = require(\"./metadata/file\");\nconst enum_1 = require(\"../enum\");\nconst stream_1 = require(\"../io/stream\");\nconst vectorassembler_1 = require(\"../visitor/vectorassembler\");\nconst jsontypeassembler_1 = require(\"../visitor/jsontypeassembler\");\nconst jsonvectorassembler_1 = require(\"../visitor/jsonvectorassembler\");\nconst buffer_1 = require(\"../util/buffer\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst interfaces_1 = require(\"../io/interfaces\");\nconst compat_1 = require(\"../util/compat\");\nclass RecordBatchWriter extends interfaces_1.ReadableInterop {\n    constructor(options) {\n        super();\n        this._position = 0;\n        this._started = false;\n        // @ts-ignore\n        this._sink = new stream_1.AsyncByteQueue();\n        this._schema = null;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        compat_1.isObject(options) || (options = { autoDestroy: true, writeLegacyIpcFormat: false });\n        this._autoDestroy = (typeof options.autoDestroy === 'boolean') ? options.autoDestroy : true;\n        this._writeLegacyIpcFormat = (typeof options.writeLegacyIpcFormat === 'boolean') ? options.writeLegacyIpcFormat : false;\n    }\n    /** @nocollapse */\n    // @ts-ignore\n    static throughNode(options) {\n        throw new Error(`\"throughNode\" not available in this environment`);\n    }\n    /** @nocollapse */\n    static throughDOM(\n    // @ts-ignore\n    writableStrategy, \n    // @ts-ignore\n    readableStrategy) {\n        throw new Error(`\"throughDOM\" not available in this environment`);\n    }\n    toString(sync = false) {\n        return this._sink.toString(sync);\n    }\n    toUint8Array(sync = false) {\n        return this._sink.toUint8Array(sync);\n    }\n    writeAll(input) {\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => this.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(this, input);\n        }\n        return writeAll(this, input);\n    }\n    get closed() { return this._sink.closed; }\n    [Symbol.asyncIterator]() { return this._sink[Symbol.asyncIterator](); }\n    toDOMStream(options) { return this._sink.toDOMStream(options); }\n    toNodeStream(options) { return this._sink.toNodeStream(options); }\n    close() {\n        return this.reset()._sink.close();\n    }\n    abort(reason) {\n        return this.reset()._sink.abort(reason);\n    }\n    finish() {\n        this._autoDestroy ? this.close() : this.reset(this._sink, this._schema);\n        return this;\n    }\n    reset(sink = this._sink, schema = null) {\n        if ((sink === this._sink) || (sink instanceof stream_1.AsyncByteQueue)) {\n            this._sink = sink;\n        }\n        else {\n            this._sink = new stream_1.AsyncByteQueue();\n            if (sink && compat_1.isWritableDOMStream(sink)) {\n                this.toDOMStream({ type: 'bytes' }).pipeTo(sink);\n            }\n            else if (sink && compat_1.isWritableNodeStream(sink)) {\n                this.toNodeStream({ objectMode: false }).pipe(sink);\n            }\n        }\n        if (this._started && this._schema) {\n            this._writeFooter(this._schema);\n        }\n        this._started = false;\n        this._dictionaryBlocks = [];\n        this._recordBatchBlocks = [];\n        this._dictionaryDeltaOffsets = new Map();\n        if (!schema || !(schema.compareTo(this._schema))) {\n            if (schema === null) {\n                this._position = 0;\n                this._schema = null;\n            }\n            else {\n                this._started = true;\n                this._schema = schema;\n                this._writeSchema(schema);\n            }\n        }\n        return this;\n    }\n    write(payload) {\n        let schema = null;\n        if (!this._sink) {\n            throw new Error(`RecordBatchWriter is closed`);\n        }\n        else if (payload === null || payload === undefined) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof table_1.Table && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        else if (payload instanceof recordbatch_1.RecordBatch && !(schema = payload.schema)) {\n            return this.finish() && undefined;\n        }\n        if (schema && !schema.compareTo(this._schema)) {\n            if (this._started && this._autoDestroy) {\n                return this.close();\n            }\n            this.reset(this._sink, schema);\n        }\n        if (payload instanceof recordbatch_1.RecordBatch) {\n            if (!(payload instanceof recordbatch_1._InternalEmptyPlaceholderRecordBatch)) {\n                this._writeRecordBatch(payload);\n            }\n        }\n        else if (payload instanceof table_1.Table) {\n            this.writeAll(payload.chunks);\n        }\n        else if (compat_1.isIterable(payload)) {\n            this.writeAll(payload);\n        }\n    }\n    _writeMessage(message, alignment = 8) {\n        const a = alignment - 1;\n        const buffer = message_2.Message.encode(message);\n        const flatbufferSize = buffer.byteLength;\n        const prefixSize = !this._writeLegacyIpcFormat ? 8 : 4;\n        const alignedSize = (flatbufferSize + prefixSize + a) & ~a;\n        const nPaddingBytes = alignedSize - flatbufferSize - prefixSize;\n        if (message.headerType === enum_1.MessageHeader.RecordBatch) {\n            this._recordBatchBlocks.push(new file_1.FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        else if (message.headerType === enum_1.MessageHeader.DictionaryBatch) {\n            this._dictionaryBlocks.push(new file_1.FileBlock(alignedSize, message.bodyLength, this._position));\n        }\n        // If not in legacy pre-0.15.0 mode, write the stream continuation indicator\n        if (!this._writeLegacyIpcFormat) {\n            this._write(Int32Array.of(-1));\n        }\n        // Write the flatbuffer size prefix including padding\n        this._write(Int32Array.of(alignedSize - prefixSize));\n        // Write the flatbuffer\n        if (flatbufferSize > 0) {\n            this._write(buffer);\n        }\n        // Write any padding\n        return this._writePadding(nPaddingBytes);\n    }\n    _write(chunk) {\n        if (this._started) {\n            const buffer = buffer_1.toUint8Array(chunk);\n            if (buffer && buffer.byteLength > 0) {\n                this._sink.write(buffer);\n                this._position += buffer.byteLength;\n            }\n        }\n        return this;\n    }\n    _writeSchema(schema) {\n        return this._writeMessage(message_2.Message.from(schema));\n    }\n    // @ts-ignore\n    _writeFooter(schema) {\n        // eos bytes\n        return this._writeLegacyIpcFormat\n            ? this._write(Int32Array.of(0))\n            : this._write(Int32Array.of(-1, 0));\n    }\n    _writeMagic() {\n        return this._write(message_1.MAGIC);\n    }\n    _writePadding(nBytes) {\n        return nBytes > 0 ? this._write(new Uint8Array(nBytes)) : this;\n    }\n    _writeRecordBatch(batch) {\n        const { byteLength, nodes, bufferRegions, buffers } = vectorassembler_1.VectorAssembler.assemble(batch);\n        const recordBatch = new metadata.RecordBatch(batch.length, nodes, bufferRegions);\n        const message = message_2.Message.from(recordBatch, byteLength);\n        return this\n            ._writeDictionaries(batch)\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        const { byteLength, nodes, bufferRegions, buffers } = vectorassembler_1.VectorAssembler.assemble(dictionary);\n        const recordBatch = new metadata.RecordBatch(dictionary.length, nodes, bufferRegions);\n        const dictionaryBatch = new metadata.DictionaryBatch(recordBatch, id, isDelta);\n        const message = message_2.Message.from(dictionaryBatch, byteLength);\n        return this\n            ._writeMessage(message)\n            ._writeBodyBuffers(buffers);\n    }\n    _writeBodyBuffers(buffers) {\n        let buffer;\n        let size, padding;\n        for (let i = -1, n = buffers.length; ++i < n;) {\n            if ((buffer = buffers[i]) && (size = buffer.byteLength) > 0) {\n                this._write(buffer);\n                if ((padding = ((size + 7) & ~7) - size) > 0) {\n                    this._writePadding(padding);\n                }\n            }\n        }\n        return this;\n    }\n    _writeDictionaries(batch) {\n        for (let [id, dictionary] of batch.dictionaries) {\n            let offset = this._dictionaryDeltaOffsets.get(id) || 0;\n            if (offset === 0 || (dictionary = dictionary.slice(offset)).length > 0) {\n                const chunks = 'chunks' in dictionary ? dictionary.chunks : [dictionary];\n                for (const chunk of chunks) {\n                    this._writeDictionaryBatch(chunk, id, offset > 0);\n                    offset += chunk.length;\n                }\n            }\n        }\n        return this;\n    }\n}\nexports.RecordBatchWriter = RecordBatchWriter;\n/** @ignore */\nclass RecordBatchStreamWriter extends RecordBatchWriter {\n    /** @nocollapse */\n    static writeAll(input, options) {\n        const writer = new RecordBatchStreamWriter(options);\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n}\nexports.RecordBatchStreamWriter = RecordBatchStreamWriter;\n/** @ignore */\nclass RecordBatchFileWriter extends RecordBatchWriter {\n    constructor() {\n        super();\n        this._autoDestroy = true;\n    }\n    /** @nocollapse */\n    static writeAll(input) {\n        const writer = new RecordBatchFileWriter();\n        if (compat_1.isPromise(input)) {\n            return input.then((x) => writer.writeAll(x));\n        }\n        else if (compat_1.isAsyncIterable(input)) {\n            return writeAllAsync(writer, input);\n        }\n        return writeAll(writer, input);\n    }\n    // @ts-ignore\n    _writeSchema(schema) {\n        return this._writeMagic()._writePadding(2);\n    }\n    _writeFooter(schema) {\n        const buffer = file_1.Footer.encode(new file_1.Footer(schema, enum_1.MetadataVersion.V4, this._recordBatchBlocks, this._dictionaryBlocks));\n        return super\n            ._writeFooter(schema) // EOS bytes for sequential readers\n            ._write(buffer) // Write the flatbuffer\n            ._write(Int32Array.of(buffer.byteLength)) // then the footer size suffix\n            ._writeMagic(); // then the magic suffix\n    }\n}\nexports.RecordBatchFileWriter = RecordBatchFileWriter;\n/** @ignore */\nclass RecordBatchJSONWriter extends RecordBatchWriter {\n    constructor() {\n        super();\n        this._autoDestroy = true;\n        this._recordBatches = [];\n        this._dictionaries = [];\n    }\n    /** @nocollapse */\n    static writeAll(input) {\n        return new RecordBatchJSONWriter().writeAll(input);\n    }\n    _writeMessage() { return this; }\n    // @ts-ignore\n    _writeFooter(schema) { return this; }\n    _writeSchema(schema) {\n        return this._write(`{\\n  \"schema\": ${JSON.stringify({ fields: schema.fields.map(fieldToJSON) }, null, 2)}`);\n    }\n    _writeDictionaries(batch) {\n        if (batch.dictionaries.size > 0) {\n            this._dictionaries.push(batch);\n        }\n        return this;\n    }\n    _writeDictionaryBatch(dictionary, id, isDelta = false) {\n        this._dictionaryDeltaOffsets.set(id, dictionary.length + (this._dictionaryDeltaOffsets.get(id) || 0));\n        this._write(this._dictionaryBlocks.length === 0 ? `    ` : `,\\n    `);\n        this._write(`${dictionaryBatchToJSON(dictionary, id, isDelta)}`);\n        this._dictionaryBlocks.push(new file_1.FileBlock(0, 0, 0));\n        return this;\n    }\n    _writeRecordBatch(batch) {\n        this._writeDictionaries(batch);\n        this._recordBatches.push(batch);\n        return this;\n    }\n    close() {\n        if (this._dictionaries.length > 0) {\n            this._write(`,\\n  \"dictionaries\": [\\n`);\n            for (const batch of this._dictionaries) {\n                super._writeDictionaries(batch);\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._recordBatches.length > 0) {\n            for (let i = -1, n = this._recordBatches.length; ++i < n;) {\n                this._write(i === 0 ? `,\\n  \"batches\": [\\n    ` : `,\\n    `);\n                this._write(`${recordBatchToJSON(this._recordBatches[i])}`);\n                this._recordBatchBlocks.push(new file_1.FileBlock(0, 0, 0));\n            }\n            this._write(`\\n  ]`);\n        }\n        if (this._schema) {\n            this._write(`\\n}`);\n        }\n        this._dictionaries = [];\n        this._recordBatches = [];\n        return super.close();\n    }\n}\nexports.RecordBatchJSONWriter = RecordBatchJSONWriter;\n/** @ignore */\nfunction writeAll(writer, input) {\n    let chunks = input;\n    if (input instanceof table_1.Table) {\n        chunks = input.chunks;\n        writer.reset(undefined, input.schema);\n    }\n    for (const batch of chunks) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n/** @ignore */\nasync function writeAllAsync(writer, batches) {\n    for await (const batch of batches) {\n        writer.write(batch);\n    }\n    return writer.finish();\n}\n/** @ignore */\nfunction fieldToJSON({ name, type, nullable }) {\n    const assembler = new jsontypeassembler_1.JSONTypeAssembler();\n    return {\n        'name': name, 'nullable': nullable,\n        'type': assembler.visit(type),\n        'children': (type.children || []).map(fieldToJSON),\n        'dictionary': !type_1.DataType.isDictionary(type) ? undefined : {\n            'id': type.id,\n            'isOrdered': type.isOrdered,\n            'indexType': assembler.visit(type.indices)\n        }\n    };\n}\n/** @ignore */\nfunction dictionaryBatchToJSON(dictionary, id, isDelta = false) {\n    const field = new schema_1.Field(`${id}`, dictionary.type, dictionary.nullCount > 0);\n    const columns = jsonvectorassembler_1.JSONVectorAssembler.assemble(new column_1.Column(field, [dictionary]));\n    return JSON.stringify({\n        'id': id,\n        'isDelta': isDelta,\n        'data': {\n            'count': dictionary.length,\n            'columns': columns\n        }\n    }, null, 2);\n}\n/** @ignore */\nfunction recordBatchToJSON(records) {\n    return JSON.stringify({\n        'count': records.length,\n        'columns': jsonvectorassembler_1.JSONVectorAssembler.assemble(records)\n    }, null, 2);\n}\n\n//# sourceMappingURL=writer.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"./data\");\nconst table_1 = require(\"./table\");\nconst vector_1 = require(\"./vector\");\nconst visitor_1 = require(\"./visitor\");\nconst schema_1 = require(\"./schema\");\nconst compat_1 = require(\"./util/compat\");\nconst chunked_1 = require(\"./vector/chunked\");\nconst args_1 = require(\"./util/args\");\nconst type_1 = require(\"./type\");\nconst recordbatch_1 = require(\"./util/recordbatch\");\nconst index_1 = require(\"./vector/index\");\nclass RecordBatch extends index_1.StructVector {\n    constructor(...args) {\n        let data;\n        let schema = args[0];\n        let children;\n        if (args[1] instanceof data_1.Data) {\n            [, data, children] = args;\n        }\n        else {\n            const fields = schema.fields;\n            const [, length, childData] = args;\n            data = data_1.Data.Struct(new type_1.Struct(fields), 0, length, 0, null, childData);\n        }\n        super(data, children);\n        this._schema = schema;\n    }\n    /** @nocollapse */\n    static from(options) {\n        if (compat_1.isIterable(options['values'])) {\n            return table_1.Table.from(options);\n        }\n        return table_1.Table.from(options);\n    }\n    /** @nocollapse */\n    static new(...args) {\n        const [fs, xs] = args_1.selectFieldArgs(args);\n        const vs = xs.filter((x) => x instanceof vector_1.Vector);\n        return new RecordBatch(...recordbatch_1.ensureSameLengthData(new schema_1.Schema(fs), vs.map((x) => x.data)));\n    }\n    clone(data, children = this._children) {\n        return new RecordBatch(this._schema, data, children);\n    }\n    concat(...others) {\n        const schema = this._schema, chunks = chunked_1.Chunked.flatten(this, ...others);\n        return new table_1.Table(schema, chunks.map(({ data }) => new RecordBatch(schema, data)));\n    }\n    get schema() { return this._schema; }\n    get numCols() { return this._schema.fields.length; }\n    get dictionaries() {\n        return this._dictionaries || (this._dictionaries = DictionaryCollector.collect(this));\n    }\n    select(...columnNames) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name, i), new Map());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)).filter((x) => x > -1));\n    }\n    selectAt(...columnIndices) {\n        const schema = this._schema.selectAt(...columnIndices);\n        const childData = columnIndices.map((i) => this.data.childData[i]).filter(Boolean);\n        return new RecordBatch(schema, this.length, childData);\n    }\n}\nexports.RecordBatch = RecordBatch;\n/**\n * An internal class used by the `RecordBatchReader` and `RecordBatchWriter`\n * implementations to differentiate between a stream with valid zero-length\n * RecordBatches, and a stream with a Schema message, but no RecordBatches.\n * @see https://github.com/apache/arrow/pull/4373\n * @ignore\n * @private\n */\n/* tslint:disable:class-name */\nclass _InternalEmptyPlaceholderRecordBatch extends RecordBatch {\n    constructor(schema) {\n        super(schema, 0, schema.fields.map((f) => data_1.Data.new(f.type, 0, 0, 0)));\n    }\n}\nexports._InternalEmptyPlaceholderRecordBatch = _InternalEmptyPlaceholderRecordBatch;\n/** @ignore */\nclass DictionaryCollector extends visitor_1.Visitor {\n    constructor() {\n        super(...arguments);\n        this.dictionaries = new Map();\n    }\n    static collect(batch) {\n        return new DictionaryCollector().visit(batch.data, new type_1.Struct(batch.schema.fields)).dictionaries;\n    }\n    visit(data, type) {\n        if (type_1.DataType.isDictionary(type)) {\n            return this.visitDictionary(data, type);\n        }\n        else {\n            data.childData.forEach((child, i) => this.visit(child, type.children[i].type));\n        }\n        return this;\n    }\n    visitDictionary(data, type) {\n        const dictionary = data.dictionary;\n        if (dictionary && dictionary.length > 0) {\n            this.dictionaries.set(type.id, dictionary);\n        }\n        return this;\n    }\n}\n\n//# sourceMappingURL=recordbatch.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst type_1 = require(\"./type\");\nconst args_1 = require(\"./util/args\");\nconst args_2 = require(\"./util/args\");\nconst typecomparator_1 = require(\"./visitor/typecomparator\");\nclass Schema {\n    constructor(fields = [], metadata, dictionaries) {\n        this.fields = (fields || []);\n        this.metadata = metadata || new Map();\n        if (!dictionaries) {\n            dictionaries = generateDictionaryMap(fields);\n        }\n        this.dictionaries = dictionaries;\n    }\n    /** @nocollapse */\n    static from(...args) {\n        return Schema.new(args[0], args[1]);\n    }\n    /** @nocollapse */\n    static new(...args) {\n        return new Schema(args_2.selectFieldArgs(args)[0]);\n    }\n    get [Symbol.toStringTag]() { return 'Schema'; }\n    toString() {\n        return `Schema<{ ${this.fields.map((f, i) => `${i}: ${f}`).join(', ')} }>`;\n    }\n    compareTo(other) {\n        return typecomparator_1.instance.compareSchemas(this, other);\n    }\n    select(...columnNames) {\n        const names = columnNames.reduce((xs, x) => (xs[x] = true) && xs, Object.create(null));\n        return new Schema(this.fields.filter((f) => names[f.name]), this.metadata);\n    }\n    selectAt(...columnIndices) {\n        return new Schema(columnIndices.map((i) => this.fields[i]).filter(Boolean), this.metadata);\n    }\n    assign(...args) {\n        const other = args[0] instanceof Schema ? args[0]\n            : new Schema(args_1.selectArgs(Field, args));\n        const curFields = [...this.fields];\n        const metadata = mergeMaps(mergeMaps(new Map(), this.metadata), other.metadata);\n        const newFields = other.fields.filter((f2) => {\n            const i = curFields.findIndex((f) => f.name === f2.name);\n            return ~i ? (curFields[i] = f2.clone({\n                metadata: mergeMaps(mergeMaps(new Map(), curFields[i].metadata), f2.metadata)\n            })) && false : true;\n        });\n        const newDictionaries = generateDictionaryMap(newFields, new Map());\n        return new Schema([...curFields, ...newFields], metadata, new Map([...this.dictionaries, ...newDictionaries]));\n    }\n}\nexports.Schema = Schema;\nclass Field {\n    constructor(name, type, nullable = false, metadata) {\n        this.name = name;\n        this.type = type;\n        this.nullable = nullable;\n        this.metadata = metadata || new Map();\n    }\n    /** @nocollapse */\n    static new(...args) {\n        let [name, type, nullable, metadata] = args;\n        if (args[0] && typeof args[0] === 'object') {\n            ({ name } = args[0]);\n            (type === undefined) && (type = args[0].type);\n            (nullable === undefined) && (nullable = args[0].nullable);\n            (metadata === undefined) && (metadata = args[0].metadata);\n        }\n        return new Field(`${name}`, type, nullable, metadata);\n    }\n    get typeId() { return this.type.typeId; }\n    get [Symbol.toStringTag]() { return 'Field'; }\n    toString() { return `${this.name}: ${this.type}`; }\n    compareTo(other) {\n        return typecomparator_1.instance.compareField(this, other);\n    }\n    clone(...args) {\n        let [name, type, nullable, metadata] = args;\n        (!args[0] || typeof args[0] !== 'object')\n            ? ([name = this.name, type = this.type, nullable = this.nullable, metadata = this.metadata] = args)\n            : ({ name = this.name, type = this.type, nullable = this.nullable, metadata = this.metadata } = args[0]);\n        return Field.new(name, type, nullable, metadata);\n    }\n}\nexports.Field = Field;\n/** @ignore */\nfunction mergeMaps(m1, m2) {\n    return new Map([...(m1 || new Map()), ...(m2 || new Map())]);\n}\n/** @ignore */\nfunction generateDictionaryMap(fields, dictionaries = new Map()) {\n    for (let i = -1, n = fields.length; ++i < n;) {\n        const field = fields[i];\n        const type = field.type;\n        if (type_1.DataType.isDictionary(type)) {\n            if (!dictionaries.has(type.id)) {\n                dictionaries.set(type.id, type.dictionary);\n            }\n            else if (dictionaries.get(type.id) !== type.dictionary) {\n                throw new Error(`Cannot create Schema containing two different dictionaries with the same Id`);\n            }\n        }\n        if (type.children && type.children.length > 0) {\n            generateDictionaryMap(type.children, dictionaries);\n        }\n    }\n    return dictionaries;\n}\n// Add these here so they're picked up by the externs creator\n// in the build, and closure-compiler doesn't minify them away\nSchema.prototype.fields = null;\nSchema.prototype.metadata = null;\nSchema.prototype.dictionaries = null;\nField.prototype.type = null;\nField.prototype.name = null;\nField.prototype.nullable = null;\nField.prototype.metadata = null;\n\n//# sourceMappingURL=schema.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst column_1 = require(\"./column\");\nconst schema_1 = require(\"./schema\");\nconst recordbatch_1 = require(\"./recordbatch\");\nconst reader_1 = require(\"./ipc/reader\");\nconst type_1 = require(\"./type\");\nconst args_1 = require(\"./util/args\");\nconst compat_1 = require(\"./util/compat\");\nconst writer_1 = require(\"./ipc/writer\");\nconst recordbatch_2 = require(\"./util/recordbatch\");\nconst index_1 = require(\"./vector/index\");\nclass Table extends index_1.Chunked {\n    constructor(...args) {\n        let schema = null;\n        if (args[0] instanceof schema_1.Schema) {\n            schema = args.shift();\n        }\n        let chunks = args_1.selectArgs(recordbatch_1.RecordBatch, args);\n        if (!schema && !(schema = chunks[0] && chunks[0].schema)) {\n            throw new TypeError('Table must be initialized with a Schema or at least one RecordBatch');\n        }\n        chunks[0] || (chunks[0] = new recordbatch_1._InternalEmptyPlaceholderRecordBatch(schema));\n        super(new type_1.Struct(schema.fields), chunks);\n        this._schema = schema;\n        this._chunks = chunks;\n    }\n    /** @nocollapse */\n    static empty(schema = new schema_1.Schema([])) { return new Table(schema, []); }\n    /** @nocollapse */\n    static from(input) {\n        if (!input) {\n            return Table.empty();\n        }\n        if (typeof input === 'object') {\n            let table = compat_1.isIterable(input['values']) ? tableFromIterable(input)\n                : compat_1.isAsyncIterable(input['values']) ? tableFromAsyncIterable(input)\n                    : null;\n            if (table !== null) {\n                return table;\n            }\n        }\n        let reader = reader_1.RecordBatchReader.from(input);\n        if (compat_1.isPromise(reader)) {\n            return (async () => await Table.from(await reader))();\n        }\n        if (reader.isSync() && (reader = reader.open())) {\n            return !reader.schema ? Table.empty() : new Table(reader.schema, [...reader]);\n        }\n        return (async (opening) => {\n            const reader = await opening;\n            const schema = reader.schema;\n            const batches = [];\n            if (schema) {\n                for await (let batch of reader) {\n                    batches.push(batch);\n                }\n                return new Table(schema, batches);\n            }\n            return Table.empty();\n        })(reader.open());\n    }\n    /** @nocollapse */\n    static async fromAsync(source) {\n        return await Table.from(source);\n    }\n    /** @nocollapse */\n    static fromStruct(vector) {\n        return Table.new(vector.data.childData, vector.type.children);\n    }\n    /** @nocollapse */\n    static new(...cols) {\n        return new Table(...recordbatch_2.distributeColumnsIntoRecordBatches(args_1.selectColumnArgs(cols)));\n    }\n    get schema() { return this._schema; }\n    get length() { return this._length; }\n    get chunks() { return this._chunks; }\n    get numCols() { return this._numChildren; }\n    clone(chunks = this._chunks) {\n        return new Table(this._schema, chunks);\n    }\n    getColumn(name) {\n        return this.getColumnAt(this.getColumnIndex(name));\n    }\n    getColumnAt(index) {\n        return this.getChildAt(index);\n    }\n    getColumnIndex(name) {\n        return this._schema.fields.findIndex((f) => f.name === name);\n    }\n    getChildAt(index) {\n        if (index < 0 || index >= this.numChildren) {\n            return null;\n        }\n        let field, child;\n        const fields = this._schema.fields;\n        const columns = this._children || (this._children = []);\n        if (child = columns[index]) {\n            return child;\n        }\n        if (field = fields[index]) {\n            const chunks = this._chunks\n                .map((chunk) => chunk.getChildAt(index))\n                .filter((vec) => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new column_1.Column(field, chunks));\n            }\n        }\n        return null;\n    }\n    // @ts-ignore\n    serialize(encoding = 'binary', stream = true) {\n        const Writer = !stream\n            ? writer_1.RecordBatchFileWriter\n            : writer_1.RecordBatchStreamWriter;\n        return Writer.writeAll(this).toUint8Array(true);\n    }\n    count() {\n        return this._length;\n    }\n    select(...columnNames) {\n        const nameToIndex = this._schema.fields.reduce((m, f, i) => m.set(f.name, i), new Map());\n        return this.selectAt(...columnNames.map((columnName) => nameToIndex.get(columnName)).filter((x) => x > -1));\n    }\n    selectAt(...columnIndices) {\n        const schema = this._schema.selectAt(...columnIndices);\n        return new Table(schema, this._chunks.map(({ length, data: { childData } }) => {\n            return new recordbatch_1.RecordBatch(schema, length, columnIndices.map((i) => childData[i]).filter(Boolean));\n        }));\n    }\n    assign(other) {\n        const fields = this._schema.fields;\n        const [indices, oldToNew] = other.schema.fields.reduce((memo, f2, newIdx) => {\n            const [indices, oldToNew] = memo;\n            const i = fields.findIndex((f) => f.name === f2.name);\n            ~i ? (oldToNew[i] = newIdx) : indices.push(newIdx);\n            return memo;\n        }, [[], []]);\n        const schema = this._schema.assign(other.schema);\n        const columns = [\n            ...fields.map((_f, i, _fs, j = oldToNew[i]) => (j === undefined ? this.getColumnAt(i) : other.getColumnAt(j))),\n            ...indices.map((i) => other.getColumnAt(i))\n        ].filter(Boolean);\n        return new Table(...recordbatch_2.distributeVectorsIntoRecordBatches(schema, columns));\n    }\n}\nexports.Table = Table;\nfunction tableFromIterable(input) {\n    const { type } = input;\n    if (type instanceof type_1.Struct) {\n        return Table.fromStruct(index_1.StructVector.from(input));\n    }\n    return null;\n}\nfunction tableFromAsyncIterable(input) {\n    const { type } = input;\n    if (type instanceof type_1.Struct) {\n        return index_1.StructVector.from(input).then((vector) => Table.fromStruct(vector));\n    }\n    return null;\n}\n\n//# sourceMappingURL=table.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst typecomparator_1 = require(\"./visitor/typecomparator\");\nconst enum_1 = require(\"./enum\");\n/**\n * An abstract base class for classes that encapsulate metadata about each of\n * the logical types that Arrow can represent.\n */\nclass DataType {\n    /** @nocollapse */ static isNull(x) { return x && x.typeId === enum_1.Type.Null; }\n    /** @nocollapse */ static isInt(x) { return x && x.typeId === enum_1.Type.Int; }\n    /** @nocollapse */ static isFloat(x) { return x && x.typeId === enum_1.Type.Float; }\n    /** @nocollapse */ static isBinary(x) { return x && x.typeId === enum_1.Type.Binary; }\n    /** @nocollapse */ static isUtf8(x) { return x && x.typeId === enum_1.Type.Utf8; }\n    /** @nocollapse */ static isBool(x) { return x && x.typeId === enum_1.Type.Bool; }\n    /** @nocollapse */ static isDecimal(x) { return x && x.typeId === enum_1.Type.Decimal; }\n    /** @nocollapse */ static isDate(x) { return x && x.typeId === enum_1.Type.Date; }\n    /** @nocollapse */ static isTime(x) { return x && x.typeId === enum_1.Type.Time; }\n    /** @nocollapse */ static isTimestamp(x) { return x && x.typeId === enum_1.Type.Timestamp; }\n    /** @nocollapse */ static isInterval(x) { return x && x.typeId === enum_1.Type.Interval; }\n    /** @nocollapse */ static isList(x) { return x && x.typeId === enum_1.Type.List; }\n    /** @nocollapse */ static isStruct(x) { return x && x.typeId === enum_1.Type.Struct; }\n    /** @nocollapse */ static isUnion(x) { return x && x.typeId === enum_1.Type.Union; }\n    /** @nocollapse */ static isFixedSizeBinary(x) { return x && x.typeId === enum_1.Type.FixedSizeBinary; }\n    /** @nocollapse */ static isFixedSizeList(x) { return x && x.typeId === enum_1.Type.FixedSizeList; }\n    /** @nocollapse */ static isMap(x) { return x && x.typeId === enum_1.Type.Map; }\n    /** @nocollapse */ static isDictionary(x) { return x && x.typeId === enum_1.Type.Dictionary; }\n    get typeId() { return enum_1.Type.NONE; }\n    compareTo(other) {\n        return typecomparator_1.instance.visit(this, other);\n    }\n}\nDataType[Symbol.toStringTag] = ((proto) => {\n    proto.children = null;\n    proto.ArrayType = Array;\n    return proto[Symbol.toStringTag] = 'DataType';\n})(DataType.prototype);\nexports.DataType = DataType;\n/** @ignore */\nclass Null extends DataType {\n    toString() { return `Null`; }\n    get typeId() { return enum_1.Type.Null; }\n}\nNull[Symbol.toStringTag] = ((proto) => {\n    return proto[Symbol.toStringTag] = 'Null';\n})(Null.prototype);\nexports.Null = Null;\n/** @ignore */\nclass Int_ extends DataType {\n    constructor(isSigned, bitWidth) {\n        super();\n        this.isSigned = isSigned;\n        this.bitWidth = bitWidth;\n    }\n    get typeId() { return enum_1.Type.Int; }\n    get ArrayType() {\n        switch (this.bitWidth) {\n            case 8: return this.isSigned ? Int8Array : Uint8Array;\n            case 16: return this.isSigned ? Int16Array : Uint16Array;\n            case 32: return this.isSigned ? Int32Array : Uint32Array;\n            case 64: return this.isSigned ? Int32Array : Uint32Array;\n        }\n        throw new Error(`Unrecognized ${this[Symbol.toStringTag]} type`);\n    }\n    toString() { return `${this.isSigned ? `I` : `Ui`}nt${this.bitWidth}`; }\n}\nInt_[Symbol.toStringTag] = ((proto) => {\n    proto.isSigned = null;\n    proto.bitWidth = null;\n    return proto[Symbol.toStringTag] = 'Int';\n})(Int_.prototype);\nexports.Int = Int_;\n/** @ignore */\nclass Int8 extends Int_ {\n    constructor() { super(true, 8); }\n}\nexports.Int8 = Int8;\n/** @ignore */\nclass Int16 extends Int_ {\n    constructor() { super(true, 16); }\n}\nexports.Int16 = Int16;\n/** @ignore */\nclass Int32 extends Int_ {\n    constructor() { super(true, 32); }\n}\nexports.Int32 = Int32;\n/** @ignore */\nclass Int64 extends Int_ {\n    constructor() { super(true, 64); }\n}\nexports.Int64 = Int64;\n/** @ignore */\nclass Uint8 extends Int_ {\n    constructor() { super(false, 8); }\n}\nexports.Uint8 = Uint8;\n/** @ignore */\nclass Uint16 extends Int_ {\n    constructor() { super(false, 16); }\n}\nexports.Uint16 = Uint16;\n/** @ignore */\nclass Uint32 extends Int_ {\n    constructor() { super(false, 32); }\n}\nexports.Uint32 = Uint32;\n/** @ignore */\nclass Uint64 extends Int_ {\n    constructor() { super(false, 64); }\n}\nexports.Uint64 = Uint64;\nObject.defineProperty(Int8.prototype, 'ArrayType', { value: Int8Array });\nObject.defineProperty(Int16.prototype, 'ArrayType', { value: Int16Array });\nObject.defineProperty(Int32.prototype, 'ArrayType', { value: Int32Array });\nObject.defineProperty(Int64.prototype, 'ArrayType', { value: Int32Array });\nObject.defineProperty(Uint8.prototype, 'ArrayType', { value: Uint8Array });\nObject.defineProperty(Uint16.prototype, 'ArrayType', { value: Uint16Array });\nObject.defineProperty(Uint32.prototype, 'ArrayType', { value: Uint32Array });\nObject.defineProperty(Uint64.prototype, 'ArrayType', { value: Uint32Array });\n/** @ignore */\nclass Float extends DataType {\n    constructor(precision) {\n        super();\n        this.precision = precision;\n    }\n    get typeId() { return enum_1.Type.Float; }\n    get ArrayType() {\n        switch (this.precision) {\n            case enum_1.Precision.HALF: return Uint16Array;\n            case enum_1.Precision.SINGLE: return Float32Array;\n            case enum_1.Precision.DOUBLE: return Float64Array;\n        }\n        throw new Error(`Unrecognized ${this[Symbol.toStringTag]} type`);\n    }\n    toString() { return `Float${(this.precision << 5) || 16}`; }\n}\nFloat[Symbol.toStringTag] = ((proto) => {\n    proto.precision = null;\n    return proto[Symbol.toStringTag] = 'Float';\n})(Float.prototype);\nexports.Float = Float;\n/** @ignore */\nclass Float16 extends Float {\n    constructor() { super(enum_1.Precision.HALF); }\n}\nexports.Float16 = Float16;\n/** @ignore */\nclass Float32 extends Float {\n    constructor() { super(enum_1.Precision.SINGLE); }\n}\nexports.Float32 = Float32;\n/** @ignore */\nclass Float64 extends Float {\n    constructor() { super(enum_1.Precision.DOUBLE); }\n}\nexports.Float64 = Float64;\nObject.defineProperty(Float16.prototype, 'ArrayType', { value: Uint16Array });\nObject.defineProperty(Float32.prototype, 'ArrayType', { value: Float32Array });\nObject.defineProperty(Float64.prototype, 'ArrayType', { value: Float64Array });\n/** @ignore */\nclass Binary extends DataType {\n    constructor() {\n        super();\n    }\n    get typeId() { return enum_1.Type.Binary; }\n    toString() { return `Binary`; }\n}\nBinary[Symbol.toStringTag] = ((proto) => {\n    proto.ArrayType = Uint8Array;\n    return proto[Symbol.toStringTag] = 'Binary';\n})(Binary.prototype);\nexports.Binary = Binary;\n/** @ignore */\nclass Utf8 extends DataType {\n    constructor() {\n        super();\n    }\n    get typeId() { return enum_1.Type.Utf8; }\n    toString() { return `Utf8`; }\n}\nUtf8[Symbol.toStringTag] = ((proto) => {\n    proto.ArrayType = Uint8Array;\n    return proto[Symbol.toStringTag] = 'Utf8';\n})(Utf8.prototype);\nexports.Utf8 = Utf8;\n/** @ignore */\nclass Bool extends DataType {\n    constructor() {\n        super();\n    }\n    get typeId() { return enum_1.Type.Bool; }\n    toString() { return `Bool`; }\n}\nBool[Symbol.toStringTag] = ((proto) => {\n    proto.ArrayType = Uint8Array;\n    return proto[Symbol.toStringTag] = 'Bool';\n})(Bool.prototype);\nexports.Bool = Bool;\n/** @ignore */\nclass Decimal extends DataType {\n    constructor(scale, precision) {\n        super();\n        this.scale = scale;\n        this.precision = precision;\n    }\n    get typeId() { return enum_1.Type.Decimal; }\n    toString() { return `Decimal[${this.precision}e${this.scale > 0 ? `+` : ``}${this.scale}]`; }\n}\nDecimal[Symbol.toStringTag] = ((proto) => {\n    proto.scale = null;\n    proto.precision = null;\n    proto.ArrayType = Uint32Array;\n    return proto[Symbol.toStringTag] = 'Decimal';\n})(Decimal.prototype);\nexports.Decimal = Decimal;\n/** @ignore */\nclass Date_ extends DataType {\n    constructor(unit) {\n        super();\n        this.unit = unit;\n    }\n    get typeId() { return enum_1.Type.Date; }\n    toString() { return `Date${(this.unit + 1) * 32}<${enum_1.DateUnit[this.unit]}>`; }\n}\nDate_[Symbol.toStringTag] = ((proto) => {\n    proto.unit = null;\n    proto.ArrayType = Int32Array;\n    return proto[Symbol.toStringTag] = 'Date';\n})(Date_.prototype);\nexports.Date_ = Date_;\n/** @ignore */\nclass DateDay extends Date_ {\n    constructor() { super(enum_1.DateUnit.DAY); }\n}\nexports.DateDay = DateDay;\n/** @ignore */\nclass DateMillisecond extends Date_ {\n    constructor() { super(enum_1.DateUnit.MILLISECOND); }\n}\nexports.DateMillisecond = DateMillisecond;\n/** @ignore */\nclass Time_ extends DataType {\n    constructor(unit, bitWidth) {\n        super();\n        this.unit = unit;\n        this.bitWidth = bitWidth;\n    }\n    get typeId() { return enum_1.Type.Time; }\n    toString() { return `Time${this.bitWidth}<${enum_1.TimeUnit[this.unit]}>`; }\n}\nTime_[Symbol.toStringTag] = ((proto) => {\n    proto.unit = null;\n    proto.bitWidth = null;\n    proto.ArrayType = Int32Array;\n    return proto[Symbol.toStringTag] = 'Time';\n})(Time_.prototype);\nexports.Time = Time_;\n/** @ignore */\nclass TimeSecond extends Time_ {\n    constructor() { super(enum_1.TimeUnit.SECOND, 32); }\n}\nexports.TimeSecond = TimeSecond;\n/** @ignore */\nclass TimeMillisecond extends Time_ {\n    constructor() { super(enum_1.TimeUnit.MILLISECOND, 32); }\n}\nexports.TimeMillisecond = TimeMillisecond;\n/** @ignore */\nclass TimeMicrosecond extends Time_ {\n    constructor() { super(enum_1.TimeUnit.MICROSECOND, 64); }\n}\nexports.TimeMicrosecond = TimeMicrosecond;\n/** @ignore */\nclass TimeNanosecond extends Time_ {\n    constructor() { super(enum_1.TimeUnit.NANOSECOND, 64); }\n}\nexports.TimeNanosecond = TimeNanosecond;\n/** @ignore */\nclass Timestamp_ extends DataType {\n    constructor(unit, timezone) {\n        super();\n        this.unit = unit;\n        this.timezone = timezone;\n    }\n    get typeId() { return enum_1.Type.Timestamp; }\n    toString() { return `Timestamp<${enum_1.TimeUnit[this.unit]}${this.timezone ? `, ${this.timezone}` : ``}>`; }\n}\nTimestamp_[Symbol.toStringTag] = ((proto) => {\n    proto.unit = null;\n    proto.timezone = null;\n    proto.ArrayType = Int32Array;\n    return proto[Symbol.toStringTag] = 'Timestamp';\n})(Timestamp_.prototype);\nexports.Timestamp = Timestamp_;\n/** @ignore */\nclass TimestampSecond extends Timestamp_ {\n    constructor(timezone) { super(enum_1.TimeUnit.SECOND, timezone); }\n}\nexports.TimestampSecond = TimestampSecond;\n/** @ignore */\nclass TimestampMillisecond extends Timestamp_ {\n    constructor(timezone) { super(enum_1.TimeUnit.MILLISECOND, timezone); }\n}\nexports.TimestampMillisecond = TimestampMillisecond;\n/** @ignore */\nclass TimestampMicrosecond extends Timestamp_ {\n    constructor(timezone) { super(enum_1.TimeUnit.MICROSECOND, timezone); }\n}\nexports.TimestampMicrosecond = TimestampMicrosecond;\n/** @ignore */\nclass TimestampNanosecond extends Timestamp_ {\n    constructor(timezone) { super(enum_1.TimeUnit.NANOSECOND, timezone); }\n}\nexports.TimestampNanosecond = TimestampNanosecond;\n/** @ignore */\nclass Interval_ extends DataType {\n    constructor(unit) {\n        super();\n        this.unit = unit;\n    }\n    get typeId() { return enum_1.Type.Interval; }\n    toString() { return `Interval<${enum_1.IntervalUnit[this.unit]}>`; }\n}\nInterval_[Symbol.toStringTag] = ((proto) => {\n    proto.unit = null;\n    proto.ArrayType = Int32Array;\n    return proto[Symbol.toStringTag] = 'Interval';\n})(Interval_.prototype);\nexports.Interval = Interval_;\n/** @ignore */\nclass IntervalDayTime extends Interval_ {\n    constructor() { super(enum_1.IntervalUnit.DAY_TIME); }\n}\nexports.IntervalDayTime = IntervalDayTime;\n/** @ignore */\nclass IntervalYearMonth extends Interval_ {\n    constructor() { super(enum_1.IntervalUnit.YEAR_MONTH); }\n}\nexports.IntervalYearMonth = IntervalYearMonth;\n/** @ignore */\nclass List extends DataType {\n    constructor(child) {\n        super();\n        this.children = [child];\n    }\n    get typeId() { return enum_1.Type.List; }\n    toString() { return `List<${this.valueType}>`; }\n    get valueType() { return this.children[0].type; }\n    get valueField() { return this.children[0]; }\n    get ArrayType() { return this.valueType.ArrayType; }\n}\nList[Symbol.toStringTag] = ((proto) => {\n    proto.children = null;\n    return proto[Symbol.toStringTag] = 'List';\n})(List.prototype);\nexports.List = List;\n/** @ignore */\nclass Struct extends DataType {\n    constructor(children) {\n        super();\n        this.children = children;\n        this.children = children;\n    }\n    get typeId() { return enum_1.Type.Struct; }\n    toString() { return `Struct<{${this.children.map((f) => `${f.name}:${f.type}`).join(`, `)}}>`; }\n}\nStruct[Symbol.toStringTag] = ((proto) => {\n    proto.children = null;\n    return proto[Symbol.toStringTag] = 'Struct';\n})(Struct.prototype);\nexports.Struct = Struct;\n/** @ignore */\nclass Union_ extends DataType {\n    constructor(mode, typeIds, children) {\n        super();\n        this.mode = mode;\n        this.children = children;\n        this.typeIds = typeIds = Int32Array.from(typeIds);\n        this.typeIdToChildIndex = typeIds.reduce((typeIdToChildIndex, typeId, idx) => {\n            return (typeIdToChildIndex[typeId] = idx) && typeIdToChildIndex || typeIdToChildIndex;\n        }, Object.create(null));\n    }\n    get typeId() { return enum_1.Type.Union; }\n    toString() {\n        return `${this[Symbol.toStringTag]}<${this.children.map((x) => `${x.type}`).join(` | `)}>`;\n    }\n}\nUnion_[Symbol.toStringTag] = ((proto) => {\n    proto.mode = null;\n    proto.typeIds = null;\n    proto.children = null;\n    proto.typeIdToChildIndex = null;\n    proto.ArrayType = Int8Array;\n    return proto[Symbol.toStringTag] = 'Union';\n})(Union_.prototype);\nexports.Union = Union_;\n/** @ignore */\nclass DenseUnion extends Union_ {\n    constructor(typeIds, children) {\n        super(enum_1.UnionMode.Dense, typeIds, children);\n    }\n}\nexports.DenseUnion = DenseUnion;\n/** @ignore */\nclass SparseUnion extends Union_ {\n    constructor(typeIds, children) {\n        super(enum_1.UnionMode.Sparse, typeIds, children);\n    }\n}\nexports.SparseUnion = SparseUnion;\n/** @ignore */\nclass FixedSizeBinary extends DataType {\n    constructor(byteWidth) {\n        super();\n        this.byteWidth = byteWidth;\n    }\n    get typeId() { return enum_1.Type.FixedSizeBinary; }\n    toString() { return `FixedSizeBinary[${this.byteWidth}]`; }\n}\nFixedSizeBinary[Symbol.toStringTag] = ((proto) => {\n    proto.byteWidth = null;\n    proto.ArrayType = Uint8Array;\n    return proto[Symbol.toStringTag] = 'FixedSizeBinary';\n})(FixedSizeBinary.prototype);\nexports.FixedSizeBinary = FixedSizeBinary;\n/** @ignore */\nclass FixedSizeList extends DataType {\n    constructor(listSize, child) {\n        super();\n        this.listSize = listSize;\n        this.children = [child];\n    }\n    get typeId() { return enum_1.Type.FixedSizeList; }\n    get valueType() { return this.children[0].type; }\n    get valueField() { return this.children[0]; }\n    get ArrayType() { return this.valueType.ArrayType; }\n    toString() { return `FixedSizeList[${this.listSize}]<${this.valueType}>`; }\n}\nFixedSizeList[Symbol.toStringTag] = ((proto) => {\n    proto.children = null;\n    proto.listSize = null;\n    return proto[Symbol.toStringTag] = 'FixedSizeList';\n})(FixedSizeList.prototype);\nexports.FixedSizeList = FixedSizeList;\n/** @ignore */\nclass Map_ extends DataType {\n    constructor(child, keysSorted = false) {\n        super();\n        this.children = [child];\n        this.keysSorted = keysSorted;\n    }\n    get typeId() { return enum_1.Type.Map; }\n    get keyType() { return this.children[0].type.children[0].type; }\n    get valueType() { return this.children[0].type.children[1].type; }\n    toString() { return `Map<{${this.children[0].type.children.map((f) => `${f.name}:${f.type}`).join(`, `)}}>`; }\n}\nMap_[Symbol.toStringTag] = ((proto) => {\n    proto.children = null;\n    proto.keysSorted = null;\n    return proto[Symbol.toStringTag] = 'Map_';\n})(Map_.prototype);\nexports.Map_ = Map_;\n/** @ignore */\nconst getId = ((atomicDictionaryId) => () => ++atomicDictionaryId)(-1);\n/** @ignore */\nclass Dictionary extends DataType {\n    constructor(dictionary, indices, id, isOrdered) {\n        super();\n        this.indices = indices;\n        this.dictionary = dictionary;\n        this.isOrdered = isOrdered || false;\n        this.id = id == null ? getId() : typeof id === 'number' ? id : id.low;\n    }\n    get typeId() { return enum_1.Type.Dictionary; }\n    get children() { return this.dictionary.children; }\n    get valueType() { return this.dictionary; }\n    get ArrayType() { return this.dictionary.ArrayType; }\n    toString() { return `Dictionary<${this.indices}, ${this.dictionary}>`; }\n}\nDictionary[Symbol.toStringTag] = ((proto) => {\n    proto.id = null;\n    proto.indices = null;\n    proto.isOrdered = null;\n    proto.dictionary = null;\n    return proto[Symbol.toStringTag] = 'Dictionary';\n})(Dictionary.prototype);\nexports.Dictionary = Dictionary;\n/** @ignore */\nfunction strideForType(type) {\n    let t = type;\n    switch (type.typeId) {\n        case enum_1.Type.Decimal: return 4;\n        case enum_1.Type.Timestamp: return 2;\n        case enum_1.Type.Date: return 1 + t.unit;\n        case enum_1.Type.Interval: return 1 + t.unit;\n        case enum_1.Type.Int: return 1 + +(t.bitWidth > 32);\n        case enum_1.Type.Time: return 1 + +(t.bitWidth > 32);\n        case enum_1.Type.FixedSizeList: return t.listSize;\n        case enum_1.Type.FixedSizeBinary: return t.byteWidth;\n        default: return 1;\n    }\n}\nexports.strideForType = strideForType;\n\n//# sourceMappingURL=type.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst schema_1 = require(\"../schema\");\nconst column_1 = require(\"../column\");\nconst vector_1 = require(\"../vector\");\nconst type_1 = require(\"../type\");\nconst chunked_1 = require(\"../vector/chunked\");\nconst isArray = Array.isArray;\n/** @ignore */\nexports.selectArgs = (Ctor, vals) => _selectArgs(Ctor, vals, [], 0);\n/** @ignore */\nexports.selectColumnArgs = (args) => {\n    const [fields, values] = _selectFieldArgs(args, [[], []]);\n    return values.map((x, i) => x instanceof column_1.Column ? column_1.Column.new(x.field.clone(fields[i]), x) :\n        x instanceof vector_1.Vector ? column_1.Column.new(fields[i], x) :\n            column_1.Column.new(fields[i], []));\n};\n/** @ignore */\nexports.selectFieldArgs = (args) => _selectFieldArgs(args, [[], []]);\n/** @ignore */\nexports.selectChunkArgs = (Ctor, vals) => _selectChunkArgs(Ctor, vals, [], 0);\n/** @ignore */\nexports.selectVectorChildrenArgs = (Ctor, vals) => _selectVectorChildrenArgs(Ctor, vals, [], 0);\n/** @ignore */\nexports.selectColumnChildrenArgs = (Ctor, vals) => _selectColumnChildrenArgs(Ctor, vals, [], 0);\n/** @ignore */\nfunction _selectArgs(Ctor, vals, res, idx) {\n    let value, j = idx;\n    let i = -1, n = vals.length;\n    while (++i < n) {\n        if (isArray(value = vals[i])) {\n            j = _selectArgs(Ctor, value, res, j).length;\n        }\n        else if (value instanceof Ctor) {\n            res[j++] = value;\n        }\n    }\n    return res;\n}\n/** @ignore */\nfunction _selectChunkArgs(Ctor, vals, res, idx) {\n    let value, j = idx;\n    let i = -1, n = vals.length;\n    while (++i < n) {\n        if (isArray(value = vals[i])) {\n            j = _selectChunkArgs(Ctor, value, res, j).length;\n        }\n        else if (value instanceof chunked_1.Chunked) {\n            j = _selectChunkArgs(Ctor, value.chunks, res, j).length;\n        }\n        else if (value instanceof Ctor) {\n            res[j++] = value;\n        }\n    }\n    return res;\n}\n/** @ignore */\nfunction _selectVectorChildrenArgs(Ctor, vals, res, idx) {\n    let value, j = idx;\n    let i = -1, n = vals.length;\n    while (++i < n) {\n        if (isArray(value = vals[i])) {\n            j = _selectVectorChildrenArgs(Ctor, value, res, j).length;\n        }\n        else if (value instanceof Ctor) {\n            j = _selectArgs(vector_1.Vector, value.schema.fields.map((_, i) => value.getChildAt(i)), res, j).length;\n        }\n        else if (value instanceof vector_1.Vector) {\n            res[j++] = value;\n        }\n    }\n    return res;\n}\n/** @ignore */\nfunction _selectColumnChildrenArgs(Ctor, vals, res, idx) {\n    let value, j = idx;\n    let i = -1, n = vals.length;\n    while (++i < n) {\n        if (isArray(value = vals[i])) {\n            j = _selectColumnChildrenArgs(Ctor, value, res, j).length;\n        }\n        else if (value instanceof Ctor) {\n            j = _selectArgs(column_1.Column, value.schema.fields.map((f, i) => column_1.Column.new(f, value.getChildAt(i))), res, j).length;\n        }\n        else if (value instanceof column_1.Column) {\n            res[j++] = value;\n        }\n    }\n    return res;\n}\n/** @ignore */\nconst toKeysAndValues = (xs, [k, v], i) => (xs[0][i] = k, xs[1][i] = v, xs);\n/** @ignore */\nfunction _selectFieldArgs(vals, ret) {\n    let keys, n;\n    switch (n = vals.length) {\n        case 0: return ret;\n        case 1:\n            keys = ret[0];\n            if (!(vals[0])) {\n                return ret;\n            }\n            if (isArray(vals[0])) {\n                return _selectFieldArgs(vals[0], ret);\n            }\n            if (!(vals[0] instanceof data_1.Data || vals[0] instanceof vector_1.Vector || vals[0] instanceof type_1.DataType)) {\n                [keys, vals] = Object.entries(vals[0]).reduce(toKeysAndValues, ret);\n            }\n            break;\n        default:\n            !isArray(keys = vals[n - 1])\n                ? (vals = isArray(vals[0]) ? vals[0] : vals, keys = [])\n                : (vals = isArray(vals[0]) ? vals[0] : vals.slice(0, n - 1));\n    }\n    let fieldIndex = -1;\n    let valueIndex = -1;\n    let idx = -1, len = vals.length;\n    let field;\n    let val;\n    let [fields, values] = ret;\n    while (++idx < len) {\n        val = vals[idx];\n        if (val instanceof column_1.Column && (values[++valueIndex] = val)) {\n            fields[++fieldIndex] = val.field.clone(keys[idx], val.type, true);\n        }\n        else {\n            ({ [idx]: field = idx } = keys);\n            if (val instanceof type_1.DataType && (values[++valueIndex] = val)) {\n                fields[++fieldIndex] = schema_1.Field.new(field, val, true);\n            }\n            else if (val && val.type && (values[++valueIndex] = val)) {\n                val instanceof data_1.Data && (values[valueIndex] = val = vector_1.Vector.new(val));\n                fields[++fieldIndex] = schema_1.Field.new(field, val.type, true);\n            }\n        }\n    }\n    return ret;\n}\n\n//# sourceMappingURL=args.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @ignore */\nfunction getBool(_data, _index, byte, bit) {\n    return (byte & 1 << bit) !== 0;\n}\nexports.getBool = getBool;\n/** @ignore */\nfunction getBit(_data, _index, byte, bit) {\n    return (byte & 1 << bit) >> bit;\n}\nexports.getBit = getBit;\n/** @ignore */\nfunction setBool(bytes, index, value) {\n    return value ?\n        !!(bytes[index >> 3] |= (1 << (index % 8))) || true :\n        !(bytes[index >> 3] &= ~(1 << (index % 8))) && false;\n}\nexports.setBool = setBool;\n/** @ignore */\nfunction truncateBitmap(offset, length, bitmap) {\n    const alignedSize = (bitmap.byteLength + 7) & ~7;\n    if (offset > 0 || bitmap.byteLength < alignedSize) {\n        const bytes = new Uint8Array(alignedSize);\n        // If the offset is a multiple of 8 bits, it's safe to slice the bitmap\n        bytes.set(offset % 8 === 0 ? bitmap.subarray(offset >> 3) :\n            // Otherwise iterate each bit from the offset and return a new one\n            packBools(iterateBits(bitmap, offset, length, null, getBool)).subarray(0, alignedSize));\n        return bytes;\n    }\n    return bitmap;\n}\nexports.truncateBitmap = truncateBitmap;\n/** @ignore */\nfunction packBools(values) {\n    let xs = [];\n    let i = 0, bit = 0, byte = 0;\n    for (const value of values) {\n        value && (byte |= 1 << bit);\n        if (++bit === 8) {\n            xs[i++] = byte;\n            byte = bit = 0;\n        }\n    }\n    if (i === 0 || bit > 0) {\n        xs[i++] = byte;\n    }\n    let b = new Uint8Array((xs.length + 7) & ~7);\n    b.set(xs);\n    return b;\n}\nexports.packBools = packBools;\n/** @ignore */\nfunction* iterateBits(bytes, begin, length, context, get) {\n    let bit = begin % 8;\n    let byteIndex = begin >> 3;\n    let index = 0, remaining = length;\n    for (; remaining > 0; bit = 0) {\n        let byte = bytes[byteIndex++];\n        do {\n            yield get(context, index++, byte, bit);\n        } while (--remaining > 0 && ++bit < 8);\n    }\n}\nexports.iterateBits = iterateBits;\n/**\n * Compute the population count (the number of bits set to 1) for a range of bits in a Uint8Array.\n * @param vector The Uint8Array of bits for which to compute the population count.\n * @param lhs The range's left-hand side (or start) bit\n * @param rhs The range's right-hand side (or end) bit\n */\n/** @ignore */\nfunction popcnt_bit_range(data, lhs, rhs) {\n    if (rhs - lhs <= 0) {\n        return 0;\n    }\n    // If the bit range is less than one byte, sum the 1 bits in the bit range\n    if (rhs - lhs < 8) {\n        let sum = 0;\n        for (const bit of iterateBits(data, lhs, rhs - lhs, data, getBit)) {\n            sum += bit;\n        }\n        return sum;\n    }\n    // Get the next lowest multiple of 8 from the right hand side\n    const rhsInside = rhs >> 3 << 3;\n    // Get the next highest multiple of 8 from the left hand side\n    const lhsInside = lhs + (lhs % 8 === 0 ? 0 : 8 - lhs % 8);\n    return (\n    // Get the popcnt of bits between the left hand side, and the next highest multiple of 8\n    popcnt_bit_range(data, lhs, lhsInside) +\n        // Get the popcnt of bits between the right hand side, and the next lowest multiple of 8\n        popcnt_bit_range(data, rhsInside, rhs) +\n        // Get the popcnt of all bits between the left and right hand sides' multiples of 8\n        popcnt_array(data, lhsInside >> 3, (rhsInside - lhsInside) >> 3));\n}\nexports.popcnt_bit_range = popcnt_bit_range;\n/** @ignore */\nfunction popcnt_array(arr, byteOffset, byteLength) {\n    let cnt = 0, pos = byteOffset | 0;\n    const view = new DataView(arr.buffer, arr.byteOffset, arr.byteLength);\n    const len = byteLength === void 0 ? arr.byteLength : pos + byteLength;\n    while (len - pos >= 4) {\n        cnt += popcnt_uint32(view.getUint32(pos));\n        pos += 4;\n    }\n    while (len - pos >= 2) {\n        cnt += popcnt_uint32(view.getUint16(pos));\n        pos += 2;\n    }\n    while (len - pos >= 1) {\n        cnt += popcnt_uint32(view.getUint8(pos));\n        pos += 1;\n    }\n    return cnt;\n}\nexports.popcnt_array = popcnt_array;\n/** @ignore */\nfunction popcnt_uint32(uint32) {\n    let i = uint32 | 0;\n    i = i - ((i >>> 1) & 0x55555555);\n    i = (i & 0x33333333) + ((i >>> 2) & 0x33333333);\n    return (((i + (i >>> 4)) & 0x0F0F0F0F) * 0x01010101) >>> 24;\n}\nexports.popcnt_uint32 = popcnt_uint32;\n\n//# sourceMappingURL=bit.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"./buffer\");\nconst compat_1 = require(\"./compat\");\n/** @ignore */\nexports.isArrowBigNumSymbol = Symbol.for('isArrowBigNum');\n/** @ignore */\nfunction BigNum(x, ...xs) {\n    if (xs.length === 0) {\n        return Object.setPrototypeOf(buffer_1.toArrayBufferView(this['TypedArray'], x), this.constructor.prototype);\n    }\n    return Object.setPrototypeOf(new this['TypedArray'](x, ...xs), this.constructor.prototype);\n}\nBigNum.prototype[exports.isArrowBigNumSymbol] = true;\nBigNum.prototype.toJSON = function () { return `\"${exports.bignumToString(this)}\"`; };\nBigNum.prototype.valueOf = function () { return bignumToNumber(this); };\nBigNum.prototype.toString = function () { return exports.bignumToString(this); };\nBigNum.prototype[Symbol.toPrimitive] = function (hint = 'default') {\n    switch (hint) {\n        case 'number': return bignumToNumber(this);\n        case 'string': return exports.bignumToString(this);\n        case 'default': return exports.bignumToBigInt(this);\n    }\n    return exports.bignumToString(this);\n};\n/** @ignore */\nfunction SignedBigNum(...args) { return BigNum.apply(this, args); }\n/** @ignore */\nfunction UnsignedBigNum(...args) { return BigNum.apply(this, args); }\n/** @ignore */\nfunction DecimalBigNum(...args) { return BigNum.apply(this, args); }\nObject.setPrototypeOf(SignedBigNum.prototype, Object.create(Int32Array.prototype));\nObject.setPrototypeOf(UnsignedBigNum.prototype, Object.create(Uint32Array.prototype));\nObject.setPrototypeOf(DecimalBigNum.prototype, Object.create(Uint32Array.prototype));\nObject.assign(SignedBigNum.prototype, BigNum.prototype, { 'constructor': SignedBigNum, 'signed': true, 'TypedArray': Int32Array, 'BigIntArray': compat_1.BigInt64Array });\nObject.assign(UnsignedBigNum.prototype, BigNum.prototype, { 'constructor': UnsignedBigNum, 'signed': false, 'TypedArray': Uint32Array, 'BigIntArray': compat_1.BigUint64Array });\nObject.assign(DecimalBigNum.prototype, BigNum.prototype, { 'constructor': DecimalBigNum, 'signed': true, 'TypedArray': Uint32Array, 'BigIntArray': compat_1.BigUint64Array });\n/** @ignore */\nfunction bignumToNumber(bn) {\n    let { buffer, byteOffset, length, 'signed': signed } = bn;\n    let words = new Int32Array(buffer, byteOffset, length);\n    let number = 0, i = 0, n = words.length, hi, lo;\n    while (i < n) {\n        lo = words[i++];\n        hi = words[i++];\n        signed || (hi = hi >>> 0);\n        number += (lo >>> 0) + (hi * (i ** 32));\n    }\n    return number;\n}\nif (!compat_1.BigIntAvailable) {\n    exports.bignumToString = decimalToString;\n    exports.bignumToBigInt = exports.bignumToString;\n}\nelse {\n    exports.bignumToBigInt = ((a) => a.byteLength === 8 ? new a['BigIntArray'](a.buffer, a.byteOffset, 1)[0] : decimalToString(a));\n    exports.bignumToString = ((a) => a.byteLength === 8 ? `${new a['BigIntArray'](a.buffer, a.byteOffset, 1)[0]}` : decimalToString(a));\n}\n/** @ignore */\nfunction decimalToString(a) {\n    let digits = '';\n    let base64 = new Uint32Array(2);\n    let base32 = new Uint16Array(a.buffer, a.byteOffset, a.byteLength / 2);\n    let checks = new Uint32Array((base32 = new Uint16Array(base32).reverse()).buffer);\n    let i = -1, n = base32.length - 1;\n    do {\n        for (base64[0] = base32[i = 0]; i < n;) {\n            base32[i++] = base64[1] = base64[0] / 10;\n            base64[0] = ((base64[0] - base64[1] * 10) << 16) + base32[i];\n        }\n        base32[i] = base64[1] = base64[0] / 10;\n        base64[0] = base64[0] - base64[1] * 10;\n        digits = `${base64[0]}${digits}`;\n    } while (checks[0] || checks[1] || checks[2] || checks[3]);\n    return digits ? digits : `0`;\n}\n/** @ignore */\nclass BN {\n    constructor(num, isSigned) {\n        return BN.new(num, isSigned);\n    }\n    /** @nocollapse */\n    static new(num, isSigned) {\n        switch (isSigned) {\n            case true: return new SignedBigNum(num);\n            case false: return new UnsignedBigNum(num);\n        }\n        switch (num.constructor) {\n            case Int8Array:\n            case Int16Array:\n            case Int32Array:\n            case compat_1.BigInt64Array:\n                return new SignedBigNum(num);\n        }\n        if (num.byteLength === 16) {\n            return new DecimalBigNum(num);\n        }\n        return new UnsignedBigNum(num);\n    }\n    /** @nocollapse */\n    static signed(num) {\n        return new SignedBigNum(num);\n    }\n    /** @nocollapse */\n    static unsigned(num) {\n        return new UnsignedBigNum(num);\n    }\n    /** @nocollapse */\n    static decimal(num) {\n        return new DecimalBigNum(num);\n    }\n}\nexports.BN = BN;\n\n//# sourceMappingURL=bn.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst flatbuffers_1 = require(\"flatbuffers\");\nconst utf8_1 = require(\"../util/utf8\");\nvar ByteBuffer = flatbuffers_1.flatbuffers.ByteBuffer;\nconst compat_1 = require(\"./compat\");\n/** @ignore */\nconst SharedArrayBuf = (typeof SharedArrayBuffer !== 'undefined' ? SharedArrayBuffer : ArrayBuffer);\n/** @ignore */\nfunction collapseContiguousByteRanges(chunks) {\n    let result = chunks[0] ? [chunks[0]] : [];\n    let xOffset, yOffset, xLen, yLen;\n    for (let x, y, i = 0, j = 0, n = chunks.length; ++i < n;) {\n        x = result[j];\n        y = chunks[i];\n        // continue if x and y don't share the same underlying ArrayBuffer, or if x isn't before y\n        if (!x || !y || x.buffer !== y.buffer || y.byteOffset < x.byteOffset) {\n            y && (result[++j] = y);\n            continue;\n        }\n        ({ byteOffset: xOffset, byteLength: xLen } = x);\n        ({ byteOffset: yOffset, byteLength: yLen } = y);\n        // continue if the byte ranges of x and y aren't contiguous\n        if ((xOffset + xLen) < yOffset || (yOffset + yLen) < xOffset) {\n            y && (result[++j] = y);\n            continue;\n        }\n        result[j] = new Uint8Array(x.buffer, xOffset, yOffset - xOffset + yLen);\n    }\n    return result;\n}\n/** @ignore */\nfunction memcpy(target, source, targetByteOffset = 0, sourceByteLength = source.byteLength) {\n    const targetByteLength = target.byteLength;\n    const dst = new Uint8Array(target.buffer, target.byteOffset, targetByteLength);\n    const src = new Uint8Array(source.buffer, source.byteOffset, Math.min(sourceByteLength, targetByteLength));\n    dst.set(src, targetByteOffset);\n    return target;\n}\nexports.memcpy = memcpy;\n/** @ignore */\nfunction joinUint8Arrays(chunks, size) {\n    // collapse chunks that share the same underlying ArrayBuffer and whose byte ranges overlap,\n    // to avoid unnecessarily copying the bytes to do this buffer join. This is a common case during\n    // streaming, where we may be reading partial byte ranges out of the same underlying ArrayBuffer\n    let result = collapseContiguousByteRanges(chunks);\n    let byteLength = result.reduce((x, b) => x + b.byteLength, 0);\n    let source, sliced, buffer;\n    let offset = 0, index = -1, length = Math.min(size || Infinity, byteLength);\n    for (let n = result.length; ++index < n;) {\n        source = result[index];\n        sliced = source.subarray(0, Math.min(source.length, length - offset));\n        if (length <= (offset + sliced.length)) {\n            if (sliced.length < source.length) {\n                result[index] = source.subarray(sliced.length);\n            }\n            else if (sliced.length === source.length) {\n                index++;\n            }\n            buffer ? memcpy(buffer, sliced, offset) : (buffer = sliced);\n            break;\n        }\n        memcpy(buffer || (buffer = new Uint8Array(length)), sliced, offset);\n        offset += sliced.length;\n    }\n    return [buffer || new Uint8Array(0), result.slice(index), byteLength - (buffer ? buffer.byteLength : 0)];\n}\nexports.joinUint8Arrays = joinUint8Arrays;\nfunction toArrayBufferView(ArrayBufferViewCtor, input) {\n    let value = compat_1.isIteratorResult(input) ? input.value : input;\n    if (value instanceof ArrayBufferViewCtor) {\n        if (ArrayBufferViewCtor === Uint8Array) {\n            // Node's `Buffer` class passes the `instanceof Uint8Array` check, but we need\n            // a real Uint8Array, since Buffer#slice isn't the same as Uint8Array#slice :/\n            return new ArrayBufferViewCtor(value.buffer, value.byteOffset, value.byteLength);\n        }\n        return value;\n    }\n    if (!value) {\n        return new ArrayBufferViewCtor(0);\n    }\n    if (typeof value === 'string') {\n        value = utf8_1.encodeUtf8(value);\n    }\n    if (value instanceof ArrayBuffer) {\n        return new ArrayBufferViewCtor(value);\n    }\n    if (value instanceof SharedArrayBuf) {\n        return new ArrayBufferViewCtor(value);\n    }\n    if (value instanceof ByteBuffer) {\n        return toArrayBufferView(ArrayBufferViewCtor, value.bytes());\n    }\n    return !ArrayBuffer.isView(value) ? ArrayBufferViewCtor.from(value) : value.byteLength <= 0 ? new ArrayBufferViewCtor(0)\n        : new ArrayBufferViewCtor(value.buffer, value.byteOffset, value.byteLength / ArrayBufferViewCtor.BYTES_PER_ELEMENT);\n}\nexports.toArrayBufferView = toArrayBufferView;\n/** @ignore */ exports.toInt8Array = (input) => toArrayBufferView(Int8Array, input);\n/** @ignore */ exports.toInt16Array = (input) => toArrayBufferView(Int16Array, input);\n/** @ignore */ exports.toInt32Array = (input) => toArrayBufferView(Int32Array, input);\n/** @ignore */ exports.toBigInt64Array = (input) => toArrayBufferView(compat_1.BigInt64Array, input);\n/** @ignore */ exports.toUint8Array = (input) => toArrayBufferView(Uint8Array, input);\n/** @ignore */ exports.toUint16Array = (input) => toArrayBufferView(Uint16Array, input);\n/** @ignore */ exports.toUint32Array = (input) => toArrayBufferView(Uint32Array, input);\n/** @ignore */ exports.toBigUint64Array = (input) => toArrayBufferView(compat_1.BigUint64Array, input);\n/** @ignore */ exports.toFloat32Array = (input) => toArrayBufferView(Float32Array, input);\n/** @ignore */ exports.toFloat64Array = (input) => toArrayBufferView(Float64Array, input);\n/** @ignore */ exports.toUint8ClampedArray = (input) => toArrayBufferView(Uint8ClampedArray, input);\n/** @ignore */\nconst pump = (iterator) => { iterator.next(); return iterator; };\n/** @ignore */\nfunction* toArrayBufferViewIterator(ArrayCtor, source) {\n    const wrap = function* (x) { yield x; };\n    const buffers = (typeof source === 'string') ? wrap(source)\n        : (ArrayBuffer.isView(source)) ? wrap(source)\n            : (source instanceof ArrayBuffer) ? wrap(source)\n                : (source instanceof SharedArrayBuf) ? wrap(source)\n                    : !compat_1.isIterable(source) ? wrap(source) : source;\n    yield* pump((function* (it) {\n        let r = null;\n        do {\n            r = it.next(yield toArrayBufferView(ArrayCtor, r));\n        } while (!r.done);\n    })(buffers[Symbol.iterator]()));\n}\nexports.toArrayBufferViewIterator = toArrayBufferViewIterator;\n/** @ignore */ exports.toInt8ArrayIterator = (input) => toArrayBufferViewIterator(Int8Array, input);\n/** @ignore */ exports.toInt16ArrayIterator = (input) => toArrayBufferViewIterator(Int16Array, input);\n/** @ignore */ exports.toInt32ArrayIterator = (input) => toArrayBufferViewIterator(Int32Array, input);\n/** @ignore */ exports.toUint8ArrayIterator = (input) => toArrayBufferViewIterator(Uint8Array, input);\n/** @ignore */ exports.toUint16ArrayIterator = (input) => toArrayBufferViewIterator(Uint16Array, input);\n/** @ignore */ exports.toUint32ArrayIterator = (input) => toArrayBufferViewIterator(Uint32Array, input);\n/** @ignore */ exports.toFloat32ArrayIterator = (input) => toArrayBufferViewIterator(Float32Array, input);\n/** @ignore */ exports.toFloat64ArrayIterator = (input) => toArrayBufferViewIterator(Float64Array, input);\n/** @ignore */ exports.toUint8ClampedArrayIterator = (input) => toArrayBufferViewIterator(Uint8ClampedArray, input);\n/** @ignore */\nasync function* toArrayBufferViewAsyncIterator(ArrayCtor, source) {\n    // if a Promise, unwrap the Promise and iterate the resolved value\n    if (compat_1.isPromise(source)) {\n        return yield* toArrayBufferViewAsyncIterator(ArrayCtor, await source);\n    }\n    const wrap = async function* (x) { yield await x; };\n    const emit = async function* (source) {\n        yield* pump((function* (it) {\n            let r = null;\n            do {\n                r = it.next(yield r && r.value);\n            } while (!r.done);\n        })(source[Symbol.iterator]()));\n    };\n    const buffers = (typeof source === 'string') ? wrap(source) // if string, wrap in an AsyncIterableIterator\n        : (ArrayBuffer.isView(source)) ? wrap(source) // if TypedArray, wrap in an AsyncIterableIterator\n            : (source instanceof ArrayBuffer) ? wrap(source) // if ArrayBuffer, wrap in an AsyncIterableIterator\n                : (source instanceof SharedArrayBuf) ? wrap(source) // if SharedArrayBuffer, wrap in an AsyncIterableIterator\n                    : compat_1.isIterable(source) ? emit(source) // If Iterable, wrap in an AsyncIterableIterator and compose the `next` values\n                        : !compat_1.isAsyncIterable(source) ? wrap(source) // If not an AsyncIterable, treat as a sentinel and wrap in an AsyncIterableIterator\n                            : source; // otherwise if AsyncIterable, use it\n    yield* pump((async function* (it) {\n        let r = null;\n        do {\n            r = await it.next(yield toArrayBufferView(ArrayCtor, r));\n        } while (!r.done);\n    })(buffers[Symbol.asyncIterator]()));\n}\nexports.toArrayBufferViewAsyncIterator = toArrayBufferViewAsyncIterator;\n/** @ignore */ exports.toInt8ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Int8Array, input);\n/** @ignore */ exports.toInt16ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Int16Array, input);\n/** @ignore */ exports.toInt32ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Int32Array, input);\n/** @ignore */ exports.toUint8ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Uint8Array, input);\n/** @ignore */ exports.toUint16ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Uint16Array, input);\n/** @ignore */ exports.toUint32ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Uint32Array, input);\n/** @ignore */ exports.toFloat32ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Float32Array, input);\n/** @ignore */ exports.toFloat64ArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Float64Array, input);\n/** @ignore */ exports.toUint8ClampedArrayAsyncIterator = (input) => toArrayBufferViewAsyncIterator(Uint8ClampedArray, input);\n/** @ignore */\nfunction rebaseValueOffsets(offset, length, valueOffsets) {\n    // If we have a non-zero offset, create a new offsets array with the values\n    // shifted by the start offset, such that the new start offset is 0\n    if (offset !== 0) {\n        valueOffsets = valueOffsets.slice(0, length + 1);\n        for (let i = -1; ++i <= length;) {\n            valueOffsets[i] += offset;\n        }\n    }\n    return valueOffsets;\n}\nexports.rebaseValueOffsets = rebaseValueOffsets;\n/** @ignore */\nfunction compareArrayLike(a, b) {\n    let i = 0, n = a.length;\n    if (n !== b.length) {\n        return false;\n    }\n    if (n > 0) {\n        do {\n            if (a[i] !== b[i]) {\n                return false;\n            }\n        } while (++i < n);\n    }\n    return true;\n}\nexports.compareArrayLike = compareArrayLike;\n\n//# sourceMappingURL=buffer.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst interfaces_1 = require(\"../io/interfaces\");\n/** @ignore */\nconst [BigIntCtor, BigIntAvailable] = (() => {\n    const BigIntUnavailableError = () => { throw new Error('BigInt is not available in this environment'); };\n    function BigIntUnavailable() { throw BigIntUnavailableError(); }\n    BigIntUnavailable.asIntN = () => { throw BigIntUnavailableError(); };\n    BigIntUnavailable.asUintN = () => { throw BigIntUnavailableError(); };\n    return typeof BigInt !== 'undefined' ? [BigInt, true] : [BigIntUnavailable, false];\n})();\nexports.BigInt = BigIntCtor;\nexports.BigIntAvailable = BigIntAvailable;\n/** @ignore */\nconst [BigInt64ArrayCtor, BigInt64ArrayAvailable] = (() => {\n    const BigInt64ArrayUnavailableError = () => { throw new Error('BigInt64Array is not available in this environment'); };\n    class BigInt64ArrayUnavailable {\n        static get BYTES_PER_ELEMENT() { return 8; }\n        static of() { throw BigInt64ArrayUnavailableError(); }\n        static from() { throw BigInt64ArrayUnavailableError(); }\n        constructor() { throw BigInt64ArrayUnavailableError(); }\n    }\n    return typeof BigInt64Array !== 'undefined' ? [BigInt64Array, true] : [BigInt64ArrayUnavailable, false];\n})();\nexports.BigInt64Array = BigInt64ArrayCtor;\nexports.BigInt64ArrayAvailable = BigInt64ArrayAvailable;\n/** @ignore */\nconst [BigUint64ArrayCtor, BigUint64ArrayAvailable] = (() => {\n    const BigUint64ArrayUnavailableError = () => { throw new Error('BigUint64Array is not available in this environment'); };\n    class BigUint64ArrayUnavailable {\n        static get BYTES_PER_ELEMENT() { return 8; }\n        static of() { throw BigUint64ArrayUnavailableError(); }\n        static from() { throw BigUint64ArrayUnavailableError(); }\n        constructor() { throw BigUint64ArrayUnavailableError(); }\n    }\n    return typeof BigUint64Array !== 'undefined' ? [BigUint64Array, true] : [BigUint64ArrayUnavailable, false];\n})();\nexports.BigUint64Array = BigUint64ArrayCtor;\nexports.BigUint64ArrayAvailable = BigUint64ArrayAvailable;\n/** @ignore */ const isNumber = (x) => typeof x === 'number';\n/** @ignore */ const isBoolean = (x) => typeof x === 'boolean';\n/** @ignore */ const isFunction = (x) => typeof x === 'function';\n/** @ignore */\nexports.isObject = (x) => x != null && Object(x) === x;\n/** @ignore */\nexports.isPromise = (x) => {\n    return exports.isObject(x) && isFunction(x.then);\n};\n/** @ignore */\nexports.isObservable = (x) => {\n    return exports.isObject(x) && isFunction(x.subscribe);\n};\n/** @ignore */\nexports.isIterable = (x) => {\n    return exports.isObject(x) && isFunction(x[Symbol.iterator]);\n};\n/** @ignore */\nexports.isAsyncIterable = (x) => {\n    return exports.isObject(x) && isFunction(x[Symbol.asyncIterator]);\n};\n/** @ignore */\nexports.isArrowJSON = (x) => {\n    return exports.isObject(x) && exports.isObject(x['schema']);\n};\n/** @ignore */\nexports.isArrayLike = (x) => {\n    return exports.isObject(x) && isNumber(x['length']);\n};\n/** @ignore */\nexports.isIteratorResult = (x) => {\n    return exports.isObject(x) && ('done' in x) && ('value' in x);\n};\n/** @ignore */\nexports.isUnderlyingSink = (x) => {\n    return exports.isObject(x) &&\n        isFunction(x['abort']) &&\n        isFunction(x['close']) &&\n        isFunction(x['start']) &&\n        isFunction(x['write']);\n};\n/** @ignore */\nexports.isFileHandle = (x) => {\n    return exports.isObject(x) && isFunction(x['stat']) && isNumber(x['fd']);\n};\n/** @ignore */\nexports.isFSReadStream = (x) => {\n    return exports.isReadableNodeStream(x) && isNumber(x['bytesRead']);\n};\n/** @ignore */\nexports.isFetchResponse = (x) => {\n    return exports.isObject(x) && exports.isReadableDOMStream(x['body']);\n};\n/** @ignore */\nexports.isWritableDOMStream = (x) => {\n    return exports.isObject(x) &&\n        isFunction(x['abort']) &&\n        isFunction(x['getWriter']) &&\n        !(x instanceof interfaces_1.ReadableInterop);\n};\n/** @ignore */\nexports.isReadableDOMStream = (x) => {\n    return exports.isObject(x) &&\n        isFunction(x['cancel']) &&\n        isFunction(x['getReader']) &&\n        !(x instanceof interfaces_1.ReadableInterop);\n};\n/** @ignore */\nexports.isWritableNodeStream = (x) => {\n    return exports.isObject(x) &&\n        isFunction(x['end']) &&\n        isFunction(x['write']) &&\n        isBoolean(x['writable']) &&\n        !(x instanceof interfaces_1.ReadableInterop);\n};\n/** @ignore */\nexports.isReadableNodeStream = (x) => {\n    return exports.isObject(x) &&\n        isFunction(x['read']) &&\n        isFunction(x['pipe']) &&\n        isBoolean(x['readable']) &&\n        !(x instanceof interfaces_1.ReadableInterop);\n};\n\n//# sourceMappingURL=compat.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @ignore */\nfunction partial0(visit) {\n    return function () { return visit(this); };\n}\nexports.partial0 = partial0;\n/** @ignore */\nfunction partial1(visit) {\n    return function (a) { return visit(this, a); };\n}\nexports.partial1 = partial1;\n/** @ignore */\nfunction partial2(visit) {\n    return function (a, b) { return visit(this, a, b); };\n}\nexports.partial2 = partial2;\n\n//# sourceMappingURL=fn.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @ignore */\nconst carryBit16 = 1 << 16;\n/** @ignore */\nfunction intAsHex(value) {\n    if (value < 0) {\n        value = 0xFFFFFFFF + value + 1;\n    }\n    return `0x${value.toString(16)}`;\n}\n/** @ignore */\nconst kInt32DecimalDigits = 8;\n/** @ignore */\nconst kPowersOfTen = [1,\n    10,\n    100,\n    1000,\n    10000,\n    100000,\n    1000000,\n    10000000,\n    100000000];\n/** @ignore */\nclass BaseInt64 {\n    constructor(buffer) {\n        this.buffer = buffer;\n    }\n    high() { return this.buffer[1]; }\n    low() { return this.buffer[0]; }\n    _times(other) {\n        // Break the left and right numbers into 16 bit chunks\n        // so that we can multiply them without overflow.\n        const L = new Uint32Array([\n            this.buffer[1] >>> 16,\n            this.buffer[1] & 0xFFFF,\n            this.buffer[0] >>> 16,\n            this.buffer[0] & 0xFFFF\n        ]);\n        const R = new Uint32Array([\n            other.buffer[1] >>> 16,\n            other.buffer[1] & 0xFFFF,\n            other.buffer[0] >>> 16,\n            other.buffer[0] & 0xFFFF\n        ]);\n        let product = L[3] * R[3];\n        this.buffer[0] = product & 0xFFFF;\n        let sum = product >>> 16;\n        product = L[2] * R[3];\n        sum += product;\n        product = (L[3] * R[2]) >>> 0;\n        sum += product;\n        this.buffer[0] += sum << 16;\n        this.buffer[1] = (sum >>> 0 < product ? carryBit16 : 0);\n        this.buffer[1] += sum >>> 16;\n        this.buffer[1] += L[1] * R[3] + L[2] * R[2] + L[3] * R[1];\n        this.buffer[1] += (L[0] * R[3] + L[1] * R[2] + L[2] * R[1] + L[3] * R[0]) << 16;\n        return this;\n    }\n    _plus(other) {\n        const sum = (this.buffer[0] + other.buffer[0]) >>> 0;\n        this.buffer[1] += other.buffer[1];\n        if (sum < (this.buffer[0] >>> 0)) {\n            ++this.buffer[1];\n        }\n        this.buffer[0] = sum;\n    }\n    lessThan(other) {\n        return this.buffer[1] < other.buffer[1] ||\n            (this.buffer[1] === other.buffer[1] && this.buffer[0] < other.buffer[0]);\n    }\n    equals(other) {\n        return this.buffer[1] === other.buffer[1] && this.buffer[0] == other.buffer[0];\n    }\n    greaterThan(other) {\n        return other.lessThan(this);\n    }\n    hex() {\n        return `${intAsHex(this.buffer[1])} ${intAsHex(this.buffer[0])}`;\n    }\n}\nexports.BaseInt64 = BaseInt64;\n/** @ignore */\nclass Uint64 extends BaseInt64 {\n    times(other) {\n        this._times(other);\n        return this;\n    }\n    plus(other) {\n        this._plus(other);\n        return this;\n    }\n    /** @nocollapse */\n    static from(val, out_buffer = new Uint32Array(2)) {\n        return Uint64.fromString(typeof (val) === 'string' ? val : val.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromNumber(num, out_buffer = new Uint32Array(2)) {\n        // Always parse numbers as strings - pulling out high and low bits\n        // directly seems to lose precision sometimes\n        // For example:\n        //     > -4613034156400212000 >>> 0\n        //     721782784\n        // The correct lower 32-bits are 721782752\n        return Uint64.fromString(num.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromString(str, out_buffer = new Uint32Array(2)) {\n        const length = str.length;\n        let out = new Uint64(out_buffer);\n        for (let posn = 0; posn < length;) {\n            const group = kInt32DecimalDigits < length - posn ?\n                kInt32DecimalDigits : length - posn;\n            const chunk = new Uint64(new Uint32Array([parseInt(str.substr(posn, group), 10), 0]));\n            const multiple = new Uint64(new Uint32Array([kPowersOfTen[group], 0]));\n            out.times(multiple);\n            out.plus(chunk);\n            posn += group;\n        }\n        return out;\n    }\n    /** @nocollapse */\n    static convertArray(values) {\n        const data = new Uint32Array(values.length * 2);\n        for (let i = -1, n = values.length; ++i < n;) {\n            Uint64.from(values[i], new Uint32Array(data.buffer, data.byteOffset + 2 * i * 4, 2));\n        }\n        return data;\n    }\n    /** @nocollapse */\n    static multiply(left, right) {\n        let rtrn = new Uint64(new Uint32Array(left.buffer));\n        return rtrn.times(right);\n    }\n    /** @nocollapse */\n    static add(left, right) {\n        let rtrn = new Uint64(new Uint32Array(left.buffer));\n        return rtrn.plus(right);\n    }\n}\nexports.Uint64 = Uint64;\n/** @ignore */\nclass Int64 extends BaseInt64 {\n    negate() {\n        this.buffer[0] = ~this.buffer[0] + 1;\n        this.buffer[1] = ~this.buffer[1];\n        if (this.buffer[0] == 0) {\n            ++this.buffer[1];\n        }\n        return this;\n    }\n    times(other) {\n        this._times(other);\n        return this;\n    }\n    plus(other) {\n        this._plus(other);\n        return this;\n    }\n    lessThan(other) {\n        // force high bytes to be signed\n        const this_high = this.buffer[1] << 0;\n        const other_high = other.buffer[1] << 0;\n        return this_high < other_high ||\n            (this_high === other_high && this.buffer[0] < other.buffer[0]);\n    }\n    /** @nocollapse */\n    static from(val, out_buffer = new Uint32Array(2)) {\n        return Int64.fromString(typeof (val) === 'string' ? val : val.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromNumber(num, out_buffer = new Uint32Array(2)) {\n        // Always parse numbers as strings - pulling out high and low bits\n        // directly seems to lose precision sometimes\n        // For example:\n        //     > -4613034156400212000 >>> 0\n        //     721782784\n        // The correct lower 32-bits are 721782752\n        return Int64.fromString(num.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromString(str, out_buffer = new Uint32Array(2)) {\n        // TODO: Assert that out_buffer is 0 and length = 2\n        const negate = str.startsWith('-');\n        const length = str.length;\n        let out = new Int64(out_buffer);\n        for (let posn = negate ? 1 : 0; posn < length;) {\n            const group = kInt32DecimalDigits < length - posn ?\n                kInt32DecimalDigits : length - posn;\n            const chunk = new Int64(new Uint32Array([parseInt(str.substr(posn, group), 10), 0]));\n            const multiple = new Int64(new Uint32Array([kPowersOfTen[group], 0]));\n            out.times(multiple);\n            out.plus(chunk);\n            posn += group;\n        }\n        return negate ? out.negate() : out;\n    }\n    /** @nocollapse */\n    static convertArray(values) {\n        const data = new Uint32Array(values.length * 2);\n        for (let i = -1, n = values.length; ++i < n;) {\n            Int64.from(values[i], new Uint32Array(data.buffer, data.byteOffset + 2 * i * 4, 2));\n        }\n        return data;\n    }\n    /** @nocollapse */\n    static multiply(left, right) {\n        let rtrn = new Int64(new Uint32Array(left.buffer));\n        return rtrn.times(right);\n    }\n    /** @nocollapse */\n    static add(left, right) {\n        let rtrn = new Int64(new Uint32Array(left.buffer));\n        return rtrn.plus(right);\n    }\n}\nexports.Int64 = Int64;\n/** @ignore */\nclass Int128 {\n    constructor(buffer) {\n        this.buffer = buffer;\n        // buffer[3] MSB (high)\n        // buffer[2]\n        // buffer[1]\n        // buffer[0] LSB (low)\n    }\n    high() {\n        return new Int64(new Uint32Array(this.buffer.buffer, this.buffer.byteOffset + 8, 2));\n    }\n    low() {\n        return new Int64(new Uint32Array(this.buffer.buffer, this.buffer.byteOffset, 2));\n    }\n    negate() {\n        this.buffer[0] = ~this.buffer[0] + 1;\n        this.buffer[1] = ~this.buffer[1];\n        this.buffer[2] = ~this.buffer[2];\n        this.buffer[3] = ~this.buffer[3];\n        if (this.buffer[0] == 0) {\n            ++this.buffer[1];\n        }\n        if (this.buffer[1] == 0) {\n            ++this.buffer[2];\n        }\n        if (this.buffer[2] == 0) {\n            ++this.buffer[3];\n        }\n        return this;\n    }\n    times(other) {\n        // Break the left and right numbers into 32 bit chunks\n        // so that we can multiply them without overflow.\n        const L0 = new Uint64(new Uint32Array([this.buffer[3], 0]));\n        const L1 = new Uint64(new Uint32Array([this.buffer[2], 0]));\n        const L2 = new Uint64(new Uint32Array([this.buffer[1], 0]));\n        const L3 = new Uint64(new Uint32Array([this.buffer[0], 0]));\n        const R0 = new Uint64(new Uint32Array([other.buffer[3], 0]));\n        const R1 = new Uint64(new Uint32Array([other.buffer[2], 0]));\n        const R2 = new Uint64(new Uint32Array([other.buffer[1], 0]));\n        const R3 = new Uint64(new Uint32Array([other.buffer[0], 0]));\n        let product = Uint64.multiply(L3, R3);\n        this.buffer[0] = product.low();\n        let sum = new Uint64(new Uint32Array([product.high(), 0]));\n        product = Uint64.multiply(L2, R3);\n        sum.plus(product);\n        product = Uint64.multiply(L3, R2);\n        sum.plus(product);\n        this.buffer[1] = sum.low();\n        this.buffer[3] = (sum.lessThan(product) ? 1 : 0);\n        this.buffer[2] = sum.high();\n        let high = new Uint64(new Uint32Array(this.buffer.buffer, this.buffer.byteOffset + 8, 2));\n        high.plus(Uint64.multiply(L1, R3))\n            .plus(Uint64.multiply(L2, R2))\n            .plus(Uint64.multiply(L3, R1));\n        this.buffer[3] += Uint64.multiply(L0, R3)\n            .plus(Uint64.multiply(L1, R2))\n            .plus(Uint64.multiply(L2, R1))\n            .plus(Uint64.multiply(L3, R0)).low();\n        return this;\n    }\n    plus(other) {\n        let sums = new Uint32Array(4);\n        sums[3] = (this.buffer[3] + other.buffer[3]) >>> 0;\n        sums[2] = (this.buffer[2] + other.buffer[2]) >>> 0;\n        sums[1] = (this.buffer[1] + other.buffer[1]) >>> 0;\n        sums[0] = (this.buffer[0] + other.buffer[0]) >>> 0;\n        if (sums[0] < (this.buffer[0] >>> 0)) {\n            ++sums[1];\n        }\n        if (sums[1] < (this.buffer[1] >>> 0)) {\n            ++sums[2];\n        }\n        if (sums[2] < (this.buffer[2] >>> 0)) {\n            ++sums[3];\n        }\n        this.buffer[3] = sums[3];\n        this.buffer[2] = sums[2];\n        this.buffer[1] = sums[1];\n        this.buffer[0] = sums[0];\n        return this;\n    }\n    hex() {\n        return `${intAsHex(this.buffer[3])} ${intAsHex(this.buffer[2])} ${intAsHex(this.buffer[1])} ${intAsHex(this.buffer[0])}`;\n    }\n    /** @nocollapse */\n    static multiply(left, right) {\n        let rtrn = new Int128(new Uint32Array(left.buffer));\n        return rtrn.times(right);\n    }\n    /** @nocollapse */\n    static add(left, right) {\n        let rtrn = new Int128(new Uint32Array(left.buffer));\n        return rtrn.plus(right);\n    }\n    /** @nocollapse */\n    static from(val, out_buffer = new Uint32Array(4)) {\n        return Int128.fromString(typeof (val) === 'string' ? val : val.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromNumber(num, out_buffer = new Uint32Array(4)) {\n        // Always parse numbers as strings - pulling out high and low bits\n        // directly seems to lose precision sometimes\n        // For example:\n        //     > -4613034156400212000 >>> 0\n        //     721782784\n        // The correct lower 32-bits are 721782752\n        return Int128.fromString(num.toString(), out_buffer);\n    }\n    /** @nocollapse */\n    static fromString(str, out_buffer = new Uint32Array(4)) {\n        // TODO: Assert that out_buffer is 0 and length = 4\n        const negate = str.startsWith('-');\n        const length = str.length;\n        let out = new Int128(out_buffer);\n        for (let posn = negate ? 1 : 0; posn < length;) {\n            const group = kInt32DecimalDigits < length - posn ?\n                kInt32DecimalDigits : length - posn;\n            const chunk = new Int128(new Uint32Array([parseInt(str.substr(posn, group), 10), 0, 0, 0]));\n            const multiple = new Int128(new Uint32Array([kPowersOfTen[group], 0, 0, 0]));\n            out.times(multiple);\n            out.plus(chunk);\n            posn += group;\n        }\n        return negate ? out.negate() : out;\n    }\n    /** @nocollapse */\n    static convertArray(values) {\n        // TODO: Distinguish between string and number at compile-time\n        const data = new Uint32Array(values.length * 4);\n        for (let i = -1, n = values.length; ++i < n;) {\n            Int128.from(values[i], new Uint32Array(data.buffer, data.byteOffset + 4 * 4 * i, 4));\n        }\n        return data;\n    }\n}\nexports.Int128 = Int128;\n\n//# sourceMappingURL=int.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst f64 = new Float64Array(1);\nconst u32 = new Uint32Array(f64.buffer);\n/**\n * Convert uint16 (logically a float16) to a JS float64. Inspired by numpy's `npy_half_to_double`:\n * https://github.com/numpy/numpy/blob/5a5987291dc95376bb098be8d8e5391e89e77a2c/numpy/core/src/npymath/halffloat.c#L29\n * @param h {number} the uint16 to convert\n * @private\n * @ignore\n */\nfunction uint16ToFloat64(h) {\n    let expo = (h & 0x7C00) >> 10;\n    let sigf = (h & 0x03FF) / 1024;\n    let sign = (-1) ** ((h & 0x8000) >> 15);\n    switch (expo) {\n        case 0x1F: return sign * (sigf ? NaN : 1 / 0);\n        case 0x00: return sign * (sigf ? 6.103515625e-5 * sigf : 0);\n    }\n    return sign * (2 ** (expo - 15)) * (1 + sigf);\n}\nexports.uint16ToFloat64 = uint16ToFloat64;\n/**\n * Convert a float64 to uint16 (assuming the float64 is logically a float16). Inspired by numpy's `npy_double_to_half`:\n * https://github.com/numpy/numpy/blob/5a5987291dc95376bb098be8d8e5391e89e77a2c/numpy/core/src/npymath/halffloat.c#L43\n * @param d {number} The float64 to convert\n * @private\n * @ignore\n */\nfunction float64ToUint16(d) {\n    if (d !== d) {\n        return 0x7E00;\n    } // NaN\n    f64[0] = d;\n    // Magic numbers:\n    // 0x80000000 = 10000000 00000000 00000000 00000000 -- masks the 32nd bit\n    // 0x7ff00000 = 01111111 11110000 00000000 00000000 -- masks the 21st-31st bits\n    // 0x000fffff = 00000000 00001111 11111111 11111111 -- masks the 1st-20th bit\n    let sign = (u32[1] & 0x80000000) >> 16 & 0xFFFF;\n    let expo = (u32[1] & 0x7ff00000), sigf = 0x0000;\n    if (expo >= 0x40f00000) {\n        //\n        // If exponent overflowed, the float16 is either NaN or Infinity.\n        // Rules to propagate the sign bit: mantissa > 0 ? NaN : +/-Infinity\n        //\n        // Magic numbers:\n        // 0x40F00000 = 01000000 11110000 00000000 00000000 -- 6-bit exponent overflow\n        // 0x7C000000 = 01111100 00000000 00000000 00000000 -- masks the 27th-31st bits\n        //\n        // returns:\n        // qNaN, aka 32256 decimal, 0x7E00 hex, or 01111110 00000000 binary\n        // sNaN, aka 32000 decimal, 0x7D00 hex, or 01111101 00000000 binary\n        // +inf, aka 31744 decimal, 0x7C00 hex, or 01111100 00000000 binary\n        // -inf, aka 64512 decimal, 0xFC00 hex, or 11111100 00000000 binary\n        //\n        // If mantissa is greater than 23 bits, set to +Infinity like numpy\n        if (u32[0] > 0) {\n            expo = 0x7C00;\n        }\n        else {\n            expo = (expo & 0x7C000000) >> 16;\n            sigf = (u32[1] & 0x000fffff) >> 10;\n        }\n    }\n    else if (expo <= 0x3f000000) {\n        //\n        // If exponent underflowed, the float is either signed zero or subnormal.\n        //\n        // Magic numbers:\n        // 0x3F000000 = 00111111 00000000 00000000 00000000 -- 6-bit exponent underflow\n        //\n        sigf = 0x100000 + (u32[1] & 0x000fffff);\n        sigf = 0x100000 + (sigf << ((expo >> 20) - 998)) >> 21;\n        expo = 0;\n    }\n    else {\n        //\n        // No overflow or underflow, rebase the exponent and round the mantissa\n        // Magic numbers:\n        // 0x200 = 00000010 00000000 -- masks off the 10th bit\n        //\n        // Ensure the first mantissa bit (the 10th one) is 1 and round\n        expo = (expo - 0x3f000000) >> 10;\n        sigf = ((u32[1] & 0x000fffff) + 0x200) >> 10;\n    }\n    return sign | expo | sigf & 0xFFFF;\n}\nexports.float64ToUint16 = float64ToUint16;\n\n//# sourceMappingURL=math.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/** @ignore */ const undf = void (0);\n/** @ignore */\nfunction valueToString(x) {\n    if (x === null) {\n        return 'null';\n    }\n    if (x === undf) {\n        return 'undefined';\n    }\n    switch (typeof x) {\n        case 'number': return `${x}`;\n        case 'bigint': return `${x}`;\n        case 'string': return `\"${x}\"`;\n    }\n    // If [Symbol.toPrimitive] is implemented (like in BN)\n    // use it instead of JSON.stringify(). This ensures we\n    // print BigInts, Decimals, and Binary in their native\n    // representation\n    if (typeof x[Symbol.toPrimitive] === 'function') {\n        return x[Symbol.toPrimitive]('string');\n    }\n    return ArrayBuffer.isView(x) ? `[${x}]` : JSON.stringify(x);\n}\nexports.valueToString = valueToString;\n\n//# sourceMappingURL=pretty.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst schema_1 = require(\"../schema\");\nconst chunked_1 = require(\"../vector/chunked\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst noopBuf = new Uint8Array(0);\nconst nullBufs = (bitmapLength) => [\n    noopBuf, noopBuf, new Uint8Array(bitmapLength), noopBuf\n];\n/** @ignore */\nfunction ensureSameLengthData(schema, chunks, batchLength = chunks.reduce((l, c) => Math.max(l, c.length), 0)) {\n    let data;\n    let field;\n    let i = -1, n = chunks.length;\n    const fields = [...schema.fields];\n    const batchData = [];\n    const bitmapLength = ((batchLength + 63) & ~63) >> 3;\n    while (++i < n) {\n        if ((data = chunks[i]) && data.length === batchLength) {\n            batchData[i] = data;\n        }\n        else {\n            (field = fields[i]).nullable || (fields[i] = fields[i].clone({ nullable: true }));\n            batchData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength)\n                : data_1.Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength));\n        }\n    }\n    return [new schema_1.Schema(fields), batchLength, batchData];\n}\nexports.ensureSameLengthData = ensureSameLengthData;\n/** @ignore */\nfunction distributeColumnsIntoRecordBatches(columns) {\n    return distributeVectorsIntoRecordBatches(new schema_1.Schema(columns.map(({ field }) => field)), columns);\n}\nexports.distributeColumnsIntoRecordBatches = distributeColumnsIntoRecordBatches;\n/** @ignore */\nfunction distributeVectorsIntoRecordBatches(schema, vecs) {\n    return uniformlyDistributeChunksAcrossRecordBatches(schema, vecs.map((v) => v instanceof chunked_1.Chunked ? v.chunks.map((c) => c.data) : [v.data]));\n}\nexports.distributeVectorsIntoRecordBatches = distributeVectorsIntoRecordBatches;\n/** @ignore */\nfunction uniformlyDistributeChunksAcrossRecordBatches(schema, columns) {\n    const fields = [...schema.fields];\n    const batchArgs = [];\n    const memo = { numBatches: columns.reduce((n, c) => Math.max(n, c.length), 0) };\n    let numBatches = 0, batchLength = 0;\n    let i = -1, numColumns = columns.length;\n    let child, childData = [];\n    while (memo.numBatches-- > 0) {\n        for (batchLength = Number.POSITIVE_INFINITY, i = -1; ++i < numColumns;) {\n            childData[i] = child = columns[i].shift();\n            batchLength = Math.min(batchLength, child ? child.length : batchLength);\n        }\n        if (isFinite(batchLength)) {\n            childData = distributeChildData(fields, batchLength, childData, columns, memo);\n            if (batchLength > 0) {\n                batchArgs[numBatches++] = [batchLength, childData.slice()];\n            }\n        }\n    }\n    return [\n        schema = new schema_1.Schema(fields, schema.metadata),\n        batchArgs.map((xs) => new recordbatch_1.RecordBatch(schema, ...xs))\n    ];\n}\n/** @ignore */\nfunction distributeChildData(fields, batchLength, childData, columns, memo) {\n    let data;\n    let field;\n    let length = 0, i = -1, n = columns.length;\n    const bitmapLength = ((batchLength + 63) & ~63) >> 3;\n    while (++i < n) {\n        if ((data = childData[i]) && ((length = data.length) >= batchLength)) {\n            if (length === batchLength) {\n                childData[i] = data;\n            }\n            else {\n                childData[i] = data.slice(0, batchLength);\n                data = data.slice(batchLength, length - batchLength);\n                memo.numBatches = Math.max(memo.numBatches, columns[i].unshift(data));\n            }\n        }\n        else {\n            (field = fields[i]).nullable || (fields[i] = field.clone({ nullable: true }));\n            childData[i] = data ? data._changeLengthAndBackfillNullBitmap(batchLength)\n                : data_1.Data.new(field.type, 0, batchLength, batchLength, nullBufs(bitmapLength));\n        }\n    }\n    return childData;\n}\n\n//# sourceMappingURL=recordbatch.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst buffer_1 = require(\"./buffer\");\nconst text_encoding_utf_8_1 = require(\"text-encoding-utf-8\");\n/** @ignore @suppress {missingRequire} */\nconst _Buffer = typeof Buffer === 'function' ? Buffer : null;\n/** @ignore */\nconst useNativeEncoders = typeof TextDecoder === 'function' && typeof TextEncoder === 'function';\n/** @ignore */\nexports.decodeUtf8 = ((TextDecoder) => {\n    if (useNativeEncoders || !_Buffer) {\n        const decoder = new TextDecoder('utf-8');\n        return (buffer) => decoder.decode(buffer);\n    }\n    return (input) => {\n        const { buffer, byteOffset, length } = buffer_1.toUint8Array(input);\n        return _Buffer.from(buffer, byteOffset, length).toString();\n    };\n})(typeof TextDecoder !== 'undefined' ? TextDecoder : text_encoding_utf_8_1.TextDecoder);\n/** @ignore */\nexports.encodeUtf8 = ((TextEncoder) => {\n    if (useNativeEncoders || !_Buffer) {\n        const encoder = new TextEncoder();\n        return (value) => encoder.encode(value);\n    }\n    return (input = '') => buffer_1.toUint8Array(_Buffer.from(input, 'utf8'));\n})(typeof TextEncoder !== 'undefined' ? TextEncoder : text_encoding_utf_8_1.TextEncoder);\n\n//# sourceMappingURL=utf8.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\nconst row_1 = require(\"../vector/row\");\nconst buffer_1 = require(\"../util/buffer\");\nconst compat_1 = require(\"./compat\");\n/** @ignore */\nfunction clampIndex(source, index, then) {\n    const length = source.length;\n    const adjust = index > -1 ? index : (length + (index % length));\n    return then ? then(source, adjust) : adjust;\n}\nexports.clampIndex = clampIndex;\n/** @ignore */\nlet tmp;\n/** @ignore */\nfunction clampRange(source, begin, end, then) {\n    // Adjust args similar to Array.prototype.slice. Normalize begin/end to\n    // clamp between 0 and length, and wrap around on negative indices, e.g.\n    // slice(-1, 5) or slice(5, -1)\n    let { length: len = 0 } = source;\n    let lhs = typeof begin !== 'number' ? 0 : begin;\n    let rhs = typeof end !== 'number' ? len : end;\n    // wrap around on negative start/end positions\n    (lhs < 0) && (lhs = ((lhs % len) + len) % len);\n    (rhs < 0) && (rhs = ((rhs % len) + len) % len);\n    // ensure lhs <= rhs\n    (rhs < lhs) && (tmp = lhs, lhs = rhs, rhs = tmp);\n    // ensure rhs <= length\n    (rhs > len) && (rhs = len);\n    return then ? then(source, lhs, rhs) : [lhs, rhs];\n}\nexports.clampRange = clampRange;\nconst big0 = compat_1.BigIntAvailable ? compat_1.BigInt(0) : 0;\nconst isNaNFast = (value) => value !== value;\n/** @ignore */\nfunction createElementComparator(search) {\n    let typeofSearch = typeof search;\n    // Compare primitives\n    if (typeofSearch !== 'object' || search === null) {\n        // Compare NaN\n        if (isNaNFast(search)) {\n            return isNaNFast;\n        }\n        return typeofSearch !== 'bigint'\n            ? (value) => value === search\n            : (value) => (big0 + value) === search;\n    }\n    // Compare Dates\n    if (search instanceof Date) {\n        const valueOfSearch = search.valueOf();\n        return (value) => value instanceof Date ? (value.valueOf() === valueOfSearch) : false;\n    }\n    // Compare TypedArrays\n    if (ArrayBuffer.isView(search)) {\n        return (value) => value ? buffer_1.compareArrayLike(search, value) : false;\n    }\n    // Compare Maps and Rows\n    if (search instanceof Map) {\n        return creatMapComparator(search);\n    }\n    // Compare Array-likes\n    if (Array.isArray(search)) {\n        return createArrayLikeComparator(search);\n    }\n    // Compare Vectors\n    if (search instanceof vector_1.Vector) {\n        return createVectorComparator(search);\n    }\n    // Compare non-empty Objects\n    return createObjectComparator(search);\n}\nexports.createElementComparator = createElementComparator;\n/** @ignore */\nfunction createArrayLikeComparator(lhs) {\n    const comparitors = [];\n    for (let i = -1, n = lhs.length; ++i < n;) {\n        comparitors[i] = createElementComparator(lhs[i]);\n    }\n    return createSubElementsComparator(comparitors);\n}\n/** @ignore */\nfunction creatMapComparator(lhs) {\n    let i = -1;\n    const comparitors = [];\n    lhs.forEach((v) => comparitors[++i] = createElementComparator(v));\n    return createSubElementsComparator(comparitors);\n}\n/** @ignore */\nfunction createVectorComparator(lhs) {\n    const comparitors = [];\n    for (let i = -1, n = lhs.length; ++i < n;) {\n        comparitors[i] = createElementComparator(lhs.get(i));\n    }\n    return createSubElementsComparator(comparitors);\n}\n/** @ignore */\nfunction createObjectComparator(lhs) {\n    const keys = Object.keys(lhs);\n    // Only compare non-empty Objects\n    if (keys.length === 0) {\n        return () => false;\n    }\n    const comparitors = [];\n    for (let i = -1, n = keys.length; ++i < n;) {\n        comparitors[i] = createElementComparator(lhs[keys[i]]);\n    }\n    return createSubElementsComparator(comparitors, keys);\n}\nfunction createSubElementsComparator(comparitors, keys) {\n    return (rhs) => {\n        if (!rhs || typeof rhs !== 'object') {\n            return false;\n        }\n        switch (rhs.constructor) {\n            case Array: return compareArray(comparitors, rhs);\n            case Map:\n            case row_1.MapRow:\n            case row_1.StructRow:\n                return compareObject(comparitors, rhs, rhs.keys());\n            case Object:\n            case undefined: // support `Object.create(null)` objects\n                return compareObject(comparitors, rhs, keys || Object.keys(rhs));\n        }\n        return rhs instanceof vector_1.Vector ? compareVector(comparitors, rhs) : false;\n    };\n}\nfunction compareArray(comparitors, arr) {\n    const n = comparitors.length;\n    if (arr.length !== n) {\n        return false;\n    }\n    for (let i = -1; ++i < n;) {\n        if (!(comparitors[i](arr[i]))) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction compareVector(comparitors, vec) {\n    const n = comparitors.length;\n    if (vec.length !== n) {\n        return false;\n    }\n    for (let i = -1; ++i < n;) {\n        if (!(comparitors[i](vec.get(i)))) {\n            return false;\n        }\n    }\n    return true;\n}\nfunction compareObject(comparitors, obj, keys) {\n    const lKeyItr = keys[Symbol.iterator]();\n    const rKeyItr = obj instanceof Map ? obj.keys() : Object.keys(obj)[Symbol.iterator]();\n    const rValItr = obj instanceof Map ? obj.values() : Object.values(obj)[Symbol.iterator]();\n    let i = 0;\n    let n = comparitors.length;\n    let rVal = rValItr.next();\n    let lKey = lKeyItr.next();\n    let rKey = rKeyItr.next();\n    for (; i < n && !lKey.done && !rKey.done && !rVal.done; ++i, lKey = lKeyItr.next(), rKey = rKeyItr.next(), rVal = rValItr.next()) {\n        if (lKey.value !== rKey.value || !comparitors[i](rVal.value)) {\n            break;\n        }\n    }\n    if (i === n && lKey.done && rKey.done && rVal.done) {\n        return true;\n    }\n    lKeyItr.return && lKeyItr.return();\n    rKeyItr.return && rKeyItr.return();\n    rValItr.return && rValItr.return();\n    return false;\n}\n\n//# sourceMappingURL=vector.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass AbstractVector {\n}\nexports.AbstractVector = AbstractVector;\nexports.Vector = AbstractVector;\n\n//# sourceMappingURL=vector.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst enum_1 = require(\"../enum\");\nconst chunked_1 = require(\"./chunked\");\nconst vector_1 = require(\"../util/vector\");\nconst vector_2 = require(\"../vector\");\n/** @ignore */\nclass BaseVector extends vector_2.AbstractVector {\n    constructor(data, children) {\n        super();\n        this._children = children;\n        this.numChildren = data.childData.length;\n        this._bindDataAccessors(this.data = data);\n    }\n    get type() { return this.data.type; }\n    get typeId() { return this.data.typeId; }\n    get length() { return this.data.length; }\n    get offset() { return this.data.offset; }\n    get stride() { return this.data.stride; }\n    get nullCount() { return this.data.nullCount; }\n    get byteLength() { return this.data.byteLength; }\n    get VectorName() { return `${enum_1.Type[this.typeId]}Vector`; }\n    get ArrayType() { return this.type.ArrayType; }\n    get values() { return this.data.values; }\n    get typeIds() { return this.data.typeIds; }\n    get nullBitmap() { return this.data.nullBitmap; }\n    get valueOffsets() { return this.data.valueOffsets; }\n    get [Symbol.toStringTag]() { return `${this.VectorName}<${this.type[Symbol.toStringTag]}>`; }\n    clone(data, children = this._children) {\n        return vector_2.Vector.new(data, children);\n    }\n    concat(...others) {\n        return chunked_1.Chunked.concat(this, ...others);\n    }\n    slice(begin, end) {\n        // Adjust args similar to Array.prototype.slice. Normalize begin/end to\n        // clamp between 0 and length, and wrap around on negative indices, e.g.\n        // slice(-1, 5) or slice(5, -1)\n        return vector_1.clampRange(this, begin, end, this._sliceInternal);\n    }\n    isValid(index) {\n        if (this.nullCount > 0) {\n            const idx = this.offset + index;\n            const val = this.nullBitmap[idx >> 3];\n            const mask = (val & (1 << (idx % 8)));\n            return mask !== 0;\n        }\n        return true;\n    }\n    getChildAt(index) {\n        return index < 0 || index >= this.numChildren ? null : ((this._children || (this._children = []))[index] ||\n            (this._children[index] = vector_2.Vector.new(this.data.childData[index])));\n    }\n    toJSON() { return [...this]; }\n    _sliceInternal(self, begin, end) {\n        return self.clone(self.data.slice(begin, end - begin), null);\n    }\n    // @ts-ignore\n    _bindDataAccessors(data) {\n        // Implementation in src/vectors/index.ts due to circular dependency/packaging shenanigans\n    }\n}\nexports.BaseVector = BaseVector;\nBaseVector.prototype[Symbol.isConcatSpreadable] = true;\n\n//# sourceMappingURL=base.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass BinaryVector extends base_1.BaseVector {\n    asUtf8() {\n        return vector_1.Vector.new(this.data.clone(new type_1.Utf8()));\n    }\n}\nexports.BinaryVector = BinaryVector;\n\n//# sourceMappingURL=binary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst type_1 = require(\"../type\");\nconst base_1 = require(\"./base\");\nconst index_1 = require(\"./index\");\n/** @ignore */\nclass BoolVector extends base_1.BaseVector {\n    /** @nocollapse */\n    static from(input) {\n        return index_1.vectorFromValuesWithType(() => new type_1.Bool(), input);\n    }\n}\nexports.BoolVector = BoolVector;\n\n//# sourceMappingURL=bool.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../util/vector\");\nconst type_1 = require(\"../type\");\nconst args_1 = require(\"../util/args\");\nconst vector_2 = require(\"../vector\");\n/** @ignore */\nclass Chunked extends vector_2.AbstractVector {\n    constructor(type, chunks = [], offsets = calculateOffsets(chunks)) {\n        super();\n        this._nullCount = -1;\n        this._type = type;\n        this._chunks = chunks;\n        this._chunkOffsets = offsets;\n        this._length = offsets[offsets.length - 1];\n        this._numChildren = (this._type.children || []).length;\n    }\n    /** @nocollapse */\n    static flatten(...vectors) {\n        return args_1.selectChunkArgs(vector_2.Vector, vectors);\n    }\n    /** @nocollapse */\n    static concat(...vectors) {\n        const chunks = Chunked.flatten(...vectors);\n        return new Chunked(chunks[0].type, chunks);\n    }\n    get type() { return this._type; }\n    get length() { return this._length; }\n    get chunks() { return this._chunks; }\n    get typeId() { return this._type.typeId; }\n    get VectorName() { return `Chunked<${this._type}>`; }\n    get data() {\n        return this._chunks[0] ? this._chunks[0].data : null;\n    }\n    get ArrayType() { return this._type.ArrayType; }\n    get numChildren() { return this._numChildren; }\n    get stride() { return this._chunks[0] ? this._chunks[0].stride : 1; }\n    get byteLength() {\n        return this._chunks.reduce((byteLength, chunk) => byteLength + chunk.byteLength, 0);\n    }\n    get nullCount() {\n        let nullCount = this._nullCount;\n        if (nullCount < 0) {\n            this._nullCount = nullCount = this._chunks.reduce((x, { nullCount }) => x + nullCount, 0);\n        }\n        return nullCount;\n    }\n    get indices() {\n        if (type_1.DataType.isDictionary(this._type)) {\n            if (!this._indices) {\n                const chunks = this._chunks;\n                this._indices = (chunks.length === 1\n                    ? chunks[0].indices\n                    : Chunked.concat(...chunks.map((x) => x.indices)));\n            }\n            return this._indices;\n        }\n        return null;\n    }\n    get dictionary() {\n        if (type_1.DataType.isDictionary(this._type)) {\n            return this._chunks[this._chunks.length - 1].data.dictionary;\n        }\n        return null;\n    }\n    *[Symbol.iterator]() {\n        for (const chunk of this._chunks) {\n            yield* chunk;\n        }\n    }\n    clone(chunks = this._chunks) {\n        return new Chunked(this._type, chunks);\n    }\n    concat(...others) {\n        return this.clone(Chunked.flatten(this, ...others));\n    }\n    slice(begin, end) {\n        return vector_1.clampRange(this, begin, end, this._sliceInternal);\n    }\n    getChildAt(index) {\n        if (index < 0 || index >= this._numChildren) {\n            return null;\n        }\n        let columns = this._children || (this._children = []);\n        let child, field, chunks;\n        if (child = columns[index]) {\n            return child;\n        }\n        if (field = (this._type.children || [])[index]) {\n            chunks = this._chunks\n                .map((vector) => vector.getChildAt(index))\n                .filter((vec) => vec != null);\n            if (chunks.length > 0) {\n                return (columns[index] = new Chunked(field.type, chunks));\n            }\n        }\n        return null;\n    }\n    search(index, then) {\n        let idx = index;\n        // binary search to find the child vector and value indices\n        let offsets = this._chunkOffsets, rhs = offsets.length - 1;\n        // return early if out of bounds, or if there's just one child\n        if (idx < 0) {\n            return null;\n        }\n        if (idx >= offsets[rhs]) {\n            return null;\n        }\n        if (rhs <= 1) {\n            return then ? then(this, 0, idx) : [0, idx];\n        }\n        let lhs = 0, pos = 0, mid = 0;\n        do {\n            if (lhs + 1 === rhs) {\n                return then ? then(this, lhs, idx - pos) : [lhs, idx - pos];\n            }\n            mid = lhs + ((rhs - lhs) / 2) | 0;\n            idx >= offsets[mid] ? (lhs = mid) : (rhs = mid);\n        } while (idx < offsets[rhs] && idx >= (pos = offsets[lhs]));\n        return null;\n    }\n    isValid(index) {\n        return !!this.search(index, this.isValidInternal);\n    }\n    get(index) {\n        return this.search(index, this.getInternal);\n    }\n    set(index, value) {\n        this.search(index, ({ chunks }, i, j) => chunks[i].set(j, value));\n    }\n    indexOf(element, offset) {\n        if (offset && typeof offset === 'number') {\n            return this.search(offset, (self, i, j) => this.indexOfInternal(self, i, j, element));\n        }\n        return this.indexOfInternal(this, 0, Math.max(0, offset || 0), element);\n    }\n    toArray() {\n        const { chunks } = this;\n        const n = chunks.length;\n        let ArrayType = this._type.ArrayType;\n        if (n <= 0) {\n            return new ArrayType(0);\n        }\n        if (n <= 1) {\n            return chunks[0].toArray();\n        }\n        let len = 0, src = new Array(n);\n        for (let i = -1; ++i < n;) {\n            len += (src[i] = chunks[i].toArray()).length;\n        }\n        if (ArrayType !== src[0].constructor) {\n            ArrayType = src[0].constructor;\n        }\n        let dst = new ArrayType(len);\n        let set = ArrayType === Array ? arraySet : typedSet;\n        for (let i = -1, idx = 0; ++i < n;) {\n            idx = set(src[i], dst, idx);\n        }\n        return dst;\n    }\n    getInternal({ _chunks }, i, j) { return _chunks[i].get(j); }\n    isValidInternal({ _chunks }, i, j) { return _chunks[i].isValid(j); }\n    indexOfInternal({ _chunks }, chunkIndex, fromIndex, element) {\n        let i = chunkIndex - 1, n = _chunks.length;\n        let start = fromIndex, offset = 0, found = -1;\n        while (++i < n) {\n            if (~(found = _chunks[i].indexOf(element, start))) {\n                return offset + found;\n            }\n            start = 0;\n            offset += _chunks[i].length;\n        }\n        return -1;\n    }\n    _sliceInternal(self, begin, end) {\n        const slices = [];\n        const { chunks, _chunkOffsets: chunkOffsets } = self;\n        for (let i = -1, n = chunks.length; ++i < n;) {\n            const chunk = chunks[i];\n            const chunkLength = chunk.length;\n            const chunkOffset = chunkOffsets[i];\n            // If the child is to the right of the slice boundary, we can stop\n            if (chunkOffset >= end) {\n                break;\n            }\n            // If the child is to the left of of the slice boundary, exclude\n            if (begin >= chunkOffset + chunkLength) {\n                continue;\n            }\n            // If the child is between both left and right boundaries, include w/o slicing\n            if (chunkOffset >= begin && (chunkOffset + chunkLength) <= end) {\n                slices.push(chunk);\n                continue;\n            }\n            // If the child overlaps one of the slice boundaries, include that slice\n            const from = Math.max(0, begin - chunkOffset);\n            const to = Math.min(end - chunkOffset, chunkLength);\n            slices.push(chunk.slice(from, to));\n        }\n        return self.clone(slices);\n    }\n}\nexports.Chunked = Chunked;\n/** @ignore */\nfunction calculateOffsets(vectors) {\n    let offsets = new Uint32Array((vectors || []).length + 1);\n    let offset = offsets[0] = 0, length = offsets.length;\n    for (let index = 0; ++index < length;) {\n        offsets[index] = (offset += vectors[index - 1].length);\n    }\n    return offsets;\n}\n/** @ignore */\nconst typedSet = (src, dst, offset) => {\n    dst.set(src, offset);\n    return (offset + src.length);\n};\n/** @ignore */\nconst arraySet = (src, dst, offset) => {\n    let idx = offset;\n    for (let i = -1, n = src.length; ++i < n;) {\n        dst[idx++] = src[i];\n    }\n    return idx;\n};\n\n//# sourceMappingURL=chunked.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst enum_1 = require(\"../enum\");\nconst base_1 = require(\"./base\");\nconst index_1 = require(\"./index\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass DateVector extends base_1.BaseVector {\n    /** @nocollapse */\n    static from(...args) {\n        if (args.length === 2) {\n            return index_1.vectorFromValuesWithType(() => args[1] === enum_1.DateUnit.DAY ? new type_1.DateDay() : new type_1.DateMillisecond(), args[0]);\n        }\n        return index_1.vectorFromValuesWithType(() => new type_1.DateMillisecond(), args[0]);\n    }\n}\nexports.DateVector = DateVector;\n/** @ignore */\nclass DateDayVector extends DateVector {\n}\nexports.DateDayVector = DateDayVector;\n/** @ignore */\nclass DateMillisecondVector extends DateVector {\n}\nexports.DateMillisecondVector = DateMillisecondVector;\n\n//# sourceMappingURL=date.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass DecimalVector extends base_1.BaseVector {\n}\nexports.DecimalVector = DecimalVector;\n\n//# sourceMappingURL=decimal.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst index_1 = require(\"./index\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass DictionaryVector extends base_1.BaseVector {\n    constructor(data) {\n        super(data);\n        this.indices = vector_1.Vector.new(data.clone(this.type.indices));\n    }\n    /** @nocollapse */\n    static from(...args) {\n        if (args.length === 3) {\n            const [values, indices, keys] = args;\n            const type = new type_1.Dictionary(values.type, indices, null, null);\n            return vector_1.Vector.new(data_1.Data.Dictionary(type, 0, keys.length, 0, null, keys, values));\n        }\n        return index_1.vectorFromValuesWithType(() => args[0].type, args[0]);\n    }\n    get dictionary() { return this.data.dictionary; }\n    reverseLookup(value) { return this.dictionary.indexOf(value); }\n    getKey(idx) { return this.indices.get(idx); }\n    getValue(key) { return this.dictionary.get(key); }\n    setKey(idx, key) { return this.indices.set(idx, key); }\n    setValue(key, value) { return this.dictionary.set(key, value); }\n}\nexports.DictionaryVector = DictionaryVector;\nDictionaryVector.prototype.indices = null;\n\n//# sourceMappingURL=dictionary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass FixedSizeBinaryVector extends base_1.BaseVector {\n}\nexports.FixedSizeBinaryVector = FixedSizeBinaryVector;\n\n//# sourceMappingURL=fixedsizebinary.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass FixedSizeListVector extends base_1.BaseVector {\n}\nexports.FixedSizeListVector = FixedSizeListVector;\n\n//# sourceMappingURL=fixedsizelist.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst index_1 = require(\"./index\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass FloatVector extends base_1.BaseVector {\n    /** @nocollapse */\n    static from(input) {\n        let ArrowType = vectorTypeToDataType(this);\n        if ((input instanceof ArrayBuffer) || ArrayBuffer.isView(input)) {\n            let InputType = arrayTypeToDataType(input.constructor) || ArrowType;\n            // Special case, infer the Arrow DataType from the input if calling the base\n            // FloatVector.from with a TypedArray, e.g. `FloatVector.from(new Float32Array())`\n            if (ArrowType === null) {\n                ArrowType = InputType;\n            }\n            // If the DataType inferred from the Vector constructor matches the\n            // DataType inferred from the input arguments, return zero-copy view\n            if (ArrowType && ArrowType === InputType) {\n                let type = new ArrowType();\n                let length = input.byteLength / type.ArrayType.BYTES_PER_ELEMENT;\n                // If the ArrowType is Float16 but the input type isn't a Uint16Array,\n                // let the Float16Builder handle casting the input values to Uint16s.\n                if (!convertTo16Bit(ArrowType, input.constructor)) {\n                    return vector_1.Vector.new(data_1.Data.Float(type, 0, length, 0, null, input));\n                }\n            }\n        }\n        if (ArrowType) {\n            // If the DataType inferred from the Vector constructor is different than\n            // the DataType inferred from the input TypedArray, or if input isn't a\n            // TypedArray, use the Builders to construct the result Vector\n            return index_1.vectorFromValuesWithType(() => new ArrowType(), input);\n        }\n        if ((input instanceof DataView) || (input instanceof ArrayBuffer)) {\n            throw new TypeError(`Cannot infer float type from instance of ${input.constructor.name}`);\n        }\n        throw new TypeError('Unrecognized FloatVector input');\n    }\n}\nexports.FloatVector = FloatVector;\n/** @ignore */\nclass Float16Vector extends FloatVector {\n    // Since JS doesn't have half floats, `toArray()` returns a zero-copy slice\n    // of the underlying Uint16Array data. This behavior ensures we don't incur\n    // extra compute or copies if you're calling `toArray()` in order to create\n    // a buffer for something like WebGL. Buf if you're using JS and want typed\n    // arrays of 4-to-8-byte precision, these methods will enumerate the values\n    // and clamp to the desired byte lengths.\n    toFloat32Array() { return new Float32Array(this); }\n    toFloat64Array() { return new Float64Array(this); }\n}\nexports.Float16Vector = Float16Vector;\n/** @ignore */\nclass Float32Vector extends FloatVector {\n}\nexports.Float32Vector = Float32Vector;\n/** @ignore */\nclass Float64Vector extends FloatVector {\n}\nexports.Float64Vector = Float64Vector;\nconst convertTo16Bit = (typeCtor, dataCtor) => {\n    return (typeCtor === type_1.Float16) && (dataCtor !== Uint16Array);\n};\n/** @ignore */\nconst arrayTypeToDataType = (ctor) => {\n    switch (ctor) {\n        case Uint16Array: return type_1.Float16;\n        case Float32Array: return type_1.Float32;\n        case Float64Array: return type_1.Float64;\n        default: return null;\n    }\n};\n/** @ignore */\nconst vectorTypeToDataType = (ctor) => {\n    switch (ctor) {\n        case Float16Vector: return type_1.Float16;\n        case Float32Vector: return type_1.Float32;\n        case Float64Vector: return type_1.Float64;\n        default: return null;\n    }\n};\n\n//# sourceMappingURL=float.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar vector_1 = require(\"../vector\");\nexports.Vector = vector_1.Vector;\nvar base_1 = require(\"./base\");\nexports.BaseVector = base_1.BaseVector;\nvar binary_1 = require(\"./binary\");\nexports.BinaryVector = binary_1.BinaryVector;\nvar bool_1 = require(\"./bool\");\nexports.BoolVector = bool_1.BoolVector;\nvar chunked_1 = require(\"./chunked\");\nexports.Chunked = chunked_1.Chunked;\nvar date_1 = require(\"./date\");\nexports.DateVector = date_1.DateVector;\nexports.DateDayVector = date_1.DateDayVector;\nexports.DateMillisecondVector = date_1.DateMillisecondVector;\nvar decimal_1 = require(\"./decimal\");\nexports.DecimalVector = decimal_1.DecimalVector;\nvar dictionary_1 = require(\"./dictionary\");\nexports.DictionaryVector = dictionary_1.DictionaryVector;\nvar fixedsizebinary_1 = require(\"./fixedsizebinary\");\nexports.FixedSizeBinaryVector = fixedsizebinary_1.FixedSizeBinaryVector;\nvar fixedsizelist_1 = require(\"./fixedsizelist\");\nexports.FixedSizeListVector = fixedsizelist_1.FixedSizeListVector;\nvar float_1 = require(\"./float\");\nexports.FloatVector = float_1.FloatVector;\nexports.Float16Vector = float_1.Float16Vector;\nexports.Float32Vector = float_1.Float32Vector;\nexports.Float64Vector = float_1.Float64Vector;\nvar interval_1 = require(\"./interval\");\nexports.IntervalVector = interval_1.IntervalVector;\nexports.IntervalDayTimeVector = interval_1.IntervalDayTimeVector;\nexports.IntervalYearMonthVector = interval_1.IntervalYearMonthVector;\nvar int_1 = require(\"./int\");\nexports.IntVector = int_1.IntVector;\nexports.Int8Vector = int_1.Int8Vector;\nexports.Int16Vector = int_1.Int16Vector;\nexports.Int32Vector = int_1.Int32Vector;\nexports.Int64Vector = int_1.Int64Vector;\nexports.Uint8Vector = int_1.Uint8Vector;\nexports.Uint16Vector = int_1.Uint16Vector;\nexports.Uint32Vector = int_1.Uint32Vector;\nexports.Uint64Vector = int_1.Uint64Vector;\nvar list_1 = require(\"./list\");\nexports.ListVector = list_1.ListVector;\nvar map_1 = require(\"./map\");\nexports.MapVector = map_1.MapVector;\nvar null_1 = require(\"./null\");\nexports.NullVector = null_1.NullVector;\nvar struct_1 = require(\"./struct\");\nexports.StructVector = struct_1.StructVector;\nvar timestamp_1 = require(\"./timestamp\");\nexports.TimestampVector = timestamp_1.TimestampVector;\nexports.TimestampSecondVector = timestamp_1.TimestampSecondVector;\nexports.TimestampMillisecondVector = timestamp_1.TimestampMillisecondVector;\nexports.TimestampMicrosecondVector = timestamp_1.TimestampMicrosecondVector;\nexports.TimestampNanosecondVector = timestamp_1.TimestampNanosecondVector;\nvar time_1 = require(\"./time\");\nexports.TimeVector = time_1.TimeVector;\nexports.TimeSecondVector = time_1.TimeSecondVector;\nexports.TimeMillisecondVector = time_1.TimeMillisecondVector;\nexports.TimeMicrosecondVector = time_1.TimeMicrosecondVector;\nexports.TimeNanosecondVector = time_1.TimeNanosecondVector;\nvar union_1 = require(\"./union\");\nexports.UnionVector = union_1.UnionVector;\nexports.DenseUnionVector = union_1.DenseUnionVector;\nexports.SparseUnionVector = union_1.SparseUnionVector;\nvar utf8_1 = require(\"./utf8\");\nexports.Utf8Vector = utf8_1.Utf8Vector;\nvar row_1 = require(\"./row\");\nexports.MapRow = row_1.MapRow;\nexports.StructRow = row_1.StructRow;\nconst fn = require(\"../util/fn\");\nconst enum_1 = require(\"../enum\");\nconst vector_2 = require(\"../vector\");\nconst chunked_2 = require(\"./chunked\");\nconst base_2 = require(\"./base\");\nconst bit_1 = require(\"../util/bit\");\nconst compat_1 = require(\"../util/compat\");\nconst builder_1 = require(\"../builder\");\nconst get_1 = require(\"../visitor/get\");\nconst set_1 = require(\"../visitor/set\");\nconst indexof_1 = require(\"../visitor/indexof\");\nconst toarray_1 = require(\"../visitor/toarray\");\nconst iterator_1 = require(\"../visitor/iterator\");\nconst bytewidth_1 = require(\"../visitor/bytewidth\");\nconst vectorctor_1 = require(\"../visitor/vectorctor\");\n/** @nocollapse */\nvector_2.Vector.new = newVector;\n/** @nocollapse */\nvector_2.Vector.from = vectorFrom;\n/** @ignore */\nfunction newVector(data, ...args) {\n    return new (vectorctor_1.instance.getVisitFn(data)())(data, ...args);\n}\n/** @ignore */\nfunction vectorFromValuesWithType(newDataType, input) {\n    if (compat_1.isIterable(input)) {\n        return vector_2.Vector.from({ 'nullValues': [null, undefined], type: newDataType(), 'values': input });\n    }\n    else if (compat_1.isAsyncIterable(input)) {\n        return vector_2.Vector.from({ 'nullValues': [null, undefined], type: newDataType(), 'values': input });\n    }\n    const { 'values': values = [], 'type': type = newDataType(), 'nullValues': nullValues = [null, undefined], } = { ...input };\n    return compat_1.isIterable(values)\n        ? vector_2.Vector.from({ nullValues, ...input, type })\n        : vector_2.Vector.from({ nullValues, ...input, type });\n}\nexports.vectorFromValuesWithType = vectorFromValuesWithType;\nfunction vectorFrom(input) {\n    const { 'values': values = [], ...options } = { 'nullValues': [null, undefined], ...input };\n    if (compat_1.isIterable(values)) {\n        const chunks = [...builder_1.Builder.throughIterable(options)(values)];\n        return chunks.length === 1 ? chunks[0] : chunked_2.Chunked.concat(chunks);\n    }\n    return (async (chunks) => {\n        const transform = builder_1.Builder.throughAsyncIterable(options);\n        for await (const chunk of transform(values)) {\n            chunks.push(chunk);\n        }\n        return chunks.length === 1 ? chunks[0] : chunked_2.Chunked.concat(chunks);\n    })([]);\n}\n//\n// We provide the following method implementations for code navigability purposes only.\n// They're overridden at runtime below with the specific Visitor implementation for each type,\n// short-circuiting the usual Visitor traversal and reducing intermediate lookups and calls.\n// This comment is here to remind you to not set breakpoints in these function bodies, or to inform\n// you why the breakpoints you have already set are not being triggered. Have a great day!\n//\nbase_2.BaseVector.prototype.get = function baseVectorGet(index) {\n    return get_1.instance.visit(this, index);\n};\nbase_2.BaseVector.prototype.set = function baseVectorSet(index, value) {\n    return set_1.instance.visit(this, index, value);\n};\nbase_2.BaseVector.prototype.indexOf = function baseVectorIndexOf(value, fromIndex) {\n    return indexof_1.instance.visit(this, value, fromIndex);\n};\nbase_2.BaseVector.prototype.toArray = function baseVectorToArray() {\n    return toarray_1.instance.visit(this);\n};\nbase_2.BaseVector.prototype.getByteWidth = function baseVectorGetByteWidth() {\n    return bytewidth_1.instance.visit(this.type);\n};\nbase_2.BaseVector.prototype[Symbol.iterator] = function baseVectorSymbolIterator() {\n    return iterator_1.instance.visit(this);\n};\nbase_2.BaseVector.prototype._bindDataAccessors = bindBaseVectorDataAccessors;\n// Perf: bind and assign the operator Visitor methods to each of the Vector subclasses for each Type\nObject.keys(enum_1.Type)\n    .map((T) => enum_1.Type[T])\n    .filter((T) => typeof T === 'number')\n    .filter((typeId) => typeId !== enum_1.Type.NONE)\n    .forEach((typeId) => {\n    const VectorCtor = vectorctor_1.instance.visit(typeId);\n    VectorCtor.prototype['get'] = fn.partial1(get_1.instance.getVisitFn(typeId));\n    VectorCtor.prototype['set'] = fn.partial2(set_1.instance.getVisitFn(typeId));\n    VectorCtor.prototype['indexOf'] = fn.partial2(indexof_1.instance.getVisitFn(typeId));\n    VectorCtor.prototype['toArray'] = fn.partial0(toarray_1.instance.getVisitFn(typeId));\n    VectorCtor.prototype['getByteWidth'] = partialType0(bytewidth_1.instance.getVisitFn(typeId));\n    VectorCtor.prototype[Symbol.iterator] = fn.partial0(iterator_1.instance.getVisitFn(typeId));\n});\n/** @ignore */\nfunction partialType0(visit) {\n    return function () { return visit(this.type); };\n}\n/** @ignore */\nfunction wrapNullableGet(fn) {\n    return function (i) { return this.isValid(i) ? fn.call(this, i) : null; };\n}\n/** @ignore */\nfunction wrapNullableSet(fn) {\n    return function (i, a) {\n        if (bit_1.setBool(this.nullBitmap, this.offset + i, !(a === null || a === undefined))) {\n            fn.call(this, i, a);\n        }\n    };\n}\n/** @ignore */\nfunction bindBaseVectorDataAccessors() {\n    const nullBitmap = this.nullBitmap;\n    if (nullBitmap && nullBitmap.byteLength > 0) {\n        this.get = wrapNullableGet(this.get);\n        this.set = wrapNullableSet(this.set);\n    }\n}\n\n//# sourceMappingURL=index.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst index_1 = require(\"./index\");\nconst compat_1 = require(\"../util/compat\");\nconst buffer_1 = require(\"../util/buffer\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass IntVector extends base_1.BaseVector {\n    /** @nocollapse */\n    static from(...args) {\n        let [input, is64bit = false] = args;\n        let ArrowType = vectorTypeToDataType(this, is64bit);\n        if ((input instanceof ArrayBuffer) || ArrayBuffer.isView(input)) {\n            let InputType = arrayTypeToDataType(input.constructor, is64bit) || ArrowType;\n            // Special case, infer the Arrow DataType from the input if calling the base\n            // IntVector.from with a TypedArray, e.g. `IntVector.from(new Int32Array())`\n            if (ArrowType === null) {\n                ArrowType = InputType;\n            }\n            // If the DataType inferred from the Vector constructor matches the\n            // DataType inferred from the input arguments, return zero-copy view\n            if (ArrowType && ArrowType === InputType) {\n                let type = new ArrowType();\n                let length = input.byteLength / type.ArrayType.BYTES_PER_ELEMENT;\n                // If the ArrowType is 64bit but the input type is 32bit pairs, update the logical length\n                if (convert32To64Bit(ArrowType, input.constructor)) {\n                    length *= 0.5;\n                }\n                return vector_1.Vector.new(data_1.Data.Int(type, 0, length, 0, null, input));\n            }\n        }\n        if (ArrowType) {\n            // If the DataType inferred from the Vector constructor is different than\n            // the DataType inferred from the input TypedArray, or if input isn't a\n            // TypedArray, use the Builders to construct the result Vector\n            return index_1.vectorFromValuesWithType(() => new ArrowType(), input);\n        }\n        if ((input instanceof DataView) || (input instanceof ArrayBuffer)) {\n            throw new TypeError(`Cannot infer integer type from instance of ${input.constructor.name}`);\n        }\n        throw new TypeError('Unrecognized IntVector input');\n    }\n}\nexports.IntVector = IntVector;\n/** @ignore */\nclass Int8Vector extends IntVector {\n}\nexports.Int8Vector = Int8Vector;\n/** @ignore */\nclass Int16Vector extends IntVector {\n}\nexports.Int16Vector = Int16Vector;\n/** @ignore */\nclass Int32Vector extends IntVector {\n}\nexports.Int32Vector = Int32Vector;\n/** @ignore */\nclass Int64Vector extends IntVector {\n    toBigInt64Array() {\n        return buffer_1.toBigInt64Array(this.values);\n    }\n    get values64() {\n        return this._values64 || (this._values64 = this.toBigInt64Array());\n    }\n}\nexports.Int64Vector = Int64Vector;\n/** @ignore */\nclass Uint8Vector extends IntVector {\n}\nexports.Uint8Vector = Uint8Vector;\n/** @ignore */\nclass Uint16Vector extends IntVector {\n}\nexports.Uint16Vector = Uint16Vector;\n/** @ignore */\nclass Uint32Vector extends IntVector {\n}\nexports.Uint32Vector = Uint32Vector;\n/** @ignore */\nclass Uint64Vector extends IntVector {\n    toBigUint64Array() {\n        return buffer_1.toBigUint64Array(this.values);\n    }\n    get values64() {\n        return this._values64 || (this._values64 = this.toBigUint64Array());\n    }\n}\nexports.Uint64Vector = Uint64Vector;\nconst convert32To64Bit = (typeCtor, dataCtor) => {\n    return (typeCtor === type_1.Int64 || typeCtor === type_1.Uint64) &&\n        (dataCtor === Int32Array || dataCtor === Uint32Array);\n};\n/** @ignore */\nconst arrayTypeToDataType = (ctor, is64bit) => {\n    switch (ctor) {\n        case Int8Array: return type_1.Int8;\n        case Int16Array: return type_1.Int16;\n        case Int32Array: return is64bit ? type_1.Int64 : type_1.Int32;\n        case compat_1.BigInt64Array: return type_1.Int64;\n        case Uint8Array: return type_1.Uint8;\n        case Uint16Array: return type_1.Uint16;\n        case Uint32Array: return is64bit ? type_1.Uint64 : type_1.Uint32;\n        case compat_1.BigUint64Array: return type_1.Uint64;\n        default: return null;\n    }\n};\n/** @ignore */\nconst vectorTypeToDataType = (ctor, is64bit) => {\n    switch (ctor) {\n        case Int8Vector: return type_1.Int8;\n        case Int16Vector: return type_1.Int16;\n        case Int32Vector: return is64bit ? type_1.Int64 : type_1.Int32;\n        case Int64Vector: return type_1.Int64;\n        case Uint8Vector: return type_1.Uint8;\n        case Uint16Vector: return type_1.Uint16;\n        case Uint32Vector: return is64bit ? type_1.Uint64 : type_1.Uint32;\n        case Uint64Vector: return type_1.Uint64;\n        default: return null;\n    }\n};\n\n//# sourceMappingURL=int.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass IntervalVector extends base_1.BaseVector {\n}\nexports.IntervalVector = IntervalVector;\n/** @ignore */\nclass IntervalDayTimeVector extends IntervalVector {\n}\nexports.IntervalDayTimeVector = IntervalDayTimeVector;\n/** @ignore */\nclass IntervalYearMonthVector extends IntervalVector {\n}\nexports.IntervalYearMonthVector = IntervalYearMonthVector;\n\n//# sourceMappingURL=interval.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass ListVector extends base_1.BaseVector {\n}\nexports.ListVector = ListVector;\n\n//# sourceMappingURL=list.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst row_1 = require(\"./row\");\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass MapVector extends base_1.BaseVector {\n    asList() {\n        const child = this.type.children[0];\n        return vector_1.Vector.new(this.data.clone(new type_1.List(child)));\n    }\n    bind(index) {\n        const child = this.getChildAt(0);\n        const { [index]: begin, [index + 1]: end } = this.valueOffsets;\n        return new row_1.MapRow(child.slice(begin, end));\n    }\n}\nexports.MapVector = MapVector;\n\n//# sourceMappingURL=map.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass NullVector extends base_1.BaseVector {\n}\nexports.NullVector = NullVector;\n\n//# sourceMappingURL=null.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst pretty_1 = require(\"../util/pretty\");\n/** @ignore */ const kParent = Symbol.for('parent');\n/** @ignore */ const kRowIndex = Symbol.for('rowIndex');\n/** @ignore */ const kKeyToIdx = Symbol.for('keyToIdx');\n/** @ignore */ const kIdxToVal = Symbol.for('idxToVal');\n/** @ignore */ const kCustomInspect = Symbol.for('nodejs.util.inspect.custom');\nclass Row {\n    constructor(parent, numKeys) {\n        this[kParent] = parent;\n        this.size = numKeys;\n    }\n    entries() { return this[Symbol.iterator](); }\n    has(key) { return this.get(key) !== undefined; }\n    get(key) {\n        let val = undefined;\n        if (key !== null && key !== undefined) {\n            const ktoi = this[kKeyToIdx] || (this[kKeyToIdx] = new Map());\n            let idx = ktoi.get(key);\n            if (idx !== undefined) {\n                const itov = this[kIdxToVal] || (this[kIdxToVal] = new Array(this.size));\n                ((val = itov[idx]) !== undefined) || (itov[idx] = val = this.getValue(idx));\n            }\n            else if ((idx = this.getIndex(key)) > -1) {\n                ktoi.set(key, idx);\n                const itov = this[kIdxToVal] || (this[kIdxToVal] = new Array(this.size));\n                ((val = itov[idx]) !== undefined) || (itov[idx] = val = this.getValue(idx));\n            }\n        }\n        return val;\n    }\n    set(key, val) {\n        if (key !== null && key !== undefined) {\n            const ktoi = this[kKeyToIdx] || (this[kKeyToIdx] = new Map());\n            let idx = ktoi.get(key);\n            if (idx === undefined) {\n                ktoi.set(key, idx = this.getIndex(key));\n            }\n            if (idx > -1) {\n                const itov = this[kIdxToVal] || (this[kIdxToVal] = new Array(this.size));\n                itov[idx] = this.setValue(idx, val);\n            }\n        }\n        return this;\n    }\n    clear() { throw new Error(`Clearing ${this[Symbol.toStringTag]} not supported.`); }\n    delete(_) { throw new Error(`Deleting ${this[Symbol.toStringTag]} values not supported.`); }\n    *[Symbol.iterator]() {\n        const ki = this.keys();\n        const vi = this.values();\n        const ktoi = this[kKeyToIdx] || (this[kKeyToIdx] = new Map());\n        const itov = this[kIdxToVal] || (this[kIdxToVal] = new Array(this.size));\n        for (let k, v, i = 0, kr, vr; !((kr = ki.next()).done || (vr = vi.next()).done); ++i) {\n            k = kr.value;\n            v = vr.value;\n            itov[i] = v;\n            ktoi.has(k) || ktoi.set(k, i);\n            yield [k, v];\n        }\n    }\n    forEach(callbackfn, thisArg) {\n        const ki = this.keys();\n        const vi = this.values();\n        const callback = thisArg === undefined ? callbackfn :\n            (v, k, m) => callbackfn.call(thisArg, v, k, m);\n        const ktoi = this[kKeyToIdx] || (this[kKeyToIdx] = new Map());\n        const itov = this[kIdxToVal] || (this[kIdxToVal] = new Array(this.size));\n        for (let k, v, i = 0, kr, vr; !((kr = ki.next()).done || (vr = vi.next()).done); ++i) {\n            k = kr.value;\n            v = vr.value;\n            itov[i] = v;\n            ktoi.has(k) || ktoi.set(k, i);\n            callback(v, k, this);\n        }\n    }\n    toArray() { return [...this.values()]; }\n    toJSON() {\n        const obj = {};\n        this.forEach((val, key) => obj[key] = val);\n        return obj;\n    }\n    inspect() { return this.toString(); }\n    [kCustomInspect]() { return this.toString(); }\n    toString() {\n        const str = [];\n        this.forEach((val, key) => {\n            key = pretty_1.valueToString(key);\n            val = pretty_1.valueToString(val);\n            str.push(`${key}: ${val}`);\n        });\n        return `{ ${str.join(', ')} }`;\n    }\n}\nRow[Symbol.toStringTag] = ((proto) => {\n    Object.defineProperties(proto, {\n        'size': { writable: true, enumerable: false, configurable: false, value: 0 },\n        [kParent]: { writable: true, enumerable: false, configurable: false, value: null },\n        [kRowIndex]: { writable: true, enumerable: false, configurable: false, value: -1 },\n    });\n    return proto[Symbol.toStringTag] = 'Row';\n})(Row.prototype);\nclass MapRow extends Row {\n    constructor(slice) {\n        super(slice, slice.length);\n        return createRowProxy(this);\n    }\n    keys() {\n        return this[kParent].getChildAt(0)[Symbol.iterator]();\n    }\n    values() {\n        return this[kParent].getChildAt(1)[Symbol.iterator]();\n    }\n    getKey(idx) {\n        return this[kParent].getChildAt(0).get(idx);\n    }\n    getIndex(key) {\n        return this[kParent].getChildAt(0).indexOf(key);\n    }\n    getValue(index) {\n        return this[kParent].getChildAt(1).get(index);\n    }\n    setValue(index, value) {\n        this[kParent].getChildAt(1).set(index, value);\n    }\n}\nexports.MapRow = MapRow;\nclass StructRow extends Row {\n    constructor(parent) {\n        super(parent, parent.type.children.length);\n        return defineRowProxyProperties(this);\n    }\n    *keys() {\n        for (const field of this[kParent].type.children) {\n            yield field.name;\n        }\n    }\n    *values() {\n        for (const field of this[kParent].type.children) {\n            yield this[field.name];\n        }\n    }\n    getKey(idx) {\n        return this[kParent].type.children[idx].name;\n    }\n    getIndex(key) {\n        return this[kParent].type.children.findIndex((f) => f.name === key);\n    }\n    getValue(index) {\n        return this[kParent].getChildAt(index).get(this[kRowIndex]);\n    }\n    setValue(index, value) {\n        return this[kParent].getChildAt(index).set(this[kRowIndex], value);\n    }\n}\nexports.StructRow = StructRow;\nObject.setPrototypeOf(Row.prototype, Map.prototype);\n/** @ignore */\nconst defineRowProxyProperties = (() => {\n    const desc = { enumerable: true, configurable: false, get: null, set: null };\n    return (row) => {\n        let idx = -1, ktoi = row[kKeyToIdx] || (row[kKeyToIdx] = new Map());\n        const getter = (key) => function () { return this.get(key); };\n        const setter = (key) => function (val) { return this.set(key, val); };\n        for (const key of row.keys()) {\n            ktoi.set(key, ++idx);\n            desc.get = getter(key);\n            desc.set = setter(key);\n            row.hasOwnProperty(key) || (desc.enumerable = true, Object.defineProperty(row, key, desc));\n            row.hasOwnProperty(idx) || (desc.enumerable = false, Object.defineProperty(row, idx, desc));\n        }\n        desc.get = desc.set = null;\n        return row;\n    };\n})();\n/** @ignore */\nconst createRowProxy = (() => {\n    if (typeof Proxy === 'undefined') {\n        return defineRowProxyProperties;\n    }\n    const has = Row.prototype.has;\n    const get = Row.prototype.get;\n    const set = Row.prototype.set;\n    const getKey = Row.prototype.getKey;\n    const RowProxyHandler = {\n        isExtensible() { return false; },\n        deleteProperty() { return false; },\n        preventExtensions() { return true; },\n        ownKeys(row) { return [...row.keys()].map((x) => `${x}`); },\n        has(row, key) {\n            switch (key) {\n                case 'getKey':\n                case 'getIndex':\n                case 'getValue':\n                case 'setValue':\n                case 'toArray':\n                case 'toJSON':\n                case 'inspect':\n                case 'constructor':\n                case 'isPrototypeOf':\n                case 'propertyIsEnumerable':\n                case 'toString':\n                case 'toLocaleString':\n                case 'valueOf':\n                case 'size':\n                case 'has':\n                case 'get':\n                case 'set':\n                case 'clear':\n                case 'delete':\n                case 'keys':\n                case 'values':\n                case 'entries':\n                case 'forEach':\n                case '__proto__':\n                case '__defineGetter__':\n                case '__defineSetter__':\n                case 'hasOwnProperty':\n                case '__lookupGetter__':\n                case '__lookupSetter__':\n                case Symbol.iterator:\n                case Symbol.toStringTag:\n                case kParent:\n                case kRowIndex:\n                case kIdxToVal:\n                case kKeyToIdx:\n                case kCustomInspect:\n                    return true;\n            }\n            if (typeof key === 'number' && !row.has(key)) {\n                key = row.getKey(key);\n            }\n            return row.has(key);\n        },\n        get(row, key, receiver) {\n            switch (key) {\n                case 'getKey':\n                case 'getIndex':\n                case 'getValue':\n                case 'setValue':\n                case 'toArray':\n                case 'toJSON':\n                case 'inspect':\n                case 'constructor':\n                case 'isPrototypeOf':\n                case 'propertyIsEnumerable':\n                case 'toString':\n                case 'toLocaleString':\n                case 'valueOf':\n                case 'size':\n                case 'has':\n                case 'get':\n                case 'set':\n                case 'clear':\n                case 'delete':\n                case 'keys':\n                case 'values':\n                case 'entries':\n                case 'forEach':\n                case '__proto__':\n                case '__defineGetter__':\n                case '__defineSetter__':\n                case 'hasOwnProperty':\n                case '__lookupGetter__':\n                case '__lookupSetter__':\n                case Symbol.iterator:\n                case Symbol.toStringTag:\n                case kParent:\n                case kRowIndex:\n                case kIdxToVal:\n                case kKeyToIdx:\n                case kCustomInspect:\n                    return Reflect.get(row, key, receiver);\n            }\n            if (typeof key === 'number' && !has.call(receiver, key)) {\n                key = getKey.call(receiver, key);\n            }\n            return get.call(receiver, key);\n        },\n        set(row, key, val, receiver) {\n            switch (key) {\n                case kParent:\n                case kRowIndex:\n                case kIdxToVal:\n                case kKeyToIdx:\n                    return Reflect.set(row, key, val, receiver);\n                case 'getKey':\n                case 'getIndex':\n                case 'getValue':\n                case 'setValue':\n                case 'toArray':\n                case 'toJSON':\n                case 'inspect':\n                case 'constructor':\n                case 'isPrototypeOf':\n                case 'propertyIsEnumerable':\n                case 'toString':\n                case 'toLocaleString':\n                case 'valueOf':\n                case 'size':\n                case 'has':\n                case 'get':\n                case 'set':\n                case 'clear':\n                case 'delete':\n                case 'keys':\n                case 'values':\n                case 'entries':\n                case 'forEach':\n                case '__proto__':\n                case '__defineGetter__':\n                case '__defineSetter__':\n                case 'hasOwnProperty':\n                case '__lookupGetter__':\n                case '__lookupSetter__':\n                case Symbol.iterator:\n                case Symbol.toStringTag:\n                    return false;\n            }\n            if (typeof key === 'number' && !has.call(receiver, key)) {\n                key = getKey.call(receiver, key);\n            }\n            return has.call(receiver, key) ? !!set.call(receiver, key, val) : false;\n        },\n    };\n    return (row) => new Proxy(row, RowProxyHandler);\n})();\n\n//# sourceMappingURL=row.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst row_1 = require(\"./row\");\nconst base_1 = require(\"./base\");\n/** @ignore */ const kRowIndex = Symbol.for('rowIndex');\n/** @ignore */\nclass StructVector extends base_1.BaseVector {\n    bind(index) {\n        const proto = this._row || (this._row = new row_1.StructRow(this));\n        const bound = Object.create(proto);\n        bound[kRowIndex] = index;\n        return bound;\n    }\n}\nexports.StructVector = StructVector;\n\n//# sourceMappingURL=struct.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass TimeVector extends base_1.BaseVector {\n}\nexports.TimeVector = TimeVector;\n/** @ignore */\nclass TimeSecondVector extends TimeVector {\n}\nexports.TimeSecondVector = TimeSecondVector;\n/** @ignore */\nclass TimeMillisecondVector extends TimeVector {\n}\nexports.TimeMillisecondVector = TimeMillisecondVector;\n/** @ignore */\nclass TimeMicrosecondVector extends TimeVector {\n}\nexports.TimeMicrosecondVector = TimeMicrosecondVector;\n/** @ignore */\nclass TimeNanosecondVector extends TimeVector {\n}\nexports.TimeNanosecondVector = TimeNanosecondVector;\n\n//# sourceMappingURL=time.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass TimestampVector extends base_1.BaseVector {\n}\nexports.TimestampVector = TimestampVector;\n/** @ignore */\nclass TimestampSecondVector extends TimestampVector {\n}\nexports.TimestampSecondVector = TimestampSecondVector;\n/** @ignore */\nclass TimestampMillisecondVector extends TimestampVector {\n}\nexports.TimestampMillisecondVector = TimestampMillisecondVector;\n/** @ignore */\nclass TimestampMicrosecondVector extends TimestampVector {\n}\nexports.TimestampMicrosecondVector = TimestampMicrosecondVector;\n/** @ignore */\nclass TimestampNanosecondVector extends TimestampVector {\n}\nexports.TimestampNanosecondVector = TimestampNanosecondVector;\n\n//# sourceMappingURL=timestamp.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst base_1 = require(\"./base\");\n/** @ignore */\nclass UnionVector extends base_1.BaseVector {\n    get typeIdToChildIndex() { return this.data.type.typeIdToChildIndex; }\n}\nexports.UnionVector = UnionVector;\n/** @ignore */\nclass DenseUnionVector extends UnionVector {\n    get valueOffsets() { return this.data.valueOffsets; }\n}\nexports.DenseUnionVector = DenseUnionVector;\n/** @ignore */\nclass SparseUnionVector extends UnionVector {\n}\nexports.SparseUnionVector = SparseUnionVector;\n\n//# sourceMappingURL=union.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\nconst base_1 = require(\"./base\");\nconst type_1 = require(\"../type\");\nconst index_1 = require(\"./index\");\n/** @ignore */\nclass Utf8Vector extends base_1.BaseVector {\n    /** @nocollapse */\n    static from(input) {\n        return index_1.vectorFromValuesWithType(() => new type_1.Utf8(), input);\n    }\n    asBinary() {\n        return vector_1.Vector.new(this.data.clone(new type_1.Binary()));\n    }\n}\nexports.Utf8Vector = Utf8Vector;\n\n//# sourceMappingURL=utf8.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"./data\");\nconst vector_1 = require(\"./vector\");\nconst enum_1 = require(\"./enum\");\nconst type_1 = require(\"./type\");\nclass Visitor {\n    visitMany(nodes, ...args) {\n        return nodes.map((node, i) => this.visit(node, ...args.map((x) => x[i])));\n    }\n    visit(...args) {\n        return this.getVisitFn(args[0], false).apply(this, args);\n    }\n    getVisitFn(node, throwIfNotFound = true) {\n        return getVisitFn(this, node, throwIfNotFound);\n    }\n    visitNull(_node, ..._args) { return null; }\n    visitBool(_node, ..._args) { return null; }\n    visitInt(_node, ..._args) { return null; }\n    visitFloat(_node, ..._args) { return null; }\n    visitUtf8(_node, ..._args) { return null; }\n    visitBinary(_node, ..._args) { return null; }\n    visitFixedSizeBinary(_node, ..._args) { return null; }\n    visitDate(_node, ..._args) { return null; }\n    visitTimestamp(_node, ..._args) { return null; }\n    visitTime(_node, ..._args) { return null; }\n    visitDecimal(_node, ..._args) { return null; }\n    visitList(_node, ..._args) { return null; }\n    visitStruct(_node, ..._args) { return null; }\n    visitUnion(_node, ..._args) { return null; }\n    visitDictionary(_node, ..._args) { return null; }\n    visitInterval(_node, ..._args) { return null; }\n    visitFixedSizeList(_node, ..._args) { return null; }\n    visitMap(_node, ..._args) { return null; }\n}\nexports.Visitor = Visitor;\n/** @ignore */\nfunction getVisitFn(visitor, node, throwIfNotFound = true) {\n    let fn = null;\n    let dtype = enum_1.Type.NONE;\n    // tslint:disable\n    if (node instanceof data_1.Data) {\n        dtype = inferDType(node.type);\n    }\n    else if (node instanceof vector_1.Vector) {\n        dtype = inferDType(node.type);\n    }\n    else if (node instanceof type_1.DataType) {\n        dtype = inferDType(node);\n    }\n    else if (typeof (dtype = node) !== 'number') {\n        dtype = enum_1.Type[node];\n    }\n    switch (dtype) {\n        case enum_1.Type.Null:\n            fn = visitor.visitNull;\n            break;\n        case enum_1.Type.Bool:\n            fn = visitor.visitBool;\n            break;\n        case enum_1.Type.Int:\n            fn = visitor.visitInt;\n            break;\n        case enum_1.Type.Int8:\n            fn = visitor.visitInt8 || visitor.visitInt;\n            break;\n        case enum_1.Type.Int16:\n            fn = visitor.visitInt16 || visitor.visitInt;\n            break;\n        case enum_1.Type.Int32:\n            fn = visitor.visitInt32 || visitor.visitInt;\n            break;\n        case enum_1.Type.Int64:\n            fn = visitor.visitInt64 || visitor.visitInt;\n            break;\n        case enum_1.Type.Uint8:\n            fn = visitor.visitUint8 || visitor.visitInt;\n            break;\n        case enum_1.Type.Uint16:\n            fn = visitor.visitUint16 || visitor.visitInt;\n            break;\n        case enum_1.Type.Uint32:\n            fn = visitor.visitUint32 || visitor.visitInt;\n            break;\n        case enum_1.Type.Uint64:\n            fn = visitor.visitUint64 || visitor.visitInt;\n            break;\n        case enum_1.Type.Float:\n            fn = visitor.visitFloat;\n            break;\n        case enum_1.Type.Float16:\n            fn = visitor.visitFloat16 || visitor.visitFloat;\n            break;\n        case enum_1.Type.Float32:\n            fn = visitor.visitFloat32 || visitor.visitFloat;\n            break;\n        case enum_1.Type.Float64:\n            fn = visitor.visitFloat64 || visitor.visitFloat;\n            break;\n        case enum_1.Type.Utf8:\n            fn = visitor.visitUtf8;\n            break;\n        case enum_1.Type.Binary:\n            fn = visitor.visitBinary;\n            break;\n        case enum_1.Type.FixedSizeBinary:\n            fn = visitor.visitFixedSizeBinary;\n            break;\n        case enum_1.Type.Date:\n            fn = visitor.visitDate;\n            break;\n        case enum_1.Type.DateDay:\n            fn = visitor.visitDateDay || visitor.visitDate;\n            break;\n        case enum_1.Type.DateMillisecond:\n            fn = visitor.visitDateMillisecond || visitor.visitDate;\n            break;\n        case enum_1.Type.Timestamp:\n            fn = visitor.visitTimestamp;\n            break;\n        case enum_1.Type.TimestampSecond:\n            fn = visitor.visitTimestampSecond || visitor.visitTimestamp;\n            break;\n        case enum_1.Type.TimestampMillisecond:\n            fn = visitor.visitTimestampMillisecond || visitor.visitTimestamp;\n            break;\n        case enum_1.Type.TimestampMicrosecond:\n            fn = visitor.visitTimestampMicrosecond || visitor.visitTimestamp;\n            break;\n        case enum_1.Type.TimestampNanosecond:\n            fn = visitor.visitTimestampNanosecond || visitor.visitTimestamp;\n            break;\n        case enum_1.Type.Time:\n            fn = visitor.visitTime;\n            break;\n        case enum_1.Type.TimeSecond:\n            fn = visitor.visitTimeSecond || visitor.visitTime;\n            break;\n        case enum_1.Type.TimeMillisecond:\n            fn = visitor.visitTimeMillisecond || visitor.visitTime;\n            break;\n        case enum_1.Type.TimeMicrosecond:\n            fn = visitor.visitTimeMicrosecond || visitor.visitTime;\n            break;\n        case enum_1.Type.TimeNanosecond:\n            fn = visitor.visitTimeNanosecond || visitor.visitTime;\n            break;\n        case enum_1.Type.Decimal:\n            fn = visitor.visitDecimal;\n            break;\n        case enum_1.Type.List:\n            fn = visitor.visitList;\n            break;\n        case enum_1.Type.Struct:\n            fn = visitor.visitStruct;\n            break;\n        case enum_1.Type.Union:\n            fn = visitor.visitUnion;\n            break;\n        case enum_1.Type.DenseUnion:\n            fn = visitor.visitDenseUnion || visitor.visitUnion;\n            break;\n        case enum_1.Type.SparseUnion:\n            fn = visitor.visitSparseUnion || visitor.visitUnion;\n            break;\n        case enum_1.Type.Dictionary:\n            fn = visitor.visitDictionary;\n            break;\n        case enum_1.Type.Interval:\n            fn = visitor.visitInterval;\n            break;\n        case enum_1.Type.IntervalDayTime:\n            fn = visitor.visitIntervalDayTime || visitor.visitInterval;\n            break;\n        case enum_1.Type.IntervalYearMonth:\n            fn = visitor.visitIntervalYearMonth || visitor.visitInterval;\n            break;\n        case enum_1.Type.FixedSizeList:\n            fn = visitor.visitFixedSizeList;\n            break;\n        case enum_1.Type.Map:\n            fn = visitor.visitMap;\n            break;\n    }\n    if (typeof fn === 'function')\n        return fn;\n    if (!throwIfNotFound)\n        return () => null;\n    throw new Error(`Unrecognized type '${enum_1.Type[dtype]}'`);\n}\n/** @ignore */\nfunction inferDType(type) {\n    switch (type.typeId) {\n        case enum_1.Type.Null: return enum_1.Type.Null;\n        case enum_1.Type.Int:\n            const { bitWidth, isSigned } = type;\n            switch (bitWidth) {\n                case 8: return isSigned ? enum_1.Type.Int8 : enum_1.Type.Uint8;\n                case 16: return isSigned ? enum_1.Type.Int16 : enum_1.Type.Uint16;\n                case 32: return isSigned ? enum_1.Type.Int32 : enum_1.Type.Uint32;\n                case 64: return isSigned ? enum_1.Type.Int64 : enum_1.Type.Uint64;\n            }\n            return enum_1.Type.Int;\n        case enum_1.Type.Float:\n            switch (type.precision) {\n                case enum_1.Precision.HALF: return enum_1.Type.Float16;\n                case enum_1.Precision.SINGLE: return enum_1.Type.Float32;\n                case enum_1.Precision.DOUBLE: return enum_1.Type.Float64;\n            }\n            return enum_1.Type.Float;\n        case enum_1.Type.Binary: return enum_1.Type.Binary;\n        case enum_1.Type.Utf8: return enum_1.Type.Utf8;\n        case enum_1.Type.Bool: return enum_1.Type.Bool;\n        case enum_1.Type.Decimal: return enum_1.Type.Decimal;\n        case enum_1.Type.Time:\n            switch (type.unit) {\n                case enum_1.TimeUnit.SECOND: return enum_1.Type.TimeSecond;\n                case enum_1.TimeUnit.MILLISECOND: return enum_1.Type.TimeMillisecond;\n                case enum_1.TimeUnit.MICROSECOND: return enum_1.Type.TimeMicrosecond;\n                case enum_1.TimeUnit.NANOSECOND: return enum_1.Type.TimeNanosecond;\n            }\n            return enum_1.Type.Time;\n        case enum_1.Type.Timestamp:\n            switch (type.unit) {\n                case enum_1.TimeUnit.SECOND: return enum_1.Type.TimestampSecond;\n                case enum_1.TimeUnit.MILLISECOND: return enum_1.Type.TimestampMillisecond;\n                case enum_1.TimeUnit.MICROSECOND: return enum_1.Type.TimestampMicrosecond;\n                case enum_1.TimeUnit.NANOSECOND: return enum_1.Type.TimestampNanosecond;\n            }\n            return enum_1.Type.Timestamp;\n        case enum_1.Type.Date:\n            switch (type.unit) {\n                case enum_1.DateUnit.DAY: return enum_1.Type.DateDay;\n                case enum_1.DateUnit.MILLISECOND: return enum_1.Type.DateMillisecond;\n            }\n            return enum_1.Type.Date;\n        case enum_1.Type.Interval:\n            switch (type.unit) {\n                case enum_1.IntervalUnit.DAY_TIME: return enum_1.Type.IntervalDayTime;\n                case enum_1.IntervalUnit.YEAR_MONTH: return enum_1.Type.IntervalYearMonth;\n            }\n            return enum_1.Type.Interval;\n        case enum_1.Type.Map: return enum_1.Type.Map;\n        case enum_1.Type.List: return enum_1.Type.List;\n        case enum_1.Type.Struct: return enum_1.Type.Struct;\n        case enum_1.Type.Union:\n            switch (type.mode) {\n                case enum_1.UnionMode.Dense: return enum_1.Type.DenseUnion;\n                case enum_1.UnionMode.Sparse: return enum_1.Type.SparseUnion;\n            }\n            return enum_1.Type.Union;\n        case enum_1.Type.FixedSizeBinary: return enum_1.Type.FixedSizeBinary;\n        case enum_1.Type.FixedSizeList: return enum_1.Type.FixedSizeList;\n        case enum_1.Type.Dictionary: return enum_1.Type.Dictionary;\n    }\n    throw new Error(`Unrecognized type '${enum_1.Type[type.typeId]}'`);\n}\n// Add these here so they're picked up by the externs creator\n// in the build, and closure-compiler doesn't minify them away\nVisitor.prototype.visitInt8 = null;\nVisitor.prototype.visitInt16 = null;\nVisitor.prototype.visitInt32 = null;\nVisitor.prototype.visitInt64 = null;\nVisitor.prototype.visitUint8 = null;\nVisitor.prototype.visitUint16 = null;\nVisitor.prototype.visitUint32 = null;\nVisitor.prototype.visitUint64 = null;\nVisitor.prototype.visitFloat16 = null;\nVisitor.prototype.visitFloat32 = null;\nVisitor.prototype.visitFloat64 = null;\nVisitor.prototype.visitDateDay = null;\nVisitor.prototype.visitDateMillisecond = null;\nVisitor.prototype.visitTimestampSecond = null;\nVisitor.prototype.visitTimestampMillisecond = null;\nVisitor.prototype.visitTimestampMicrosecond = null;\nVisitor.prototype.visitTimestampNanosecond = null;\nVisitor.prototype.visitTimeSecond = null;\nVisitor.prototype.visitTimeMillisecond = null;\nVisitor.prototype.visitTimeMicrosecond = null;\nVisitor.prototype.visitTimeNanosecond = null;\nVisitor.prototype.visitDenseUnion = null;\nVisitor.prototype.visitSparseUnion = null;\nVisitor.prototype.visitIntervalDayTime = null;\nVisitor.prototype.visitIntervalYearMonth = null;\n\n//# sourceMappingURL=visitor.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst binary_1 = require(\"../builder/binary\");\nconst bool_1 = require(\"../builder/bool\");\nconst date_1 = require(\"../builder/date\");\nconst decimal_1 = require(\"../builder/decimal\");\nconst dictionary_1 = require(\"../builder/dictionary\");\nconst fixedsizebinary_1 = require(\"../builder/fixedsizebinary\");\nconst fixedsizelist_1 = require(\"../builder/fixedsizelist\");\nconst float_1 = require(\"../builder/float\");\nconst interval_1 = require(\"../builder/interval\");\nconst int_1 = require(\"../builder/int\");\nconst list_1 = require(\"../builder/list\");\nconst map_1 = require(\"../builder/map\");\nconst null_1 = require(\"../builder/null\");\nconst struct_1 = require(\"../builder/struct\");\nconst timestamp_1 = require(\"../builder/timestamp\");\nconst time_1 = require(\"../builder/time\");\nconst union_1 = require(\"../builder/union\");\nconst utf8_1 = require(\"../builder/utf8\");\n/** @ignore */\nclass GetBuilderCtor extends visitor_1.Visitor {\n    visitNull() { return null_1.NullBuilder; }\n    visitBool() { return bool_1.BoolBuilder; }\n    visitInt() { return int_1.IntBuilder; }\n    visitInt8() { return int_1.Int8Builder; }\n    visitInt16() { return int_1.Int16Builder; }\n    visitInt32() { return int_1.Int32Builder; }\n    visitInt64() { return int_1.Int64Builder; }\n    visitUint8() { return int_1.Uint8Builder; }\n    visitUint16() { return int_1.Uint16Builder; }\n    visitUint32() { return int_1.Uint32Builder; }\n    visitUint64() { return int_1.Uint64Builder; }\n    visitFloat() { return float_1.FloatBuilder; }\n    visitFloat16() { return float_1.Float16Builder; }\n    visitFloat32() { return float_1.Float32Builder; }\n    visitFloat64() { return float_1.Float64Builder; }\n    visitUtf8() { return utf8_1.Utf8Builder; }\n    visitBinary() { return binary_1.BinaryBuilder; }\n    visitFixedSizeBinary() { return fixedsizebinary_1.FixedSizeBinaryBuilder; }\n    visitDate() { return date_1.DateBuilder; }\n    visitDateDay() { return date_1.DateDayBuilder; }\n    visitDateMillisecond() { return date_1.DateMillisecondBuilder; }\n    visitTimestamp() { return timestamp_1.TimestampBuilder; }\n    visitTimestampSecond() { return timestamp_1.TimestampSecondBuilder; }\n    visitTimestampMillisecond() { return timestamp_1.TimestampMillisecondBuilder; }\n    visitTimestampMicrosecond() { return timestamp_1.TimestampMicrosecondBuilder; }\n    visitTimestampNanosecond() { return timestamp_1.TimestampNanosecondBuilder; }\n    visitTime() { return time_1.TimeBuilder; }\n    visitTimeSecond() { return time_1.TimeSecondBuilder; }\n    visitTimeMillisecond() { return time_1.TimeMillisecondBuilder; }\n    visitTimeMicrosecond() { return time_1.TimeMicrosecondBuilder; }\n    visitTimeNanosecond() { return time_1.TimeNanosecondBuilder; }\n    visitDecimal() { return decimal_1.DecimalBuilder; }\n    visitList() { return list_1.ListBuilder; }\n    visitStruct() { return struct_1.StructBuilder; }\n    visitUnion() { return union_1.UnionBuilder; }\n    visitDenseUnion() { return union_1.DenseUnionBuilder; }\n    visitSparseUnion() { return union_1.SparseUnionBuilder; }\n    visitDictionary() { return dictionary_1.DictionaryBuilder; }\n    visitInterval() { return interval_1.IntervalBuilder; }\n    visitIntervalDayTime() { return interval_1.IntervalDayTimeBuilder; }\n    visitIntervalYearMonth() { return interval_1.IntervalYearMonthBuilder; }\n    visitFixedSizeList() { return fixedsizelist_1.FixedSizeListBuilder; }\n    visitMap() { return map_1.MapBuilder; }\n}\nexports.GetBuilderCtor = GetBuilderCtor;\n/** @ignore */\nexports.instance = new GetBuilderCtor();\n\n//# sourceMappingURL=builderctor.js.map\n","\"use strict\";\n/* istanbul ignore file */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst enum_1 = require(\"../enum\");\n/** @ignore */ const sum = (x, y) => x + y;\n/** @ignore */ const variableWidthColumnErrorMessage = (type) => `Cannot compute the byte width of variable-width column ${type}`;\n/** @ignore */\nclass ByteWidthVisitor extends visitor_1.Visitor {\n    visitNull(____) { return 0; }\n    visitInt(type) { return type.bitWidth / 8; }\n    visitFloat(type) { return type.ArrayType.BYTES_PER_ELEMENT; }\n    visitBinary(type) { throw new Error(variableWidthColumnErrorMessage(type)); }\n    visitUtf8(type) { throw new Error(variableWidthColumnErrorMessage(type)); }\n    visitBool(____) { return 1 / 8; }\n    visitDecimal(____) { return 16; }\n    visitDate(type) { return (type.unit + 1) * 4; }\n    visitTime(type) { return type.bitWidth / 8; }\n    visitTimestamp(type) { return type.unit === enum_1.TimeUnit.SECOND ? 4 : 8; }\n    visitInterval(type) { return (type.unit + 1) * 4; }\n    visitList(type) { throw new Error(variableWidthColumnErrorMessage(type)); }\n    visitStruct(type) { return this.visitFields(type.children).reduce(sum, 0); }\n    visitUnion(type) { return this.visitFields(type.children).reduce(sum, 0); }\n    visitFixedSizeBinary(type) { return type.byteWidth; }\n    visitFixedSizeList(type) { return type.listSize * this.visitFields(type.children).reduce(sum, 0); }\n    visitMap(type) { return this.visitFields(type.children).reduce(sum, 0); }\n    visitDictionary(type) { return this.visit(type.indices); }\n    visitFields(fields) { return (fields || []).map((field) => this.visit(field.type)); }\n    visitSchema(schema) { return this.visitFields(schema.fields).reduce(sum, 0); }\n}\nexports.ByteWidthVisitor = ByteWidthVisitor;\n/** @ignore */\nexports.instance = new ByteWidthVisitor();\n\n//# sourceMappingURL=bytewidth.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst bn_1 = require(\"../util/bn\");\nconst visitor_1 = require(\"../visitor\");\nconst utf8_1 = require(\"../util/utf8\");\nconst math_1 = require(\"../util/math\");\nconst enum_1 = require(\"../enum\");\n/** @ignore */\nclass GetVisitor extends visitor_1.Visitor {\n}\nexports.GetVisitor = GetVisitor;\n/** @ignore */ const epochDaysToMs = (data, index) => 86400000 * data[index];\n/** @ignore */ const epochMillisecondsLongToMs = (data, index) => 4294967296 * (data[index + 1]) + (data[index] >>> 0);\n/** @ignore */ const epochMicrosecondsLongToMs = (data, index) => 4294967296 * (data[index + 1] / 1000) + ((data[index] >>> 0) / 1000);\n/** @ignore */ const epochNanosecondsLongToMs = (data, index) => 4294967296 * (data[index + 1] / 1000000) + ((data[index] >>> 0) / 1000000);\n/** @ignore */ const epochMillisecondsToDate = (epochMs) => new Date(epochMs);\n/** @ignore */ const epochDaysToDate = (data, index) => epochMillisecondsToDate(epochDaysToMs(data, index));\n/** @ignore */ const epochMillisecondsLongToDate = (data, index) => epochMillisecondsToDate(epochMillisecondsLongToMs(data, index));\n/** @ignore */\nconst getNull = (_vector, _index) => null;\n/** @ignore */\nconst getVariableWidthBytes = (values, valueOffsets, index) => {\n    const { [index]: x, [index + 1]: y } = valueOffsets;\n    return x != null && y != null ? values.subarray(x, y) : null;\n};\n/** @ignore */\nconst getBool = ({ offset, values }, index) => {\n    const idx = offset + index;\n    const byte = values[idx >> 3];\n    return (byte & 1 << (idx % 8)) !== 0;\n};\n/** @ignore */\nconst getDateDay = ({ values }, index) => epochDaysToDate(values, index);\n/** @ignore */\nconst getDateMillisecond = ({ values }, index) => epochMillisecondsLongToDate(values, index * 2);\n/** @ignore */\nconst getNumeric = ({ stride, values }, index) => values[stride * index];\n/** @ignore */\nconst getFloat16 = ({ stride, values }, index) => math_1.uint16ToFloat64(values[stride * index]);\n/** @ignore */\nconst getBigInts = ({ stride, values, type }, index) => bn_1.BN.new(values.subarray(stride * index, stride * (index + 1)), type.isSigned);\n/** @ignore */\nconst getFixedSizeBinary = ({ stride, values }, index) => values.subarray(stride * index, stride * (index + 1));\n/** @ignore */\nconst getBinary = ({ values, valueOffsets }, index) => getVariableWidthBytes(values, valueOffsets, index);\n/** @ignore */\nconst getUtf8 = ({ values, valueOffsets }, index) => {\n    const bytes = getVariableWidthBytes(values, valueOffsets, index);\n    return bytes !== null ? utf8_1.decodeUtf8(bytes) : null;\n};\n/* istanbul ignore next */\n/** @ignore */\nconst getInt = (vector, index) => (vector.type.bitWidth < 64\n    ? getNumeric(vector, index)\n    : getBigInts(vector, index));\n/* istanbul ignore next */\n/** @ignore */\nconst getFloat = (vector, index) => (vector.type.precision !== enum_1.Precision.HALF\n    ? getNumeric(vector, index)\n    : getFloat16(vector, index));\n/* istanbul ignore next */\n/** @ignore */\nconst getDate = (vector, index) => (vector.type.unit === enum_1.DateUnit.DAY\n    ? getDateDay(vector, index)\n    : getDateMillisecond(vector, index));\n/** @ignore */\nconst getTimestampSecond = ({ values }, index) => 1000 * epochMillisecondsLongToMs(values, index * 2);\n/** @ignore */\nconst getTimestampMillisecond = ({ values }, index) => epochMillisecondsLongToMs(values, index * 2);\n/** @ignore */\nconst getTimestampMicrosecond = ({ values }, index) => epochMicrosecondsLongToMs(values, index * 2);\n/** @ignore */\nconst getTimestampNanosecond = ({ values }, index) => epochNanosecondsLongToMs(values, index * 2);\n/* istanbul ignore next */\n/** @ignore */\nconst getTimestamp = (vector, index) => {\n    switch (vector.type.unit) {\n        case enum_1.TimeUnit.SECOND: return getTimestampSecond(vector, index);\n        case enum_1.TimeUnit.MILLISECOND: return getTimestampMillisecond(vector, index);\n        case enum_1.TimeUnit.MICROSECOND: return getTimestampMicrosecond(vector, index);\n        case enum_1.TimeUnit.NANOSECOND: return getTimestampNanosecond(vector, index);\n    }\n};\n/** @ignore */\nconst getTimeSecond = ({ values, stride }, index) => values[stride * index];\n/** @ignore */\nconst getTimeMillisecond = ({ values, stride }, index) => values[stride * index];\n/** @ignore */\nconst getTimeMicrosecond = ({ values }, index) => bn_1.BN.signed(values.subarray(2 * index, 2 * (index + 1)));\n/** @ignore */\nconst getTimeNanosecond = ({ values }, index) => bn_1.BN.signed(values.subarray(2 * index, 2 * (index + 1)));\n/* istanbul ignore next */\n/** @ignore */\nconst getTime = (vector, index) => {\n    switch (vector.type.unit) {\n        case enum_1.TimeUnit.SECOND: return getTimeSecond(vector, index);\n        case enum_1.TimeUnit.MILLISECOND: return getTimeMillisecond(vector, index);\n        case enum_1.TimeUnit.MICROSECOND: return getTimeMicrosecond(vector, index);\n        case enum_1.TimeUnit.NANOSECOND: return getTimeNanosecond(vector, index);\n    }\n};\n/** @ignore */\nconst getDecimal = ({ values }, index) => bn_1.BN.decimal(values.subarray(4 * index, 4 * (index + 1)));\n/** @ignore */\nconst getList = (vector, index) => {\n    const child = vector.getChildAt(0), { valueOffsets, stride } = vector;\n    return child.slice(valueOffsets[index * stride], valueOffsets[(index * stride) + 1]);\n};\n/** @ignore */\nconst getMap = (vector, index) => {\n    return vector.bind(index);\n};\n/** @ignore */\nconst getStruct = (vector, index) => {\n    return vector.bind(index);\n};\n/* istanbul ignore next */\n/** @ignore */\nconst getUnion = (vector, index) => {\n    return vector.type.mode === enum_1.UnionMode.Dense ?\n        getDenseUnion(vector, index) :\n        getSparseUnion(vector, index);\n};\n/** @ignore */\nconst getDenseUnion = (vector, index) => {\n    const childIndex = vector.typeIdToChildIndex[vector.typeIds[index]];\n    const child = vector.getChildAt(childIndex);\n    return child ? child.get(vector.valueOffsets[index]) : null;\n};\n/** @ignore */\nconst getSparseUnion = (vector, index) => {\n    const childIndex = vector.typeIdToChildIndex[vector.typeIds[index]];\n    const child = vector.getChildAt(childIndex);\n    return child ? child.get(index) : null;\n};\n/** @ignore */\nconst getDictionary = (vector, index) => {\n    return vector.getValue(vector.getKey(index));\n};\n/* istanbul ignore next */\n/** @ignore */\nconst getInterval = (vector, index) => (vector.type.unit === enum_1.IntervalUnit.DAY_TIME)\n    ? getIntervalDayTime(vector, index)\n    : getIntervalYearMonth(vector, index);\n/** @ignore */\nconst getIntervalDayTime = ({ values }, index) => values.subarray(2 * index, 2 * (index + 1));\n/** @ignore */\nconst getIntervalYearMonth = ({ values }, index) => {\n    const interval = values[index];\n    const int32s = new Int32Array(2);\n    int32s[0] = interval / 12 | 0; /* years */\n    int32s[1] = interval % 12 | 0; /* months */\n    return int32s;\n};\n/** @ignore */\nconst getFixedSizeList = (vector, index) => {\n    const child = vector.getChildAt(0), { stride } = vector;\n    return child.slice(index * stride, (index + 1) * stride);\n};\nGetVisitor.prototype.visitNull = getNull;\nGetVisitor.prototype.visitBool = getBool;\nGetVisitor.prototype.visitInt = getInt;\nGetVisitor.prototype.visitInt8 = getNumeric;\nGetVisitor.prototype.visitInt16 = getNumeric;\nGetVisitor.prototype.visitInt32 = getNumeric;\nGetVisitor.prototype.visitInt64 = getBigInts;\nGetVisitor.prototype.visitUint8 = getNumeric;\nGetVisitor.prototype.visitUint16 = getNumeric;\nGetVisitor.prototype.visitUint32 = getNumeric;\nGetVisitor.prototype.visitUint64 = getBigInts;\nGetVisitor.prototype.visitFloat = getFloat;\nGetVisitor.prototype.visitFloat16 = getFloat16;\nGetVisitor.prototype.visitFloat32 = getNumeric;\nGetVisitor.prototype.visitFloat64 = getNumeric;\nGetVisitor.prototype.visitUtf8 = getUtf8;\nGetVisitor.prototype.visitBinary = getBinary;\nGetVisitor.prototype.visitFixedSizeBinary = getFixedSizeBinary;\nGetVisitor.prototype.visitDate = getDate;\nGetVisitor.prototype.visitDateDay = getDateDay;\nGetVisitor.prototype.visitDateMillisecond = getDateMillisecond;\nGetVisitor.prototype.visitTimestamp = getTimestamp;\nGetVisitor.prototype.visitTimestampSecond = getTimestampSecond;\nGetVisitor.prototype.visitTimestampMillisecond = getTimestampMillisecond;\nGetVisitor.prototype.visitTimestampMicrosecond = getTimestampMicrosecond;\nGetVisitor.prototype.visitTimestampNanosecond = getTimestampNanosecond;\nGetVisitor.prototype.visitTime = getTime;\nGetVisitor.prototype.visitTimeSecond = getTimeSecond;\nGetVisitor.prototype.visitTimeMillisecond = getTimeMillisecond;\nGetVisitor.prototype.visitTimeMicrosecond = getTimeMicrosecond;\nGetVisitor.prototype.visitTimeNanosecond = getTimeNanosecond;\nGetVisitor.prototype.visitDecimal = getDecimal;\nGetVisitor.prototype.visitList = getList;\nGetVisitor.prototype.visitStruct = getStruct;\nGetVisitor.prototype.visitUnion = getUnion;\nGetVisitor.prototype.visitDenseUnion = getDenseUnion;\nGetVisitor.prototype.visitSparseUnion = getSparseUnion;\nGetVisitor.prototype.visitDictionary = getDictionary;\nGetVisitor.prototype.visitInterval = getInterval;\nGetVisitor.prototype.visitIntervalDayTime = getIntervalDayTime;\nGetVisitor.prototype.visitIntervalYearMonth = getIntervalYearMonth;\nGetVisitor.prototype.visitFixedSizeList = getFixedSizeList;\nGetVisitor.prototype.visitMap = getMap;\n/** @ignore */\nexports.instance = new GetVisitor();\n\n//# sourceMappingURL=get.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst bit_1 = require(\"../util/bit\");\nconst vector_1 = require(\"../util/vector\");\n/** @ignore */\nclass IndexOfVisitor extends visitor_1.Visitor {\n}\nexports.IndexOfVisitor = IndexOfVisitor;\n/** @ignore */\nfunction nullIndexOf(vector, searchElement) {\n    // if you're looking for nulls and the vector isn't empty, we've got 'em!\n    return searchElement === null && vector.length > 0 ? 0 : -1;\n}\n/** @ignore */\nfunction indexOfNull(vector, fromIndex) {\n    const { nullBitmap } = vector;\n    if (!nullBitmap || vector.nullCount <= 0) {\n        return -1;\n    }\n    let i = 0;\n    for (const isValid of bit_1.iterateBits(nullBitmap, vector.data.offset + (fromIndex || 0), vector.length, nullBitmap, bit_1.getBool)) {\n        if (!isValid) {\n            return i;\n        }\n        ++i;\n    }\n    return -1;\n}\n/** @ignore */\nfunction indexOfValue(vector, searchElement, fromIndex) {\n    if (searchElement === undefined) {\n        return -1;\n    }\n    if (searchElement === null) {\n        return indexOfNull(vector, fromIndex);\n    }\n    const compare = vector_1.createElementComparator(searchElement);\n    for (let i = (fromIndex || 0) - 1, n = vector.length; ++i < n;) {\n        if (compare(vector.get(i))) {\n            return i;\n        }\n    }\n    return -1;\n}\n/** @ignore */\nfunction indexOfUnion(vector, searchElement, fromIndex) {\n    // Unions are special -- they do have a nullBitmap, but so can their children.\n    // If the searchElement is null, we don't know whether it came from the Union's\n    // bitmap or one of its childrens'. So we don't interrogate the Union's bitmap,\n    // since that will report the wrong index if a child has a null before the Union.\n    const compare = vector_1.createElementComparator(searchElement);\n    for (let i = (fromIndex || 0) - 1, n = vector.length; ++i < n;) {\n        if (compare(vector.get(i))) {\n            return i;\n        }\n    }\n    return -1;\n}\nIndexOfVisitor.prototype.visitNull = nullIndexOf;\nIndexOfVisitor.prototype.visitBool = indexOfValue;\nIndexOfVisitor.prototype.visitInt = indexOfValue;\nIndexOfVisitor.prototype.visitInt8 = indexOfValue;\nIndexOfVisitor.prototype.visitInt16 = indexOfValue;\nIndexOfVisitor.prototype.visitInt32 = indexOfValue;\nIndexOfVisitor.prototype.visitInt64 = indexOfValue;\nIndexOfVisitor.prototype.visitUint8 = indexOfValue;\nIndexOfVisitor.prototype.visitUint16 = indexOfValue;\nIndexOfVisitor.prototype.visitUint32 = indexOfValue;\nIndexOfVisitor.prototype.visitUint64 = indexOfValue;\nIndexOfVisitor.prototype.visitFloat = indexOfValue;\nIndexOfVisitor.prototype.visitFloat16 = indexOfValue;\nIndexOfVisitor.prototype.visitFloat32 = indexOfValue;\nIndexOfVisitor.prototype.visitFloat64 = indexOfValue;\nIndexOfVisitor.prototype.visitUtf8 = indexOfValue;\nIndexOfVisitor.prototype.visitBinary = indexOfValue;\nIndexOfVisitor.prototype.visitFixedSizeBinary = indexOfValue;\nIndexOfVisitor.prototype.visitDate = indexOfValue;\nIndexOfVisitor.prototype.visitDateDay = indexOfValue;\nIndexOfVisitor.prototype.visitDateMillisecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimestamp = indexOfValue;\nIndexOfVisitor.prototype.visitTimestampSecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimestampMillisecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimestampMicrosecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimestampNanosecond = indexOfValue;\nIndexOfVisitor.prototype.visitTime = indexOfValue;\nIndexOfVisitor.prototype.visitTimeSecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimeMillisecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimeMicrosecond = indexOfValue;\nIndexOfVisitor.prototype.visitTimeNanosecond = indexOfValue;\nIndexOfVisitor.prototype.visitDecimal = indexOfValue;\nIndexOfVisitor.prototype.visitList = indexOfValue;\nIndexOfVisitor.prototype.visitStruct = indexOfValue;\nIndexOfVisitor.prototype.visitUnion = indexOfValue;\nIndexOfVisitor.prototype.visitDenseUnion = indexOfUnion;\nIndexOfVisitor.prototype.visitSparseUnion = indexOfUnion;\nIndexOfVisitor.prototype.visitDictionary = indexOfValue;\nIndexOfVisitor.prototype.visitInterval = indexOfValue;\nIndexOfVisitor.prototype.visitIntervalDayTime = indexOfValue;\nIndexOfVisitor.prototype.visitIntervalYearMonth = indexOfValue;\nIndexOfVisitor.prototype.visitFixedSizeList = indexOfValue;\nIndexOfVisitor.prototype.visitMap = indexOfValue;\n/** @ignore */\nexports.instance = new IndexOfVisitor();\n\n//# sourceMappingURL=indexof.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst enum_1 = require(\"../enum\");\nconst visitor_1 = require(\"../visitor\");\nconst bit_1 = require(\"../util/bit\");\nconst get_1 = require(\"./get\");\n/** @ignore */\nclass IteratorVisitor extends visitor_1.Visitor {\n}\nexports.IteratorVisitor = IteratorVisitor;\n/** @ignore */\nfunction nullableIterator(vector) {\n    const getFn = get_1.instance.getVisitFn(vector);\n    return bit_1.iterateBits(vector.nullBitmap, vector.offset, vector.length, vector, (vec, idx, nullByte, nullBit) => ((nullByte & 1 << nullBit) !== 0) ? getFn(vec, idx) : null);\n}\n/** @ignore */\nfunction vectorIterator(vector) {\n    // If nullable, iterate manually\n    if (vector.nullCount > 0) {\n        return nullableIterator(vector);\n    }\n    const { type, typeId, length } = vector;\n    // Fast case, defer to native iterators if possible\n    if (vector.stride === 1 && ((typeId === enum_1.Type.Timestamp) ||\n        (typeId === enum_1.Type.Int && type.bitWidth !== 64) ||\n        (typeId === enum_1.Type.Time && type.bitWidth !== 64) ||\n        (typeId === enum_1.Type.Float && type.precision > 0 /* Precision.HALF */))) {\n        return vector.values.subarray(0, length)[Symbol.iterator]();\n    }\n    // Otherwise, iterate manually\n    return (function* (getFn) {\n        for (let index = -1; ++index < length;) {\n            yield getFn(vector, index);\n        }\n    })(get_1.instance.getVisitFn(vector));\n}\nIteratorVisitor.prototype.visitNull = vectorIterator;\nIteratorVisitor.prototype.visitBool = vectorIterator;\nIteratorVisitor.prototype.visitInt = vectorIterator;\nIteratorVisitor.prototype.visitInt8 = vectorIterator;\nIteratorVisitor.prototype.visitInt16 = vectorIterator;\nIteratorVisitor.prototype.visitInt32 = vectorIterator;\nIteratorVisitor.prototype.visitInt64 = vectorIterator;\nIteratorVisitor.prototype.visitUint8 = vectorIterator;\nIteratorVisitor.prototype.visitUint16 = vectorIterator;\nIteratorVisitor.prototype.visitUint32 = vectorIterator;\nIteratorVisitor.prototype.visitUint64 = vectorIterator;\nIteratorVisitor.prototype.visitFloat = vectorIterator;\nIteratorVisitor.prototype.visitFloat16 = vectorIterator;\nIteratorVisitor.prototype.visitFloat32 = vectorIterator;\nIteratorVisitor.prototype.visitFloat64 = vectorIterator;\nIteratorVisitor.prototype.visitUtf8 = vectorIterator;\nIteratorVisitor.prototype.visitBinary = vectorIterator;\nIteratorVisitor.prototype.visitFixedSizeBinary = vectorIterator;\nIteratorVisitor.prototype.visitDate = vectorIterator;\nIteratorVisitor.prototype.visitDateDay = vectorIterator;\nIteratorVisitor.prototype.visitDateMillisecond = vectorIterator;\nIteratorVisitor.prototype.visitTimestamp = vectorIterator;\nIteratorVisitor.prototype.visitTimestampSecond = vectorIterator;\nIteratorVisitor.prototype.visitTimestampMillisecond = vectorIterator;\nIteratorVisitor.prototype.visitTimestampMicrosecond = vectorIterator;\nIteratorVisitor.prototype.visitTimestampNanosecond = vectorIterator;\nIteratorVisitor.prototype.visitTime = vectorIterator;\nIteratorVisitor.prototype.visitTimeSecond = vectorIterator;\nIteratorVisitor.prototype.visitTimeMillisecond = vectorIterator;\nIteratorVisitor.prototype.visitTimeMicrosecond = vectorIterator;\nIteratorVisitor.prototype.visitTimeNanosecond = vectorIterator;\nIteratorVisitor.prototype.visitDecimal = vectorIterator;\nIteratorVisitor.prototype.visitList = vectorIterator;\nIteratorVisitor.prototype.visitStruct = vectorIterator;\nIteratorVisitor.prototype.visitUnion = vectorIterator;\nIteratorVisitor.prototype.visitDenseUnion = vectorIterator;\nIteratorVisitor.prototype.visitSparseUnion = vectorIterator;\nIteratorVisitor.prototype.visitDictionary = vectorIterator;\nIteratorVisitor.prototype.visitInterval = vectorIterator;\nIteratorVisitor.prototype.visitIntervalDayTime = vectorIterator;\nIteratorVisitor.prototype.visitIntervalYearMonth = vectorIterator;\nIteratorVisitor.prototype.visitFixedSizeList = vectorIterator;\nIteratorVisitor.prototype.visitMap = vectorIterator;\n/** @ignore */\nexports.instance = new IteratorVisitor();\n\n//# sourceMappingURL=iterator.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst enum_1 = require(\"../enum\");\n/** @ignore */\nclass JSONTypeAssembler extends visitor_1.Visitor {\n    visit(node) {\n        return node == null ? undefined : super.visit(node);\n    }\n    visitNull({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitInt({ typeId, bitWidth, isSigned }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'bitWidth': bitWidth, 'isSigned': isSigned };\n    }\n    visitFloat({ typeId, precision }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'precision': enum_1.Precision[precision] };\n    }\n    visitBinary({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitBool({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitUtf8({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitDecimal({ typeId, scale, precision }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'scale': scale, 'precision': precision };\n    }\n    visitDate({ typeId, unit }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'unit': enum_1.DateUnit[unit] };\n    }\n    visitTime({ typeId, unit, bitWidth }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'unit': enum_1.TimeUnit[unit], bitWidth };\n    }\n    visitTimestamp({ typeId, timezone, unit }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'unit': enum_1.TimeUnit[unit], timezone };\n    }\n    visitInterval({ typeId, unit }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'unit': enum_1.IntervalUnit[unit] };\n    }\n    visitList({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitStruct({ typeId }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase() };\n    }\n    visitUnion({ typeId, mode, typeIds }) {\n        return {\n            'name': enum_1.ArrowType[typeId].toLowerCase(),\n            'mode': enum_1.UnionMode[mode],\n            'typeIds': [...typeIds]\n        };\n    }\n    visitDictionary(node) {\n        return this.visit(node.dictionary);\n    }\n    visitFixedSizeBinary({ typeId, byteWidth }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'byteWidth': byteWidth };\n    }\n    visitFixedSizeList({ typeId, listSize }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'listSize': listSize };\n    }\n    visitMap({ typeId, keysSorted }) {\n        return { 'name': enum_1.ArrowType[typeId].toLowerCase(), 'keysSorted': keysSorted };\n    }\n}\nexports.JSONTypeAssembler = JSONTypeAssembler;\n\n//# sourceMappingURL=jsontypeassembler.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst bn_1 = require(\"../util/bn\");\nconst column_1 = require(\"../column\");\nconst vector_1 = require(\"../vector\");\nconst visitor_1 = require(\"../visitor\");\nconst enum_1 = require(\"../enum\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst enum_2 = require(\"../enum\");\nconst bit_1 = require(\"../util/bit\");\nconst args_1 = require(\"../util/args\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass JSONVectorAssembler extends visitor_1.Visitor {\n    /** @nocollapse */\n    static assemble(...args) {\n        return new JSONVectorAssembler().visitMany(args_1.selectColumnChildrenArgs(recordbatch_1.RecordBatch, args));\n    }\n    visit(column) {\n        const { data, name, length } = column;\n        const { offset, nullCount, nullBitmap } = data;\n        const type = type_1.DataType.isDictionary(column.type) ? column.type.indices : column.type;\n        const buffers = Object.assign([], data.buffers, { [enum_1.BufferType.VALIDITY]: undefined });\n        return {\n            'name': name,\n            'count': length,\n            'VALIDITY': type_1.DataType.isNull(type) ? undefined\n                : nullCount <= 0 ? Array.from({ length }, () => 1)\n                    : [...bit_1.iterateBits(nullBitmap, offset, length, null, bit_1.getBit)],\n            ...super.visit(vector_1.Vector.new(data.clone(type, offset, length, 0, buffers)))\n        };\n    }\n    visitNull() { return {}; }\n    visitBool({ values, offset, length }) {\n        return { 'DATA': [...bit_1.iterateBits(values, offset, length, null, bit_1.getBool)] };\n    }\n    visitInt(vector) {\n        return {\n            'DATA': vector.type.bitWidth < 64\n                ? [...vector.values]\n                : [...bigNumsToStrings(vector.values, 2)]\n        };\n    }\n    visitFloat(vector) {\n        return { 'DATA': [...vector.values] };\n    }\n    visitUtf8(vector) {\n        return { 'DATA': [...vector], 'OFFSET': [...vector.valueOffsets] };\n    }\n    visitBinary(vector) {\n        return { 'DATA': [...binaryToString(vector)], OFFSET: [...vector.valueOffsets] };\n    }\n    visitFixedSizeBinary(vector) {\n        return { 'DATA': [...binaryToString(vector)] };\n    }\n    visitDate(vector) {\n        return {\n            'DATA': vector.type.unit === enum_2.DateUnit.DAY\n                ? [...vector.values]\n                : [...bigNumsToStrings(vector.values, 2)]\n        };\n    }\n    visitTimestamp(vector) {\n        return { 'DATA': [...bigNumsToStrings(vector.values, 2)] };\n    }\n    visitTime(vector) {\n        return {\n            'DATA': vector.type.unit < enum_2.TimeUnit.MICROSECOND\n                ? [...vector.values]\n                : [...bigNumsToStrings(vector.values, 2)]\n        };\n    }\n    visitDecimal(vector) {\n        return { 'DATA': [...bigNumsToStrings(vector.values, 4)] };\n    }\n    visitList(vector) {\n        return {\n            'OFFSET': [...vector.valueOffsets],\n            'children': vector.type.children.map((f, i) => this.visit(new column_1.Column(f, [vector.getChildAt(i)])))\n        };\n    }\n    visitStruct(vector) {\n        return {\n            'children': vector.type.children.map((f, i) => this.visit(new column_1.Column(f, [vector.getChildAt(i)])))\n        };\n    }\n    visitUnion(vector) {\n        return {\n            'TYPE': [...vector.typeIds],\n            'OFFSET': vector.type.mode === enum_2.UnionMode.Dense ? [...vector.valueOffsets] : undefined,\n            'children': vector.type.children.map((f, i) => this.visit(new column_1.Column(f, [vector.getChildAt(i)])))\n        };\n    }\n    visitInterval(vector) {\n        return { 'DATA': [...vector.values] };\n    }\n    visitFixedSizeList(vector) {\n        return {\n            'children': vector.type.children.map((f, i) => this.visit(new column_1.Column(f, [vector.getChildAt(i)])))\n        };\n    }\n    visitMap(vector) {\n        return {\n            'OFFSET': [...vector.valueOffsets],\n            'children': vector.type.children.map((f, i) => this.visit(new column_1.Column(f, [vector.getChildAt(i)])))\n        };\n    }\n}\nexports.JSONVectorAssembler = JSONVectorAssembler;\n/** @ignore */\nfunction* binaryToString(vector) {\n    for (const octets of vector) {\n        yield octets.reduce((str, byte) => {\n            return `${str}${('0' + (byte & 0xFF).toString(16)).slice(-2)}`;\n        }, '').toUpperCase();\n    }\n}\n/** @ignore */\nfunction* bigNumsToStrings(values, stride) {\n    for (let i = -1, n = values.length / stride; ++i < n;) {\n        yield `${bn_1.BN.new(values.subarray((i + 0) * stride, (i + 1) * stride), false)}`;\n    }\n}\n\n//# sourceMappingURL=jsonvectorassembler.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst vector_1 = require(\"../vector\");\nconst visitor_1 = require(\"../visitor\");\nconst utf8_1 = require(\"../util/utf8\");\nconst math_1 = require(\"../util/math\");\nconst buffer_1 = require(\"../util/buffer\");\nconst enum_1 = require(\"../enum\");\n/** @ignore */\nclass SetVisitor extends visitor_1.Visitor {\n}\nexports.SetVisitor = SetVisitor;\n/** @ignore */\nconst setEpochMsToDays = (data, index, epochMs) => { data[index] = (epochMs / 86400000) | 0; };\n/** @ignore */\nconst setEpochMsToMillisecondsLong = (data, index, epochMs) => {\n    data[index] = (epochMs % 4294967296) | 0;\n    data[index + 1] = (epochMs / 4294967296) | 0;\n};\n/** @ignore */\nconst setEpochMsToMicrosecondsLong = (data, index, epochMs) => {\n    data[index] = ((epochMs * 1000) % 4294967296) | 0;\n    data[index + 1] = ((epochMs * 1000) / 4294967296) | 0;\n};\n/** @ignore */\nconst setEpochMsToNanosecondsLong = (data, index, epochMs) => {\n    data[index] = ((epochMs * 1000000) % 4294967296) | 0;\n    data[index + 1] = ((epochMs * 1000000) / 4294967296) | 0;\n};\n/** @ignore */\nconst setVariableWidthBytes = (values, valueOffsets, index, value) => {\n    const { [index]: x, [index + 1]: y } = valueOffsets;\n    if (x != null && y != null) {\n        values.set(value.subarray(0, y - x), x);\n    }\n};\n/** @ignore */\nconst setBool = ({ offset, values }, index, val) => {\n    const idx = offset + index;\n    val ? (values[idx >> 3] |= (1 << (idx % 8))) // true\n        : (values[idx >> 3] &= ~(1 << (idx % 8))); // false\n};\n/** @ignore */\nconst setDateDay = ({ values }, index, value) => { setEpochMsToDays(values, index, value.valueOf()); };\n/** @ignore */\nconst setDateMillisecond = ({ values }, index, value) => { setEpochMsToMillisecondsLong(values, index * 2, value.valueOf()); };\n/** @ignore */\nconst setNumeric = ({ stride, values }, index, value) => { values[stride * index] = value; };\n/** @ignore */\nconst setFloat16 = ({ stride, values }, index, value) => { values[stride * index] = math_1.float64ToUint16(value); };\n/** @ignore */\nconst setNumericX2 = (vector, index, value) => {\n    switch (typeof value) {\n        case 'bigint':\n            vector.values64[index] = value;\n            break;\n        case 'number':\n            vector.values[index * vector.stride] = value;\n            break;\n        default:\n            const val = value;\n            const { stride, ArrayType } = vector;\n            const long = buffer_1.toArrayBufferView(ArrayType, val);\n            vector.values.set(long.subarray(0, stride), stride * index);\n    }\n};\n/** @ignore */\nconst setFixedSizeBinary = ({ stride, values }, index, value) => { values.set(value.subarray(0, stride), stride * index); };\n/** @ignore */\nconst setBinary = ({ values, valueOffsets }, index, value) => setVariableWidthBytes(values, valueOffsets, index, value);\n/** @ignore */\nconst setUtf8 = ({ values, valueOffsets }, index, value) => {\n    setVariableWidthBytes(values, valueOffsets, index, utf8_1.encodeUtf8(value));\n};\n/* istanbul ignore next */\n/** @ignore */\nconst setInt = (vector, index, value) => {\n    vector.type.bitWidth < 64\n        ? setNumeric(vector, index, value)\n        : setNumericX2(vector, index, value);\n};\n/* istanbul ignore next */\n/** @ignore */\nconst setFloat = (vector, index, value) => {\n    vector.type.precision !== enum_1.Precision.HALF\n        ? setNumeric(vector, index, value)\n        : setFloat16(vector, index, value);\n};\n/* istanbul ignore next */\nconst setDate = (vector, index, value) => {\n    vector.type.unit === enum_1.DateUnit.DAY\n        ? setDateDay(vector, index, value)\n        : setDateMillisecond(vector, index, value);\n};\n/** @ignore */\nconst setTimestampSecond = ({ values }, index, value) => setEpochMsToMillisecondsLong(values, index * 2, value / 1000);\n/** @ignore */\nconst setTimestampMillisecond = ({ values }, index, value) => setEpochMsToMillisecondsLong(values, index * 2, value);\n/** @ignore */\nconst setTimestampMicrosecond = ({ values }, index, value) => setEpochMsToMicrosecondsLong(values, index * 2, value);\n/** @ignore */\nconst setTimestampNanosecond = ({ values }, index, value) => setEpochMsToNanosecondsLong(values, index * 2, value);\n/* istanbul ignore next */\n/** @ignore */\nconst setTimestamp = (vector, index, value) => {\n    switch (vector.type.unit) {\n        case enum_1.TimeUnit.SECOND: return setTimestampSecond(vector, index, value);\n        case enum_1.TimeUnit.MILLISECOND: return setTimestampMillisecond(vector, index, value);\n        case enum_1.TimeUnit.MICROSECOND: return setTimestampMicrosecond(vector, index, value);\n        case enum_1.TimeUnit.NANOSECOND: return setTimestampNanosecond(vector, index, value);\n    }\n};\n/** @ignore */\nconst setTimeSecond = ({ values, stride }, index, value) => { values[stride * index] = value; };\n/** @ignore */\nconst setTimeMillisecond = ({ values, stride }, index, value) => { values[stride * index] = value; };\n/** @ignore */\nconst setTimeMicrosecond = ({ values }, index, value) => { values.set(value.subarray(0, 2), 2 * index); };\n/** @ignore */\nconst setTimeNanosecond = ({ values }, index, value) => { values.set(value.subarray(0, 2), 2 * index); };\n/* istanbul ignore next */\n/** @ignore */\nconst setTime = (vector, index, value) => {\n    switch (vector.type.unit) {\n        case enum_1.TimeUnit.SECOND: return setTimeSecond(vector, index, value);\n        case enum_1.TimeUnit.MILLISECOND: return setTimeMillisecond(vector, index, value);\n        case enum_1.TimeUnit.MICROSECOND: return setTimeMicrosecond(vector, index, value);\n        case enum_1.TimeUnit.NANOSECOND: return setTimeNanosecond(vector, index, value);\n    }\n};\n/** @ignore */\nconst setDecimal = ({ values }, index, value) => { values.set(value.subarray(0, 4), 4 * index); };\n/** @ignore */\nconst setList = (vector, index, value) => {\n    const values = vector.getChildAt(0), valueOffsets = vector.valueOffsets;\n    for (let idx = -1, itr = valueOffsets[index], end = valueOffsets[index + 1]; itr < end;) {\n        values.set(itr++, value.get(++idx));\n    }\n};\n/** @ignore */\nconst setMap = (vector, index, value) => {\n    const values = vector.getChildAt(0), valueOffsets = vector.valueOffsets;\n    const entries = value instanceof Map ? [...value] : Object.entries(value);\n    for (let idx = -1, itr = valueOffsets[index], end = valueOffsets[index + 1]; itr < end;) {\n        values.set(itr++, entries[++idx]);\n    }\n};\n/** @ignore */ const _setStructArrayValue = (o, v) => (c, _, i) => c && c.set(o, v[i]);\n/** @ignore */ const _setStructVectorValue = (o, v) => (c, _, i) => c && c.set(o, v.get(i));\n/** @ignore */ const _setStructMapValue = (o, v) => (c, f, _) => c && c.set(o, v.get(f.name));\n/** @ignore */ const _setStructObjectValue = (o, v) => (c, f, _) => c && c.set(o, v[f.name]);\n/** @ignore */\nconst setStruct = (vector, index, value) => {\n    const setValue = value instanceof Map ? _setStructMapValue(index, value) :\n        value instanceof vector_1.Vector ? _setStructVectorValue(index, value) :\n            Array.isArray(value) ? _setStructArrayValue(index, value) :\n                _setStructObjectValue(index, value);\n    vector.type.children.forEach((f, i) => setValue(vector.getChildAt(i), f, i));\n};\n/* istanbul ignore next */\n/** @ignore */\nconst setUnion = (vector, index, value) => {\n    vector.type.mode === enum_1.UnionMode.Dense ?\n        setDenseUnion(vector, index, value) :\n        setSparseUnion(vector, index, value);\n};\n/** @ignore */\nconst setDenseUnion = (vector, index, value) => {\n    const childIndex = vector.typeIdToChildIndex[vector.typeIds[index]];\n    const child = vector.getChildAt(childIndex);\n    child && child.set(vector.valueOffsets[index], value);\n};\n/** @ignore */\nconst setSparseUnion = (vector, index, value) => {\n    const childIndex = vector.typeIdToChildIndex[vector.typeIds[index]];\n    const child = vector.getChildAt(childIndex);\n    child && child.set(index, value);\n};\n/** @ignore */\nconst setDictionary = (vector, index, value) => {\n    const key = vector.getKey(index);\n    if (key !== null) {\n        vector.setValue(key, value);\n    }\n};\n/* istanbul ignore next */\n/** @ignore */\nconst setIntervalValue = (vector, index, value) => {\n    (vector.type.unit === enum_1.IntervalUnit.DAY_TIME)\n        ? setIntervalDayTime(vector, index, value)\n        : setIntervalYearMonth(vector, index, value);\n};\n/** @ignore */\nconst setIntervalDayTime = ({ values }, index, value) => { values.set(value.subarray(0, 2), 2 * index); };\n/** @ignore */\nconst setIntervalYearMonth = ({ values }, index, value) => { values[index] = (value[0] * 12) + (value[1] % 12); };\n/** @ignore */\nconst setFixedSizeList = (vector, index, value) => {\n    const child = vector.getChildAt(0), { stride } = vector;\n    for (let idx = -1, offset = index * stride; ++idx < stride;) {\n        child.set(offset + idx, value.get(idx));\n    }\n};\nSetVisitor.prototype.visitBool = setBool;\nSetVisitor.prototype.visitInt = setInt;\nSetVisitor.prototype.visitInt8 = setNumeric;\nSetVisitor.prototype.visitInt16 = setNumeric;\nSetVisitor.prototype.visitInt32 = setNumeric;\nSetVisitor.prototype.visitInt64 = setNumericX2;\nSetVisitor.prototype.visitUint8 = setNumeric;\nSetVisitor.prototype.visitUint16 = setNumeric;\nSetVisitor.prototype.visitUint32 = setNumeric;\nSetVisitor.prototype.visitUint64 = setNumericX2;\nSetVisitor.prototype.visitFloat = setFloat;\nSetVisitor.prototype.visitFloat16 = setFloat16;\nSetVisitor.prototype.visitFloat32 = setNumeric;\nSetVisitor.prototype.visitFloat64 = setNumeric;\nSetVisitor.prototype.visitUtf8 = setUtf8;\nSetVisitor.prototype.visitBinary = setBinary;\nSetVisitor.prototype.visitFixedSizeBinary = setFixedSizeBinary;\nSetVisitor.prototype.visitDate = setDate;\nSetVisitor.prototype.visitDateDay = setDateDay;\nSetVisitor.prototype.visitDateMillisecond = setDateMillisecond;\nSetVisitor.prototype.visitTimestamp = setTimestamp;\nSetVisitor.prototype.visitTimestampSecond = setTimestampSecond;\nSetVisitor.prototype.visitTimestampMillisecond = setTimestampMillisecond;\nSetVisitor.prototype.visitTimestampMicrosecond = setTimestampMicrosecond;\nSetVisitor.prototype.visitTimestampNanosecond = setTimestampNanosecond;\nSetVisitor.prototype.visitTime = setTime;\nSetVisitor.prototype.visitTimeSecond = setTimeSecond;\nSetVisitor.prototype.visitTimeMillisecond = setTimeMillisecond;\nSetVisitor.prototype.visitTimeMicrosecond = setTimeMicrosecond;\nSetVisitor.prototype.visitTimeNanosecond = setTimeNanosecond;\nSetVisitor.prototype.visitDecimal = setDecimal;\nSetVisitor.prototype.visitList = setList;\nSetVisitor.prototype.visitStruct = setStruct;\nSetVisitor.prototype.visitUnion = setUnion;\nSetVisitor.prototype.visitDenseUnion = setDenseUnion;\nSetVisitor.prototype.visitSparseUnion = setSparseUnion;\nSetVisitor.prototype.visitDictionary = setDictionary;\nSetVisitor.prototype.visitInterval = setIntervalValue;\nSetVisitor.prototype.visitIntervalDayTime = setIntervalDayTime;\nSetVisitor.prototype.visitIntervalYearMonth = setIntervalYearMonth;\nSetVisitor.prototype.visitFixedSizeList = setFixedSizeList;\nSetVisitor.prototype.visitMap = setMap;\n/** @ignore */\nexports.instance = new SetVisitor();\n\n//# sourceMappingURL=set.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst enum_1 = require(\"../enum\");\nconst visitor_1 = require(\"../visitor\");\nconst iterator_1 = require(\"./iterator\");\n/** @ignore */\nclass ToArrayVisitor extends visitor_1.Visitor {\n}\nexports.ToArrayVisitor = ToArrayVisitor;\n/** @ignore */\nfunction arrayOfVector(vector) {\n    const { type, length, stride } = vector;\n    // Fast case, return subarray if possible\n    switch (type.typeId) {\n        case enum_1.Type.Int:\n        case enum_1.Type.Float:\n        case enum_1.Type.Decimal:\n        case enum_1.Type.Time:\n        case enum_1.Type.Timestamp:\n            return vector.values.subarray(0, length * stride);\n    }\n    // Otherwise if not primitive, slow copy\n    return [...iterator_1.instance.visit(vector)];\n}\nToArrayVisitor.prototype.visitNull = arrayOfVector;\nToArrayVisitor.prototype.visitBool = arrayOfVector;\nToArrayVisitor.prototype.visitInt = arrayOfVector;\nToArrayVisitor.prototype.visitInt8 = arrayOfVector;\nToArrayVisitor.prototype.visitInt16 = arrayOfVector;\nToArrayVisitor.prototype.visitInt32 = arrayOfVector;\nToArrayVisitor.prototype.visitInt64 = arrayOfVector;\nToArrayVisitor.prototype.visitUint8 = arrayOfVector;\nToArrayVisitor.prototype.visitUint16 = arrayOfVector;\nToArrayVisitor.prototype.visitUint32 = arrayOfVector;\nToArrayVisitor.prototype.visitUint64 = arrayOfVector;\nToArrayVisitor.prototype.visitFloat = arrayOfVector;\nToArrayVisitor.prototype.visitFloat16 = arrayOfVector;\nToArrayVisitor.prototype.visitFloat32 = arrayOfVector;\nToArrayVisitor.prototype.visitFloat64 = arrayOfVector;\nToArrayVisitor.prototype.visitUtf8 = arrayOfVector;\nToArrayVisitor.prototype.visitBinary = arrayOfVector;\nToArrayVisitor.prototype.visitFixedSizeBinary = arrayOfVector;\nToArrayVisitor.prototype.visitDate = arrayOfVector;\nToArrayVisitor.prototype.visitDateDay = arrayOfVector;\nToArrayVisitor.prototype.visitDateMillisecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimestamp = arrayOfVector;\nToArrayVisitor.prototype.visitTimestampSecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimestampMillisecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimestampMicrosecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimestampNanosecond = arrayOfVector;\nToArrayVisitor.prototype.visitTime = arrayOfVector;\nToArrayVisitor.prototype.visitTimeSecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimeMillisecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimeMicrosecond = arrayOfVector;\nToArrayVisitor.prototype.visitTimeNanosecond = arrayOfVector;\nToArrayVisitor.prototype.visitDecimal = arrayOfVector;\nToArrayVisitor.prototype.visitList = arrayOfVector;\nToArrayVisitor.prototype.visitStruct = arrayOfVector;\nToArrayVisitor.prototype.visitUnion = arrayOfVector;\nToArrayVisitor.prototype.visitDenseUnion = arrayOfVector;\nToArrayVisitor.prototype.visitSparseUnion = arrayOfVector;\nToArrayVisitor.prototype.visitDictionary = arrayOfVector;\nToArrayVisitor.prototype.visitInterval = arrayOfVector;\nToArrayVisitor.prototype.visitIntervalDayTime = arrayOfVector;\nToArrayVisitor.prototype.visitIntervalYearMonth = arrayOfVector;\nToArrayVisitor.prototype.visitFixedSizeList = arrayOfVector;\nToArrayVisitor.prototype.visitMap = arrayOfVector;\n/** @ignore */\nexports.instance = new ToArrayVisitor();\n\n//# sourceMappingURL=toarray.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst flatbuffers_1 = require(\"flatbuffers\");\nvar Long = flatbuffers_1.flatbuffers.Long;\nconst Schema_ = require(\"../fb/Schema\");\nconst visitor_1 = require(\"../visitor\");\nvar Null = Schema_.org.apache.arrow.flatbuf.Null;\nvar Int = Schema_.org.apache.arrow.flatbuf.Int;\nvar FloatingPoint = Schema_.org.apache.arrow.flatbuf.FloatingPoint;\nvar Binary = Schema_.org.apache.arrow.flatbuf.Binary;\nvar Bool = Schema_.org.apache.arrow.flatbuf.Bool;\nvar Utf8 = Schema_.org.apache.arrow.flatbuf.Utf8;\nvar Decimal = Schema_.org.apache.arrow.flatbuf.Decimal;\nvar Date = Schema_.org.apache.arrow.flatbuf.Date;\nvar Time = Schema_.org.apache.arrow.flatbuf.Time;\nvar Timestamp = Schema_.org.apache.arrow.flatbuf.Timestamp;\nvar Interval = Schema_.org.apache.arrow.flatbuf.Interval;\nvar List = Schema_.org.apache.arrow.flatbuf.List;\nvar Struct = Schema_.org.apache.arrow.flatbuf.Struct_;\nvar Union = Schema_.org.apache.arrow.flatbuf.Union;\nvar DictionaryEncoding = Schema_.org.apache.arrow.flatbuf.DictionaryEncoding;\nvar FixedSizeBinary = Schema_.org.apache.arrow.flatbuf.FixedSizeBinary;\nvar FixedSizeList = Schema_.org.apache.arrow.flatbuf.FixedSizeList;\nvar Map_ = Schema_.org.apache.arrow.flatbuf.Map;\n/** @ignore */\nclass TypeAssembler extends visitor_1.Visitor {\n    visit(node, builder) {\n        return (node == null || builder == null) ? undefined : super.visit(node, builder);\n    }\n    visitNull(_node, b) {\n        Null.startNull(b);\n        return Null.endNull(b);\n    }\n    visitInt(node, b) {\n        Int.startInt(b);\n        Int.addBitWidth(b, node.bitWidth);\n        Int.addIsSigned(b, node.isSigned);\n        return Int.endInt(b);\n    }\n    visitFloat(node, b) {\n        FloatingPoint.startFloatingPoint(b);\n        FloatingPoint.addPrecision(b, node.precision);\n        return FloatingPoint.endFloatingPoint(b);\n    }\n    visitBinary(_node, b) {\n        Binary.startBinary(b);\n        return Binary.endBinary(b);\n    }\n    visitBool(_node, b) {\n        Bool.startBool(b);\n        return Bool.endBool(b);\n    }\n    visitUtf8(_node, b) {\n        Utf8.startUtf8(b);\n        return Utf8.endUtf8(b);\n    }\n    visitDecimal(node, b) {\n        Decimal.startDecimal(b);\n        Decimal.addScale(b, node.scale);\n        Decimal.addPrecision(b, node.precision);\n        return Decimal.endDecimal(b);\n    }\n    visitDate(node, b) {\n        Date.startDate(b);\n        Date.addUnit(b, node.unit);\n        return Date.endDate(b);\n    }\n    visitTime(node, b) {\n        Time.startTime(b);\n        Time.addUnit(b, node.unit);\n        Time.addBitWidth(b, node.bitWidth);\n        return Time.endTime(b);\n    }\n    visitTimestamp(node, b) {\n        const timezone = (node.timezone && b.createString(node.timezone)) || undefined;\n        Timestamp.startTimestamp(b);\n        Timestamp.addUnit(b, node.unit);\n        if (timezone !== undefined) {\n            Timestamp.addTimezone(b, timezone);\n        }\n        return Timestamp.endTimestamp(b);\n    }\n    visitInterval(node, b) {\n        Interval.startInterval(b);\n        Interval.addUnit(b, node.unit);\n        return Interval.endInterval(b);\n    }\n    visitList(_node, b) {\n        List.startList(b);\n        return List.endList(b);\n    }\n    visitStruct(_node, b) {\n        Struct.startStruct_(b);\n        return Struct.endStruct_(b);\n    }\n    visitUnion(node, b) {\n        Union.startTypeIdsVector(b, node.typeIds.length);\n        const typeIds = Union.createTypeIdsVector(b, node.typeIds);\n        Union.startUnion(b);\n        Union.addMode(b, node.mode);\n        Union.addTypeIds(b, typeIds);\n        return Union.endUnion(b);\n    }\n    visitDictionary(node, b) {\n        const indexType = this.visit(node.indices, b);\n        DictionaryEncoding.startDictionaryEncoding(b);\n        DictionaryEncoding.addId(b, new Long(node.id, 0));\n        DictionaryEncoding.addIsOrdered(b, node.isOrdered);\n        if (indexType !== undefined) {\n            DictionaryEncoding.addIndexType(b, indexType);\n        }\n        return DictionaryEncoding.endDictionaryEncoding(b);\n    }\n    visitFixedSizeBinary(node, b) {\n        FixedSizeBinary.startFixedSizeBinary(b);\n        FixedSizeBinary.addByteWidth(b, node.byteWidth);\n        return FixedSizeBinary.endFixedSizeBinary(b);\n    }\n    visitFixedSizeList(node, b) {\n        FixedSizeList.startFixedSizeList(b);\n        FixedSizeList.addListSize(b, node.listSize);\n        return FixedSizeList.endFixedSizeList(b);\n    }\n    visitMap(node, b) {\n        Map_.startMap(b);\n        Map_.addKeysSorted(b, node.keysSorted);\n        return Map_.endMap(b);\n    }\n}\nexports.TypeAssembler = TypeAssembler;\n/** @ignore */\nexports.instance = new TypeAssembler();\n\n//# sourceMappingURL=typeassembler.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\n/** @ignore */\nclass TypeComparator extends visitor_1.Visitor {\n    compareSchemas(schema, other) {\n        return (schema === other) || (other instanceof schema.constructor &&\n            exports.instance.compareFields(schema.fields, other.fields));\n    }\n    compareFields(fields, others) {\n        return (fields === others) || (Array.isArray(fields) &&\n            Array.isArray(others) &&\n            fields.length === others.length &&\n            fields.every((f, i) => exports.instance.compareField(f, others[i])));\n    }\n    compareField(field, other) {\n        return (field === other) || (other instanceof field.constructor &&\n            field.name === other.name &&\n            field.nullable === other.nullable &&\n            exports.instance.visit(field.type, other.type));\n    }\n}\nexports.TypeComparator = TypeComparator;\nfunction compareConstructor(type, other) {\n    return other instanceof type.constructor;\n}\nfunction compareAny(type, other) {\n    return (type === other) || compareConstructor(type, other);\n}\nfunction compareInt(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.bitWidth === other.bitWidth &&\n        type.isSigned === other.isSigned);\n}\nfunction compareFloat(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.precision === other.precision);\n}\nfunction compareFixedSizeBinary(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.byteWidth === other.byteWidth);\n}\nfunction compareDate(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.unit === other.unit);\n}\nfunction compareTimestamp(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.unit === other.unit &&\n        type.timezone === other.timezone);\n}\nfunction compareTime(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.unit === other.unit &&\n        type.bitWidth === other.bitWidth);\n}\nfunction compareList(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.children.length === other.children.length &&\n        exports.instance.compareFields(type.children, other.children));\n}\nfunction compareStruct(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.children.length === other.children.length &&\n        exports.instance.compareFields(type.children, other.children));\n}\nfunction compareUnion(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.mode === other.mode &&\n        type.typeIds.every((x, i) => x === other.typeIds[i]) &&\n        exports.instance.compareFields(type.children, other.children));\n}\nfunction compareDictionary(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.id === other.id &&\n        type.isOrdered === other.isOrdered &&\n        exports.instance.visit(type.indices, other.indices) &&\n        exports.instance.visit(type.dictionary, other.dictionary));\n}\nfunction compareInterval(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.unit === other.unit);\n}\nfunction compareFixedSizeList(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.listSize === other.listSize &&\n        type.children.length === other.children.length &&\n        exports.instance.compareFields(type.children, other.children));\n}\nfunction compareMap(type, other) {\n    return (type === other) || (compareConstructor(type, other) &&\n        type.keysSorted === other.keysSorted &&\n        type.children.length === other.children.length &&\n        exports.instance.compareFields(type.children, other.children));\n}\nTypeComparator.prototype.visitNull = compareAny;\nTypeComparator.prototype.visitBool = compareAny;\nTypeComparator.prototype.visitInt = compareInt;\nTypeComparator.prototype.visitInt8 = compareInt;\nTypeComparator.prototype.visitInt16 = compareInt;\nTypeComparator.prototype.visitInt32 = compareInt;\nTypeComparator.prototype.visitInt64 = compareInt;\nTypeComparator.prototype.visitUint8 = compareInt;\nTypeComparator.prototype.visitUint16 = compareInt;\nTypeComparator.prototype.visitUint32 = compareInt;\nTypeComparator.prototype.visitUint64 = compareInt;\nTypeComparator.prototype.visitFloat = compareFloat;\nTypeComparator.prototype.visitFloat16 = compareFloat;\nTypeComparator.prototype.visitFloat32 = compareFloat;\nTypeComparator.prototype.visitFloat64 = compareFloat;\nTypeComparator.prototype.visitUtf8 = compareAny;\nTypeComparator.prototype.visitBinary = compareAny;\nTypeComparator.prototype.visitFixedSizeBinary = compareFixedSizeBinary;\nTypeComparator.prototype.visitDate = compareDate;\nTypeComparator.prototype.visitDateDay = compareDate;\nTypeComparator.prototype.visitDateMillisecond = compareDate;\nTypeComparator.prototype.visitTimestamp = compareTimestamp;\nTypeComparator.prototype.visitTimestampSecond = compareTimestamp;\nTypeComparator.prototype.visitTimestampMillisecond = compareTimestamp;\nTypeComparator.prototype.visitTimestampMicrosecond = compareTimestamp;\nTypeComparator.prototype.visitTimestampNanosecond = compareTimestamp;\nTypeComparator.prototype.visitTime = compareTime;\nTypeComparator.prototype.visitTimeSecond = compareTime;\nTypeComparator.prototype.visitTimeMillisecond = compareTime;\nTypeComparator.prototype.visitTimeMicrosecond = compareTime;\nTypeComparator.prototype.visitTimeNanosecond = compareTime;\nTypeComparator.prototype.visitDecimal = compareAny;\nTypeComparator.prototype.visitList = compareList;\nTypeComparator.prototype.visitStruct = compareStruct;\nTypeComparator.prototype.visitUnion = compareUnion;\nTypeComparator.prototype.visitDenseUnion = compareUnion;\nTypeComparator.prototype.visitSparseUnion = compareUnion;\nTypeComparator.prototype.visitDictionary = compareDictionary;\nTypeComparator.prototype.visitInterval = compareInterval;\nTypeComparator.prototype.visitIntervalDayTime = compareInterval;\nTypeComparator.prototype.visitIntervalYearMonth = compareInterval;\nTypeComparator.prototype.visitFixedSizeList = compareFixedSizeList;\nTypeComparator.prototype.visitMap = compareMap;\n/** @ignore */\nexports.instance = new TypeComparator();\n\n//# sourceMappingURL=typecomparator.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst enum_1 = require(\"../enum\");\nconst recordbatch_1 = require(\"../recordbatch\");\nconst buffer_1 = require(\"../util/buffer\");\nconst bit_1 = require(\"../util/bit\");\nconst args_1 = require(\"../util/args\");\nconst message_1 = require(\"../ipc/metadata/message\");\nconst type_1 = require(\"../type\");\n/** @ignore */\nclass VectorAssembler extends visitor_1.Visitor {\n    constructor() {\n        super();\n        this._byteLength = 0;\n        this._nodes = [];\n        this._buffers = [];\n        this._bufferRegions = [];\n    }\n    /** @nocollapse */\n    static assemble(...args) {\n        const assembler = new VectorAssembler();\n        const vectorChildren = args_1.selectVectorChildrenArgs(recordbatch_1.RecordBatch, args);\n        const [assembleResult = assembler] = assembler.visitMany(vectorChildren);\n        return assembleResult;\n    }\n    visit(vector) {\n        if (!type_1.DataType.isDictionary(vector.type)) {\n            const { data, length, nullCount } = vector;\n            if (length > 2147483647) {\n                /* istanbul ignore next */\n                throw new RangeError('Cannot write arrays larger than 2^31 - 1 in length');\n            }\n            if (!type_1.DataType.isNull(vector.type)) {\n                addBuffer.call(this, nullCount <= 0\n                    ? new Uint8Array(0) // placeholder validity buffer\n                    : bit_1.truncateBitmap(data.offset, length, data.nullBitmap));\n            }\n            this.nodes.push(new message_1.FieldNode(length, nullCount));\n        }\n        return super.visit(vector);\n    }\n    visitNull(_nullV) {\n        return this;\n    }\n    visitDictionary(vector) {\n        // Assemble the indices here, Dictionary assembled separately.\n        return this.visit(vector.indices);\n    }\n    get nodes() { return this._nodes; }\n    get buffers() { return this._buffers; }\n    get byteLength() { return this._byteLength; }\n    get bufferRegions() { return this._bufferRegions; }\n}\nexports.VectorAssembler = VectorAssembler;\n/** @ignore */\nfunction addBuffer(values) {\n    const byteLength = (values.byteLength + 7) & ~7; // Round up to a multiple of 8\n    this.buffers.push(values);\n    this.bufferRegions.push(new message_1.BufferRegion(this._byteLength, byteLength));\n    this._byteLength += byteLength;\n    return this;\n}\n/** @ignore */\nfunction assembleUnion(vector) {\n    const { type, length, typeIds, valueOffsets } = vector;\n    // All Union Vectors have a typeIds buffer\n    addBuffer.call(this, typeIds);\n    // If this is a Sparse Union, treat it like all other Nested types\n    if (type.mode === enum_1.UnionMode.Sparse) {\n        return assembleNestedVector.call(this, vector);\n    }\n    else if (type.mode === enum_1.UnionMode.Dense) {\n        // If this is a Dense Union, add the valueOffsets buffer and potentially slice the children\n        if (vector.offset <= 0) {\n            // If the Vector hasn't been sliced, write the existing valueOffsets\n            addBuffer.call(this, valueOffsets);\n            // We can treat this like all other Nested types\n            return assembleNestedVector.call(this, vector);\n        }\n        else {\n            // A sliced Dense Union is an unpleasant case. Because the offsets are different for\n            // each child vector, we need to \"rebase\" the valueOffsets for each child\n            // Union typeIds are not necessary 0-indexed\n            const maxChildTypeId = typeIds.reduce((x, y) => Math.max(x, y), typeIds[0]);\n            const childLengths = new Int32Array(maxChildTypeId + 1);\n            // Set all to -1 to indicate that we haven't observed a first occurrence of a particular child yet\n            const childOffsets = new Int32Array(maxChildTypeId + 1).fill(-1);\n            const shiftedOffsets = new Int32Array(length);\n            // If we have a non-zero offset, then the value offsets do not start at\n            // zero. We must a) create a new offsets array with shifted offsets and\n            // b) slice the values array accordingly\n            const unshiftedOffsets = buffer_1.rebaseValueOffsets(-valueOffsets[0], length, valueOffsets);\n            for (let typeId, shift, index = -1; ++index < length;) {\n                if ((shift = childOffsets[typeId = typeIds[index]]) === -1) {\n                    shift = childOffsets[typeId] = unshiftedOffsets[typeId];\n                }\n                shiftedOffsets[index] = unshiftedOffsets[index] - shift;\n                ++childLengths[typeId];\n            }\n            addBuffer.call(this, shiftedOffsets);\n            // Slice and visit children accordingly\n            for (let child, childIndex = -1, numChildren = type.children.length; ++childIndex < numChildren;) {\n                if (child = vector.getChildAt(childIndex)) {\n                    const typeId = type.typeIds[childIndex];\n                    const childLength = Math.min(length, childLengths[typeId]);\n                    this.visit(child.slice(childOffsets[typeId], childLength));\n                }\n            }\n        }\n    }\n    return this;\n}\n/** @ignore */\nfunction assembleBoolVector(vector) {\n    // Bool vector is a special case of FlatVector, as its data buffer needs to stay packed\n    let values;\n    if (vector.nullCount >= vector.length) {\n        // If all values are null, just insert a placeholder empty data buffer (fastest path)\n        return addBuffer.call(this, new Uint8Array(0));\n    }\n    else if ((values = vector.values) instanceof Uint8Array) {\n        // If values is already a Uint8Array, slice the bitmap (fast path)\n        return addBuffer.call(this, bit_1.truncateBitmap(vector.offset, vector.length, values));\n    }\n    // Otherwise if the underlying data *isn't* a Uint8Array, enumerate the\n    // values as bools and re-pack them into a Uint8Array. This code isn't\n    // reachable unless you're trying to manipulate the Data internals,\n    // we we're only doing this for safety.\n    /* istanbul ignore next */\n    return addBuffer.call(this, bit_1.packBools(vector));\n}\n/** @ignore */\nfunction assembleFlatVector(vector) {\n    return addBuffer.call(this, vector.values.subarray(0, vector.length * vector.stride));\n}\n/** @ignore */\nfunction assembleFlatListVector(vector) {\n    const { length, values, valueOffsets } = vector;\n    const firstOffset = valueOffsets[0];\n    const lastOffset = valueOffsets[length];\n    const byteLength = Math.min(lastOffset - firstOffset, values.byteLength - firstOffset);\n    // Push in the order FlatList types read their buffers\n    addBuffer.call(this, buffer_1.rebaseValueOffsets(-valueOffsets[0], length, valueOffsets)); // valueOffsets buffer first\n    addBuffer.call(this, values.subarray(firstOffset, firstOffset + byteLength)); // sliced values buffer second\n    return this;\n}\n/** @ignore */\nfunction assembleListVector(vector) {\n    const { length, valueOffsets } = vector;\n    // If we have valueOffsets (MapVector, ListVector), push that buffer first\n    if (valueOffsets) {\n        addBuffer.call(this, buffer_1.rebaseValueOffsets(valueOffsets[0], length, valueOffsets));\n    }\n    // Then insert the List's values child\n    return this.visit(vector.getChildAt(0));\n}\n/** @ignore */\nfunction assembleNestedVector(vector) {\n    return this.visitMany(vector.type.children.map((_, i) => vector.getChildAt(i)).filter(Boolean))[0];\n}\nVectorAssembler.prototype.visitBool = assembleBoolVector;\nVectorAssembler.prototype.visitInt = assembleFlatVector;\nVectorAssembler.prototype.visitFloat = assembleFlatVector;\nVectorAssembler.prototype.visitUtf8 = assembleFlatListVector;\nVectorAssembler.prototype.visitBinary = assembleFlatListVector;\nVectorAssembler.prototype.visitFixedSizeBinary = assembleFlatVector;\nVectorAssembler.prototype.visitDate = assembleFlatVector;\nVectorAssembler.prototype.visitTimestamp = assembleFlatVector;\nVectorAssembler.prototype.visitTime = assembleFlatVector;\nVectorAssembler.prototype.visitDecimal = assembleFlatVector;\nVectorAssembler.prototype.visitList = assembleListVector;\nVectorAssembler.prototype.visitStruct = assembleNestedVector;\nVectorAssembler.prototype.visitUnion = assembleUnion;\nVectorAssembler.prototype.visitInterval = assembleFlatVector;\nVectorAssembler.prototype.visitFixedSizeList = assembleListVector;\nVectorAssembler.prototype.visitMap = assembleListVector;\n\n//# sourceMappingURL=vectorassembler.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst visitor_1 = require(\"../visitor\");\nconst binary_1 = require(\"../vector/binary\");\nconst bool_1 = require(\"../vector/bool\");\nconst date_1 = require(\"../vector/date\");\nconst decimal_1 = require(\"../vector/decimal\");\nconst dictionary_1 = require(\"../vector/dictionary\");\nconst fixedsizebinary_1 = require(\"../vector/fixedsizebinary\");\nconst fixedsizelist_1 = require(\"../vector/fixedsizelist\");\nconst float_1 = require(\"../vector/float\");\nconst interval_1 = require(\"../vector/interval\");\nconst int_1 = require(\"../vector/int\");\nconst list_1 = require(\"../vector/list\");\nconst map_1 = require(\"../vector/map\");\nconst null_1 = require(\"../vector/null\");\nconst struct_1 = require(\"../vector/struct\");\nconst timestamp_1 = require(\"../vector/timestamp\");\nconst time_1 = require(\"../vector/time\");\nconst union_1 = require(\"../vector/union\");\nconst utf8_1 = require(\"../vector/utf8\");\n/** @ignore */\nclass GetVectorConstructor extends visitor_1.Visitor {\n    visitNull() { return null_1.NullVector; }\n    visitBool() { return bool_1.BoolVector; }\n    visitInt() { return int_1.IntVector; }\n    visitInt8() { return int_1.Int8Vector; }\n    visitInt16() { return int_1.Int16Vector; }\n    visitInt32() { return int_1.Int32Vector; }\n    visitInt64() { return int_1.Int64Vector; }\n    visitUint8() { return int_1.Uint8Vector; }\n    visitUint16() { return int_1.Uint16Vector; }\n    visitUint32() { return int_1.Uint32Vector; }\n    visitUint64() { return int_1.Uint64Vector; }\n    visitFloat() { return float_1.FloatVector; }\n    visitFloat16() { return float_1.Float16Vector; }\n    visitFloat32() { return float_1.Float32Vector; }\n    visitFloat64() { return float_1.Float64Vector; }\n    visitUtf8() { return utf8_1.Utf8Vector; }\n    visitBinary() { return binary_1.BinaryVector; }\n    visitFixedSizeBinary() { return fixedsizebinary_1.FixedSizeBinaryVector; }\n    visitDate() { return date_1.DateVector; }\n    visitDateDay() { return date_1.DateDayVector; }\n    visitDateMillisecond() { return date_1.DateMillisecondVector; }\n    visitTimestamp() { return timestamp_1.TimestampVector; }\n    visitTimestampSecond() { return timestamp_1.TimestampSecondVector; }\n    visitTimestampMillisecond() { return timestamp_1.TimestampMillisecondVector; }\n    visitTimestampMicrosecond() { return timestamp_1.TimestampMicrosecondVector; }\n    visitTimestampNanosecond() { return timestamp_1.TimestampNanosecondVector; }\n    visitTime() { return time_1.TimeVector; }\n    visitTimeSecond() { return time_1.TimeSecondVector; }\n    visitTimeMillisecond() { return time_1.TimeMillisecondVector; }\n    visitTimeMicrosecond() { return time_1.TimeMicrosecondVector; }\n    visitTimeNanosecond() { return time_1.TimeNanosecondVector; }\n    visitDecimal() { return decimal_1.DecimalVector; }\n    visitList() { return list_1.ListVector; }\n    visitStruct() { return struct_1.StructVector; }\n    visitUnion() { return union_1.UnionVector; }\n    visitDenseUnion() { return union_1.DenseUnionVector; }\n    visitSparseUnion() { return union_1.SparseUnionVector; }\n    visitDictionary() { return dictionary_1.DictionaryVector; }\n    visitInterval() { return interval_1.IntervalVector; }\n    visitIntervalDayTime() { return interval_1.IntervalDayTimeVector; }\n    visitIntervalYearMonth() { return interval_1.IntervalYearMonthVector; }\n    visitFixedSizeList() { return fixedsizelist_1.FixedSizeListVector; }\n    visitMap() { return map_1.MapVector; }\n}\nexports.GetVectorConstructor = GetVectorConstructor;\n/** @ignore */\nexports.instance = new GetVectorConstructor();\n\n//# sourceMappingURL=vectorctor.js.map\n","\"use strict\";\n// Licensed to the Apache Software Foundation (ASF) under one\n// or more contributor license agreements.  See the NOTICE file\n// distributed with this work for additional information\n// regarding copyright ownership.  The ASF licenses this file\n// to you under the Apache License, Version 2.0 (the\n// \"License\"); you may not use this file except in compliance\n// with the License.  You may obtain a copy of the License at\n//\n//   http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing,\n// software distributed under the License is distributed on an\n// \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n// KIND, either express or implied.  See the License for the\n// specific language governing permissions and limitations\n// under the License.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst data_1 = require(\"../data\");\nconst schema_1 = require(\"../schema\");\nconst type_1 = require(\"../type\");\nconst visitor_1 = require(\"../visitor\");\nconst bit_1 = require(\"../util/bit\");\nconst utf8_1 = require(\"../util/utf8\");\nconst int_1 = require(\"../util/int\");\nconst enum_1 = require(\"../enum\");\nconst buffer_1 = require(\"../util/buffer\");\n/** @ignore */\nclass VectorLoader extends visitor_1.Visitor {\n    constructor(bytes, nodes, buffers, dictionaries) {\n        super();\n        this.nodesIndex = -1;\n        this.buffersIndex = -1;\n        this.bytes = bytes;\n        this.nodes = nodes;\n        this.buffers = buffers;\n        this.dictionaries = dictionaries;\n    }\n    visit(node) {\n        return super.visit(node instanceof schema_1.Field ? node.type : node);\n    }\n    visitNull(type, { length, } = this.nextFieldNode()) { return data_1.Data.Null(type, 0, length); }\n    visitBool(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Bool(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitInt(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Int(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitFloat(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Float(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitUtf8(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Utf8(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readOffsets(type), this.readData(type)); }\n    visitBinary(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Binary(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readOffsets(type), this.readData(type)); }\n    visitFixedSizeBinary(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.FixedSizeBinary(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitDate(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Date(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitTimestamp(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Timestamp(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitTime(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Time(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitDecimal(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Decimal(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitList(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.List(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readOffsets(type), this.visit(type.children[0])); }\n    visitStruct(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Struct(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.visitMany(type.children)); }\n    visitUnion(type) { return type.mode === enum_1.UnionMode.Sparse ? this.visitSparseUnion(type) : this.visitDenseUnion(type); }\n    visitDenseUnion(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Union(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readTypeIds(type), this.readOffsets(type), this.visitMany(type.children)); }\n    visitSparseUnion(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Union(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readTypeIds(type), this.visitMany(type.children)); }\n    visitDictionary(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Dictionary(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type.indices), this.readDictionary(type)); }\n    visitInterval(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Interval(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readData(type)); }\n    visitFixedSizeList(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.FixedSizeList(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.visit(type.children[0])); }\n    visitMap(type, { length, nullCount } = this.nextFieldNode()) { return data_1.Data.Map(type, 0, length, nullCount, this.readNullBitmap(type, nullCount), this.readOffsets(type), this.visit(type.children[0])); }\n    nextFieldNode() { return this.nodes[++this.nodesIndex]; }\n    nextBufferRange() { return this.buffers[++this.buffersIndex]; }\n    readNullBitmap(type, nullCount, buffer = this.nextBufferRange()) {\n        return nullCount > 0 && this.readData(type, buffer) || new Uint8Array(0);\n    }\n    readOffsets(type, buffer) { return this.readData(type, buffer); }\n    readTypeIds(type, buffer) { return this.readData(type, buffer); }\n    readData(_type, { length, offset } = this.nextBufferRange()) {\n        return this.bytes.subarray(offset, offset + length);\n    }\n    readDictionary(type) {\n        return this.dictionaries.get(type.id);\n    }\n}\nexports.VectorLoader = VectorLoader;\n/** @ignore */\nclass JSONVectorLoader extends VectorLoader {\n    constructor(sources, nodes, buffers, dictionaries) {\n        super(new Uint8Array(0), nodes, buffers, dictionaries);\n        this.sources = sources;\n    }\n    readNullBitmap(_type, nullCount, { offset } = this.nextBufferRange()) {\n        return nullCount <= 0 ? new Uint8Array(0) : bit_1.packBools(this.sources[offset]);\n    }\n    readOffsets(_type, { offset } = this.nextBufferRange()) {\n        return buffer_1.toArrayBufferView(Uint8Array, buffer_1.toArrayBufferView(Int32Array, this.sources[offset]));\n    }\n    readTypeIds(type, { offset } = this.nextBufferRange()) {\n        return buffer_1.toArrayBufferView(Uint8Array, buffer_1.toArrayBufferView(type.ArrayType, this.sources[offset]));\n    }\n    readData(type, { offset } = this.nextBufferRange()) {\n        const { sources } = this;\n        if (type_1.DataType.isTimestamp(type)) {\n            return buffer_1.toArrayBufferView(Uint8Array, int_1.Int64.convertArray(sources[offset]));\n        }\n        else if ((type_1.DataType.isInt(type) || type_1.DataType.isTime(type)) && type.bitWidth === 64) {\n            return buffer_1.toArrayBufferView(Uint8Array, int_1.Int64.convertArray(sources[offset]));\n        }\n        else if (type_1.DataType.isDate(type) && type.unit === enum_1.DateUnit.MILLISECOND) {\n            return buffer_1.toArrayBufferView(Uint8Array, int_1.Int64.convertArray(sources[offset]));\n        }\n        else if (type_1.DataType.isDecimal(type)) {\n            return buffer_1.toArrayBufferView(Uint8Array, int_1.Int128.convertArray(sources[offset]));\n        }\n        else if (type_1.DataType.isBinary(type) || type_1.DataType.isFixedSizeBinary(type)) {\n            return binaryDataFromJSON(sources[offset]);\n        }\n        else if (type_1.DataType.isBool(type)) {\n            return bit_1.packBools(sources[offset]);\n        }\n        else if (type_1.DataType.isUtf8(type)) {\n            return utf8_1.encodeUtf8(sources[offset].join(''));\n        }\n        return buffer_1.toArrayBufferView(Uint8Array, buffer_1.toArrayBufferView(type.ArrayType, sources[offset].map((x) => +x)));\n    }\n}\nexports.JSONVectorLoader = JSONVectorLoader;\n/** @ignore */\nfunction binaryDataFromJSON(values) {\n    // \"DATA\": [\"49BC7D5B6C47D2\",\"3F5FB6D9322026\"]\n    // There are definitely more efficient ways to do this... but it gets the\n    // job done.\n    const joined = values.join('');\n    const data = new Uint8Array(joined.length / 2);\n    for (let i = 0; i < joined.length; i += 2) {\n        data[i >> 1] = parseInt(joined.substr(i, 2), 16);\n    }\n    return data;\n}\n\n//# sourceMappingURL=vectorloader.js.map\n","/// @file\n/// @addtogroup flatbuffers_javascript_api\n/// @{\n/// @cond FLATBUFFERS_INTERNAL\n\n/**\n * @fileoverview\n *\n * Need to suppress 'global this' error so the Node.js export line doesn't cause\n * closure compile to error out.\n * @suppress {globalThis}\n */\n\n/**\n * @const\n * @namespace\n */\nvar flatbuffers = {};\n\n/**\n * @typedef {number}\n */\nflatbuffers.Offset;\n\n/**\n * @typedef {{\n *   bb: flatbuffers.ByteBuffer,\n *   bb_pos: number\n * }}\n */\nflatbuffers.Table;\n\n/**\n * @type {number}\n * @const\n */\nflatbuffers.SIZEOF_SHORT = 2;\n\n/**\n * @type {number}\n * @const\n */\nflatbuffers.SIZEOF_INT = 4;\n\n/**\n * @type {number}\n * @const\n */\nflatbuffers.FILE_IDENTIFIER_LENGTH = 4;\n\n/**\n * @enum {number}\n */\nflatbuffers.Encoding = {\n  UTF8_BYTES: 1,\n  UTF16_STRING: 2\n};\n\n/**\n * @type {Int32Array}\n * @const\n */\nflatbuffers.int32 = new Int32Array(2);\n\n/**\n * @type {Float32Array}\n * @const\n */\nflatbuffers.float32 = new Float32Array(flatbuffers.int32.buffer);\n\n/**\n * @type {Float64Array}\n * @const\n */\nflatbuffers.float64 = new Float64Array(flatbuffers.int32.buffer);\n\n/**\n * @type {boolean}\n * @const\n */\nflatbuffers.isLittleEndian = new Uint16Array(new Uint8Array([1, 0]).buffer)[0] === 1;\n\n////////////////////////////////////////////////////////////////////////////////\n\n/**\n * @constructor\n * @param {number} low\n * @param {number} high\n */\nflatbuffers.Long = function(low, high) {\n  /**\n   * @type {number}\n   * @const\n   */\n  this.low = low | 0;\n\n  /**\n   * @type {number}\n   * @const\n   */\n  this.high = high | 0;\n};\n\n/**\n * @param {number} low\n * @param {number} high\n * @returns {flatbuffers.Long}\n */\nflatbuffers.Long.create = function(low, high) {\n  // Special-case zero to avoid GC overhead for default values\n  return low == 0 && high == 0 ? flatbuffers.Long.ZERO : new flatbuffers.Long(low, high);\n};\n\n/**\n * @returns {number}\n */\nflatbuffers.Long.prototype.toFloat64 = function() {\n  return (this.low >>> 0) + this.high * 0x100000000;\n};\n\n/**\n * @param {flatbuffers.Long} other\n * @returns {boolean}\n */\nflatbuffers.Long.prototype.equals = function(other) {\n  return this.low == other.low && this.high == other.high;\n};\n\n/**\n * @type {flatbuffers.Long}\n * @const\n */\nflatbuffers.Long.ZERO = new flatbuffers.Long(0, 0);\n\n/// @endcond\n////////////////////////////////////////////////////////////////////////////////\n/**\n * Create a FlatBufferBuilder.\n *\n * @constructor\n * @param {number=} opt_initial_size\n */\nflatbuffers.Builder = function(opt_initial_size) {\n  if (!opt_initial_size) {\n    var initial_size = 1024;\n  } else {\n    var initial_size = opt_initial_size;\n  }\n\n  /**\n   * @type {flatbuffers.ByteBuffer}\n   * @private\n   */\n  this.bb = flatbuffers.ByteBuffer.allocate(initial_size);\n\n  /**\n   * Remaining space in the ByteBuffer.\n   *\n   * @type {number}\n   * @private\n   */\n  this.space = initial_size;\n\n  /**\n   * Minimum alignment encountered so far.\n   *\n   * @type {number}\n   * @private\n   */\n  this.minalign = 1;\n\n  /**\n   * The vtable for the current table.\n   *\n   * @type {Array.<number>}\n   * @private\n   */\n  this.vtable = null;\n\n  /**\n   * The amount of fields we're actually using.\n   *\n   * @type {number}\n   * @private\n   */\n  this.vtable_in_use = 0;\n\n  /**\n   * Whether we are currently serializing a table.\n   *\n   * @type {boolean}\n   * @private\n   */\n  this.isNested = false;\n\n  /**\n   * Starting offset of the current struct/table.\n   *\n   * @type {number}\n   * @private\n   */\n  this.object_start = 0;\n\n  /**\n   * List of offsets of all vtables.\n   *\n   * @type {Array.<number>}\n   * @private\n   */\n  this.vtables = [];\n\n  /**\n   * For the current vector being built.\n   *\n   * @type {number}\n   * @private\n   */\n  this.vector_num_elems = 0;\n\n  /**\n   * False omits default values from the serialized data\n   *\n   * @type {boolean}\n   * @private\n   */\n  this.force_defaults = false;\n};\n\nflatbuffers.Builder.prototype.clear = function() {\n  this.bb.clear();\n  this.space = this.bb.capacity();\n  this.minalign = 1;\n  this.vtable = null;\n  this.vtable_in_use = 0;\n  this.isNested = false;\n  this.object_start = 0;\n  this.vtables = [];\n  this.vector_num_elems = 0;\n  this.force_defaults = false;\n};\n\n/**\n * In order to save space, fields that are set to their default value\n * don't get serialized into the buffer. Forcing defaults provides a\n * way to manually disable this optimization.\n *\n * @param {boolean} forceDefaults true always serializes default values\n */\nflatbuffers.Builder.prototype.forceDefaults = function(forceDefaults) {\n  this.force_defaults = forceDefaults;\n};\n\n/**\n * Get the ByteBuffer representing the FlatBuffer. Only call this after you've\n * called finish(). The actual data starts at the ByteBuffer's current position,\n * not necessarily at 0.\n *\n * @returns {flatbuffers.ByteBuffer}\n */\nflatbuffers.Builder.prototype.dataBuffer = function() {\n  return this.bb;\n};\n\n/**\n * Get the bytes representing the FlatBuffer. Only call this after you've\n * called finish().\n *\n * @returns {Uint8Array}\n */\nflatbuffers.Builder.prototype.asUint8Array = function() {\n  return this.bb.bytes().subarray(this.bb.position(), this.bb.position() + this.offset());\n};\n\n/// @cond FLATBUFFERS_INTERNAL\n/**\n * Prepare to write an element of `size` after `additional_bytes` have been\n * written, e.g. if you write a string, you need to align such the int length\n * field is aligned to 4 bytes, and the string data follows it directly. If all\n * you need to do is alignment, `additional_bytes` will be 0.\n *\n * @param {number} size This is the of the new element to write\n * @param {number} additional_bytes The padding size\n */\nflatbuffers.Builder.prototype.prep = function(size, additional_bytes) {\n  // Track the biggest thing we've ever aligned to.\n  if (size > this.minalign) {\n    this.minalign = size;\n  }\n\n  // Find the amount of alignment needed such that `size` is properly\n  // aligned after `additional_bytes`\n  var align_size = ((~(this.bb.capacity() - this.space + additional_bytes)) + 1) & (size - 1);\n\n  // Reallocate the buffer if needed.\n  while (this.space < align_size + size + additional_bytes) {\n    var old_buf_size = this.bb.capacity();\n    this.bb = flatbuffers.Builder.growByteBuffer(this.bb);\n    this.space += this.bb.capacity() - old_buf_size;\n  }\n\n  this.pad(align_size);\n};\n\n/**\n * @param {number} byte_size\n */\nflatbuffers.Builder.prototype.pad = function(byte_size) {\n  for (var i = 0; i < byte_size; i++) {\n    this.bb.writeInt8(--this.space, 0);\n  }\n};\n\n/**\n * @param {number} value\n */\nflatbuffers.Builder.prototype.writeInt8 = function(value) {\n  this.bb.writeInt8(this.space -= 1, value);\n};\n\n/**\n * @param {number} value\n */\nflatbuffers.Builder.prototype.writeInt16 = function(value) {\n  this.bb.writeInt16(this.space -= 2, value);\n};\n\n/**\n * @param {number} value\n */\nflatbuffers.Builder.prototype.writeInt32 = function(value) {\n  this.bb.writeInt32(this.space -= 4, value);\n};\n\n/**\n * @param {flatbuffers.Long} value\n */\nflatbuffers.Builder.prototype.writeInt64 = function(value) {\n  this.bb.writeInt64(this.space -= 8, value);\n};\n\n/**\n * @param {number} value\n */\nflatbuffers.Builder.prototype.writeFloat32 = function(value) {\n  this.bb.writeFloat32(this.space -= 4, value);\n};\n\n/**\n * @param {number} value\n */\nflatbuffers.Builder.prototype.writeFloat64 = function(value) {\n  this.bb.writeFloat64(this.space -= 8, value);\n};\n/// @endcond\n\n/**\n * Add an `int8` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {number} value The `int8` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addInt8 = function(value) {\n  this.prep(1, 0);\n  this.writeInt8(value);\n};\n\n/**\n * Add an `int16` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {number} value The `int16` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addInt16 = function(value) {\n  this.prep(2, 0);\n  this.writeInt16(value);\n};\n\n/**\n * Add an `int32` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {number} value The `int32` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addInt32 = function(value) {\n  this.prep(4, 0);\n  this.writeInt32(value);\n};\n\n/**\n * Add an `int64` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {flatbuffers.Long} value The `int64` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addInt64 = function(value) {\n  this.prep(8, 0);\n  this.writeInt64(value);\n};\n\n/**\n * Add a `float32` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {number} value The `float32` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addFloat32 = function(value) {\n  this.prep(4, 0);\n  this.writeFloat32(value);\n};\n\n/**\n * Add a `float64` to the buffer, properly aligned, and grows the buffer (if necessary).\n * @param {number} value The `float64` to add the the buffer.\n */\nflatbuffers.Builder.prototype.addFloat64 = function(value) {\n  this.prep(8, 0);\n  this.writeFloat64(value);\n};\n\n/// @cond FLATBUFFERS_INTERNAL\n/**\n * @param {number} voffset\n * @param {number} value\n * @param {number} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldInt8 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addInt8(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {number} value\n * @param {number} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldInt16 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addInt16(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {number} value\n * @param {number} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldInt32 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addInt32(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {flatbuffers.Long} value\n * @param {flatbuffers.Long} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldInt64 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || !value.equals(defaultValue)) {\n    this.addInt64(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {number} value\n * @param {number} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldFloat32 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addFloat32(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {number} value\n * @param {number} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldFloat64 = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addFloat64(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * @param {number} voffset\n * @param {flatbuffers.Offset} value\n * @param {flatbuffers.Offset} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldOffset = function(voffset, value, defaultValue) {\n  if (this.force_defaults || value != defaultValue) {\n    this.addOffset(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * Structs are stored inline, so nothing additional is being added. `d` is always 0.\n *\n * @param {number} voffset\n * @param {flatbuffers.Offset} value\n * @param {flatbuffers.Offset} defaultValue\n */\nflatbuffers.Builder.prototype.addFieldStruct = function(voffset, value, defaultValue) {\n  if (value != defaultValue) {\n    this.nested(value);\n    this.slot(voffset);\n  }\n};\n\n/**\n * Structures are always stored inline, they need to be created right\n * where they're used.  You'll get this assertion failure if you\n * created it elsewhere.\n *\n * @param {flatbuffers.Offset} obj The offset of the created object\n */\nflatbuffers.Builder.prototype.nested = function(obj) {\n  if (obj != this.offset()) {\n    throw new Error('FlatBuffers: struct must be serialized inline.');\n  }\n};\n\n/**\n * Should not be creating any other object, string or vector\n * while an object is being constructed\n */\nflatbuffers.Builder.prototype.notNested = function() {\n  if (this.isNested) {\n    throw new Error('FlatBuffers: object serialization must not be nested.');\n  }\n};\n\n/**\n * Set the current vtable at `voffset` to the current location in the buffer.\n *\n * @param {number} voffset\n */\nflatbuffers.Builder.prototype.slot = function(voffset) {\n  this.vtable[voffset] = this.offset();\n};\n\n/**\n * @returns {flatbuffers.Offset} Offset relative to the end of the buffer.\n */\nflatbuffers.Builder.prototype.offset = function() {\n  return this.bb.capacity() - this.space;\n};\n\n/**\n * Doubles the size of the backing ByteBuffer and copies the old data towards\n * the end of the new buffer (since we build the buffer backwards).\n *\n * @param {flatbuffers.ByteBuffer} bb The current buffer with the existing data\n * @returns {flatbuffers.ByteBuffer} A new byte buffer with the old data copied\n * to it. The data is located at the end of the buffer.\n *\n * uint8Array.set() formally takes {Array<number>|ArrayBufferView}, so to pass\n * it a uint8Array we need to suppress the type check:\n * @suppress {checkTypes}\n */\nflatbuffers.Builder.growByteBuffer = function(bb) {\n  var old_buf_size = bb.capacity();\n\n  // Ensure we don't grow beyond what fits in an int.\n  if (old_buf_size & 0xC0000000) {\n    throw new Error('FlatBuffers: cannot grow buffer beyond 2 gigabytes.');\n  }\n\n  var new_buf_size = old_buf_size << 1;\n  var nbb = flatbuffers.ByteBuffer.allocate(new_buf_size);\n  nbb.setPosition(new_buf_size - old_buf_size);\n  nbb.bytes().set(bb.bytes(), new_buf_size - old_buf_size);\n  return nbb;\n};\n/// @endcond\n\n/**\n * Adds on offset, relative to where it will be written.\n *\n * @param {flatbuffers.Offset} offset The offset to add.\n */\nflatbuffers.Builder.prototype.addOffset = function(offset) {\n  this.prep(flatbuffers.SIZEOF_INT, 0); // Ensure alignment is already done.\n  this.writeInt32(this.offset() - offset + flatbuffers.SIZEOF_INT);\n};\n\n/// @cond FLATBUFFERS_INTERNAL\n/**\n * Start encoding a new object in the buffer.  Users will not usually need to\n * call this directly. The FlatBuffers compiler will generate helper methods\n * that call this method internally.\n *\n * @param {number} numfields\n */\nflatbuffers.Builder.prototype.startObject = function(numfields) {\n  this.notNested();\n  if (this.vtable == null) {\n    this.vtable = [];\n  }\n  this.vtable_in_use = numfields;\n  for (var i = 0; i < numfields; i++) {\n    this.vtable[i] = 0; // This will push additional elements as needed\n  }\n  this.isNested = true;\n  this.object_start = this.offset();\n};\n\n/**\n * Finish off writing the object that is under construction.\n *\n * @returns {flatbuffers.Offset} The offset to the object inside `dataBuffer`\n */\nflatbuffers.Builder.prototype.endObject = function() {\n  if (this.vtable == null || !this.isNested) {\n    throw new Error('FlatBuffers: endObject called without startObject');\n  }\n\n  this.addInt32(0);\n  var vtableloc = this.offset();\n\n  // Trim trailing zeroes.\n  var i = this.vtable_in_use - 1;\n  for (; i >= 0 && this.vtable[i] == 0; i--) {}\n  var trimmed_size = i + 1;\n\n  // Write out the current vtable.\n  for (; i >= 0; i--) {\n    // Offset relative to the start of the table.\n    this.addInt16(this.vtable[i] != 0 ? vtableloc - this.vtable[i] : 0);\n  }\n\n  var standard_fields = 2; // The fields below:\n  this.addInt16(vtableloc - this.object_start);\n  var len = (trimmed_size + standard_fields) * flatbuffers.SIZEOF_SHORT;\n  this.addInt16(len);\n\n  // Search for an existing vtable that matches the current one.\n  var existing_vtable = 0;\n  var vt1 = this.space;\nouter_loop:\n  for (i = 0; i < this.vtables.length; i++) {\n    var vt2 = this.bb.capacity() - this.vtables[i];\n    if (len == this.bb.readInt16(vt2)) {\n      for (var j = flatbuffers.SIZEOF_SHORT; j < len; j += flatbuffers.SIZEOF_SHORT) {\n        if (this.bb.readInt16(vt1 + j) != this.bb.readInt16(vt2 + j)) {\n          continue outer_loop;\n        }\n      }\n      existing_vtable = this.vtables[i];\n      break;\n    }\n  }\n\n  if (existing_vtable) {\n    // Found a match:\n    // Remove the current vtable.\n    this.space = this.bb.capacity() - vtableloc;\n\n    // Point table to existing vtable.\n    this.bb.writeInt32(this.space, existing_vtable - vtableloc);\n  } else {\n    // No match:\n    // Add the location of the current vtable to the list of vtables.\n    this.vtables.push(this.offset());\n\n    // Point table to current vtable.\n    this.bb.writeInt32(this.bb.capacity() - vtableloc, this.offset() - vtableloc);\n  }\n\n  this.isNested = false;\n  return vtableloc;\n};\n/// @endcond\n\n/**\n * Finalize a buffer, poiting to the given `root_table`.\n *\n * @param {flatbuffers.Offset} root_table\n * @param {string=} opt_file_identifier\n */\nflatbuffers.Builder.prototype.finish = function(root_table, opt_file_identifier) {\n  if (opt_file_identifier) {\n    var file_identifier = opt_file_identifier;\n    this.prep(this.minalign, flatbuffers.SIZEOF_INT +\n      flatbuffers.FILE_IDENTIFIER_LENGTH);\n    if (file_identifier.length != flatbuffers.FILE_IDENTIFIER_LENGTH) {\n      throw new Error('FlatBuffers: file identifier must be length ' +\n        flatbuffers.FILE_IDENTIFIER_LENGTH);\n    }\n    for (var i = flatbuffers.FILE_IDENTIFIER_LENGTH - 1; i >= 0; i--) {\n      this.writeInt8(file_identifier.charCodeAt(i));\n    }\n  }\n  this.prep(this.minalign, flatbuffers.SIZEOF_INT);\n  this.addOffset(root_table);\n  this.bb.setPosition(this.space);\n};\n\n/// @cond FLATBUFFERS_INTERNAL\n/**\n * This checks a required field has been set in a given table that has\n * just been constructed.\n *\n * @param {flatbuffers.Offset} table\n * @param {number} field\n */\nflatbuffers.Builder.prototype.requiredField = function(table, field) {\n  var table_start = this.bb.capacity() - table;\n  var vtable_start = table_start - this.bb.readInt32(table_start);\n  var ok = this.bb.readInt16(vtable_start + field) != 0;\n\n  // If this fails, the caller will show what field needs to be set.\n  if (!ok) {\n    throw new Error('FlatBuffers: field ' + field + ' must be set');\n  }\n};\n\n/**\n * Start a new array/vector of objects.  Users usually will not call\n * this directly. The FlatBuffers compiler will create a start/end\n * method for vector types in generated code.\n *\n * @param {number} elem_size The size of each element in the array\n * @param {number} num_elems The number of elements in the array\n * @param {number} alignment The alignment of the array\n */\nflatbuffers.Builder.prototype.startVector = function(elem_size, num_elems, alignment) {\n  this.notNested();\n  this.vector_num_elems = num_elems;\n  this.prep(flatbuffers.SIZEOF_INT, elem_size * num_elems);\n  this.prep(alignment, elem_size * num_elems); // Just in case alignment > int.\n};\n\n/**\n * Finish off the creation of an array and all its elements. The array must be\n * created with `startVector`.\n *\n * @returns {flatbuffers.Offset} The offset at which the newly created array\n * starts.\n */\nflatbuffers.Builder.prototype.endVector = function() {\n  this.writeInt32(this.vector_num_elems);\n  return this.offset();\n};\n/// @endcond\n\n/**\n * Encode the string `s` in the buffer using UTF-8. If a Uint8Array is passed\n * instead of a string, it is assumed to contain valid UTF-8 encoded data.\n *\n * @param {string|Uint8Array} s The string to encode\n * @return {flatbuffers.Offset} The offset in the buffer where the encoded string starts\n */\nflatbuffers.Builder.prototype.createString = function(s) {\n  if (s instanceof Uint8Array) {\n    var utf8 = s;\n  } else {\n    var utf8 = [];\n    var i = 0;\n\n    while (i < s.length) {\n      var codePoint;\n\n      // Decode UTF-16\n      var a = s.charCodeAt(i++);\n      if (a < 0xD800 || a >= 0xDC00) {\n        codePoint = a;\n      } else {\n        var b = s.charCodeAt(i++);\n        codePoint = (a << 10) + b + (0x10000 - (0xD800 << 10) - 0xDC00);\n      }\n\n      // Encode UTF-8\n      if (codePoint < 0x80) {\n        utf8.push(codePoint);\n      } else {\n        if (codePoint < 0x800) {\n          utf8.push(((codePoint >> 6) & 0x1F) | 0xC0);\n        } else {\n          if (codePoint < 0x10000) {\n            utf8.push(((codePoint >> 12) & 0x0F) | 0xE0);\n          } else {\n            utf8.push(\n              ((codePoint >> 18) & 0x07) | 0xF0,\n              ((codePoint >> 12) & 0x3F) | 0x80);\n          }\n          utf8.push(((codePoint >> 6) & 0x3F) | 0x80);\n        }\n        utf8.push((codePoint & 0x3F) | 0x80);\n      }\n    }\n  }\n\n  this.addInt8(0);\n  this.startVector(1, utf8.length, 1);\n  this.bb.setPosition(this.space -= utf8.length);\n  for (var i = 0, offset = this.space, bytes = this.bb.bytes(); i < utf8.length; i++) {\n    bytes[offset++] = utf8[i];\n  }\n  return this.endVector();\n};\n\n/**\n * A helper function to avoid generated code depending on this file directly.\n *\n * @param {number} low\n * @param {number} high\n * @returns {flatbuffers.Long}\n */\nflatbuffers.Builder.prototype.createLong = function(low, high) {\n  return flatbuffers.Long.create(low, high);\n};\n////////////////////////////////////////////////////////////////////////////////\n/// @cond FLATBUFFERS_INTERNAL\n/**\n * Create a new ByteBuffer with a given array of bytes (`Uint8Array`).\n *\n * @constructor\n * @param {Uint8Array} bytes\n */\nflatbuffers.ByteBuffer = function(bytes) {\n  /**\n   * @type {Uint8Array}\n   * @private\n   */\n  this.bytes_ = bytes;\n\n  /**\n   * @type {number}\n   * @private\n   */\n  this.position_ = 0;\n};\n\n/**\n * Create and allocate a new ByteBuffer with a given size.\n *\n * @param {number} byte_size\n * @returns {flatbuffers.ByteBuffer}\n */\nflatbuffers.ByteBuffer.allocate = function(byte_size) {\n  return new flatbuffers.ByteBuffer(new Uint8Array(byte_size));\n};\n\nflatbuffers.ByteBuffer.prototype.clear = function() {\n  this.position_ = 0;\n};\n\n/**\n * Get the underlying `Uint8Array`.\n *\n * @returns {Uint8Array}\n */\nflatbuffers.ByteBuffer.prototype.bytes = function() {\n  return this.bytes_;\n};\n\n/**\n * Get the buffer's position.\n *\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.position = function() {\n  return this.position_;\n};\n\n/**\n * Set the buffer's position.\n *\n * @param {number} position\n */\nflatbuffers.ByteBuffer.prototype.setPosition = function(position) {\n  this.position_ = position;\n};\n\n/**\n * Get the buffer's capacity.\n *\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.capacity = function() {\n  return this.bytes_.length;\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readInt8 = function(offset) {\n  return this.readUint8(offset) << 24 >> 24;\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readUint8 = function(offset) {\n  return this.bytes_[offset];\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readInt16 = function(offset) {\n  return this.readUint16(offset) << 16 >> 16;\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readUint16 = function(offset) {\n  return this.bytes_[offset] | this.bytes_[offset + 1] << 8;\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readInt32 = function(offset) {\n  return this.bytes_[offset] | this.bytes_[offset + 1] << 8 | this.bytes_[offset + 2] << 16 | this.bytes_[offset + 3] << 24;\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readUint32 = function(offset) {\n  return this.readInt32(offset) >>> 0;\n};\n\n/**\n * @param {number} offset\n * @returns {flatbuffers.Long}\n */\nflatbuffers.ByteBuffer.prototype.readInt64 = function(offset) {\n  return new flatbuffers.Long(this.readInt32(offset), this.readInt32(offset + 4));\n};\n\n/**\n * @param {number} offset\n * @returns {flatbuffers.Long}\n */\nflatbuffers.ByteBuffer.prototype.readUint64 = function(offset) {\n  return new flatbuffers.Long(this.readUint32(offset), this.readUint32(offset + 4));\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readFloat32 = function(offset) {\n  flatbuffers.int32[0] = this.readInt32(offset);\n  return flatbuffers.float32[0];\n};\n\n/**\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.readFloat64 = function(offset) {\n  flatbuffers.int32[flatbuffers.isLittleEndian ? 0 : 1] = this.readInt32(offset);\n  flatbuffers.int32[flatbuffers.isLittleEndian ? 1 : 0] = this.readInt32(offset + 4);\n  return flatbuffers.float64[0];\n};\n\n/**\n * @param {number} offset\n * @param {number|boolean} value\n */\nflatbuffers.ByteBuffer.prototype.writeInt8 = function(offset, value) {\n  this.bytes_[offset] = /** @type {number} */(value);\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeUint8 = function(offset, value) {\n  this.bytes_[offset] = value;\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeInt16 = function(offset, value) {\n  this.bytes_[offset] = value;\n  this.bytes_[offset + 1] = value >> 8;\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeUint16 = function(offset, value) {\n    this.bytes_[offset] = value;\n    this.bytes_[offset + 1] = value >> 8;\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeInt32 = function(offset, value) {\n  this.bytes_[offset] = value;\n  this.bytes_[offset + 1] = value >> 8;\n  this.bytes_[offset + 2] = value >> 16;\n  this.bytes_[offset + 3] = value >> 24;\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeUint32 = function(offset, value) {\n    this.bytes_[offset] = value;\n    this.bytes_[offset + 1] = value >> 8;\n    this.bytes_[offset + 2] = value >> 16;\n    this.bytes_[offset + 3] = value >> 24;\n};\n\n/**\n * @param {number} offset\n * @param {flatbuffers.Long} value\n */\nflatbuffers.ByteBuffer.prototype.writeInt64 = function(offset, value) {\n  this.writeInt32(offset, value.low);\n  this.writeInt32(offset + 4, value.high);\n};\n\n/**\n * @param {number} offset\n * @param {flatbuffers.Long} value\n */\nflatbuffers.ByteBuffer.prototype.writeUint64 = function(offset, value) {\n    this.writeUint32(offset, value.low);\n    this.writeUint32(offset + 4, value.high);\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeFloat32 = function(offset, value) {\n  flatbuffers.float32[0] = value;\n  this.writeInt32(offset, flatbuffers.int32[0]);\n};\n\n/**\n * @param {number} offset\n * @param {number} value\n */\nflatbuffers.ByteBuffer.prototype.writeFloat64 = function(offset, value) {\n  flatbuffers.float64[0] = value;\n  this.writeInt32(offset, flatbuffers.int32[flatbuffers.isLittleEndian ? 0 : 1]);\n  this.writeInt32(offset + 4, flatbuffers.int32[flatbuffers.isLittleEndian ? 1 : 0]);\n};\n\n/**\n * Return the file identifier.   Behavior is undefined for FlatBuffers whose\n * schema does not include a file_identifier (likely points at padding or the\n * start of a the root vtable).\n * @returns {string}\n */\nflatbuffers.ByteBuffer.prototype.getBufferIdentifier = function() {\n  if (this.bytes_.length < this.position_ + flatbuffers.SIZEOF_INT +\n      flatbuffers.FILE_IDENTIFIER_LENGTH) {\n    throw new Error(\n        'FlatBuffers: ByteBuffer is too short to contain an identifier.');\n  }\n  var result = \"\";\n  for (var i = 0; i < flatbuffers.FILE_IDENTIFIER_LENGTH; i++) {\n    result += String.fromCharCode(\n        this.readInt8(this.position_ + flatbuffers.SIZEOF_INT + i));\n  }\n  return result;\n};\n\n/**\n * Look up a field in the vtable, return an offset into the object, or 0 if the\n * field is not present.\n *\n * @param {number} bb_pos\n * @param {number} vtable_offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.__offset = function(bb_pos, vtable_offset) {\n  var vtable = bb_pos - this.readInt32(bb_pos);\n  return vtable_offset < this.readInt16(vtable) ? this.readInt16(vtable + vtable_offset) : 0;\n};\n\n/**\n * Initialize any Table-derived type to point to the union at the given offset.\n *\n * @param {flatbuffers.Table} t\n * @param {number} offset\n * @returns {flatbuffers.Table}\n */\nflatbuffers.ByteBuffer.prototype.__union = function(t, offset) {\n  t.bb_pos = offset + this.readInt32(offset);\n  t.bb = this;\n  return t;\n};\n\n/**\n * Create a JavaScript string from UTF-8 data stored inside the FlatBuffer.\n * This allocates a new string and converts to wide chars upon each access.\n *\n * To avoid the conversion to UTF-16, pass flatbuffers.Encoding.UTF8_BYTES as\n * the \"optionalEncoding\" argument. This is useful for avoiding conversion to\n * and from UTF-16 when the data will just be packaged back up in another\n * FlatBuffer later on.\n *\n * @param {number} offset\n * @param {flatbuffers.Encoding=} opt_encoding Defaults to UTF16_STRING\n * @returns {string|Uint8Array}\n */\nflatbuffers.ByteBuffer.prototype.__string = function(offset, opt_encoding) {\n  offset += this.readInt32(offset);\n\n  var length = this.readInt32(offset);\n  var result = '';\n  var i = 0;\n\n  offset += flatbuffers.SIZEOF_INT;\n\n  if (opt_encoding === flatbuffers.Encoding.UTF8_BYTES) {\n    return this.bytes_.subarray(offset, offset + length);\n  }\n\n  while (i < length) {\n    var codePoint;\n\n    // Decode UTF-8\n    var a = this.readUint8(offset + i++);\n    if (a < 0xC0) {\n      codePoint = a;\n    } else {\n      var b = this.readUint8(offset + i++);\n      if (a < 0xE0) {\n        codePoint =\n          ((a & 0x1F) << 6) |\n          (b & 0x3F);\n      } else {\n        var c = this.readUint8(offset + i++);\n        if (a < 0xF0) {\n          codePoint =\n            ((a & 0x0F) << 12) |\n            ((b & 0x3F) << 6) |\n            (c & 0x3F);\n        } else {\n          var d = this.readUint8(offset + i++);\n          codePoint =\n            ((a & 0x07) << 18) |\n            ((b & 0x3F) << 12) |\n            ((c & 0x3F) << 6) |\n            (d & 0x3F);\n        }\n      }\n    }\n\n    // Encode UTF-16\n    if (codePoint < 0x10000) {\n      result += String.fromCharCode(codePoint);\n    } else {\n      codePoint -= 0x10000;\n      result += String.fromCharCode(\n        (codePoint >> 10) + 0xD800,\n        (codePoint & ((1 << 10) - 1)) + 0xDC00);\n    }\n  }\n\n  return result;\n};\n\n/**\n * Retrieve the relative offset stored at \"offset\"\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.__indirect = function(offset) {\n  return offset + this.readInt32(offset);\n};\n\n/**\n * Get the start of data of a vector whose offset is stored at \"offset\" in this object.\n *\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.__vector = function(offset) {\n  return offset + this.readInt32(offset) + flatbuffers.SIZEOF_INT; // data starts after the length\n};\n\n/**\n * Get the length of a vector whose offset is stored at \"offset\" in this object.\n *\n * @param {number} offset\n * @returns {number}\n */\nflatbuffers.ByteBuffer.prototype.__vector_len = function(offset) {\n  return this.readInt32(offset + this.readInt32(offset));\n};\n\n/**\n * @param {string} ident\n * @returns {boolean}\n */\nflatbuffers.ByteBuffer.prototype.__has_identifier = function(ident) {\n  if (ident.length != flatbuffers.FILE_IDENTIFIER_LENGTH) {\n    throw new Error('FlatBuffers: file identifier must be length ' +\n                    flatbuffers.FILE_IDENTIFIER_LENGTH);\n  }\n  for (var i = 0; i < flatbuffers.FILE_IDENTIFIER_LENGTH; i++) {\n    if (ident.charCodeAt(i) != this.readInt8(this.position_ + flatbuffers.SIZEOF_INT + i)) {\n      return false;\n    }\n  }\n  return true;\n};\n\n/**\n * A helper function to avoid generated code depending on this file directly.\n *\n * @param {number} low\n * @param {number} high\n * @returns {flatbuffers.Long}\n */\nflatbuffers.ByteBuffer.prototype.createLong = function(low, high) {\n  return flatbuffers.Long.create(low, high);\n};\n\n// Exports for Node.js and RequireJS\nexport { flatbuffers };\n\n/// @endcond\n/// @}\n","'use strict';\n\n// This is free and unencumbered software released into the public domain.\n// See LICENSE.md for more information.\n\n//\n// Utilities\n//\n\n/**\n * @param {number} a The number to test.\n * @param {number} min The minimum value in the range, inclusive.\n * @param {number} max The maximum value in the range, inclusive.\n * @return {boolean} True if a >= min and a <= max.\n */\nfunction inRange(a, min, max) {\n  return min <= a && a <= max;\n}\n\n/**\n * @param {*} o\n * @return {Object}\n */\nfunction ToDictionary(o) {\n  if (o === undefined) return {};\n  if (o === Object(o)) return o;\n  throw TypeError('Could not convert argument to dictionary');\n}\n\n/**\n * @param {string} string Input string of UTF-16 code units.\n * @return {!Array.<number>} Code points.\n */\nfunction stringToCodePoints(string) {\n  // https://heycam.github.io/webidl/#dfn-obtain-unicode\n\n  // 1. Let S be the DOMString value.\n  var s = String(string);\n\n  // 2. Let n be the length of S.\n  var n = s.length;\n\n  // 3. Initialize i to 0.\n  var i = 0;\n\n  // 4. Initialize U to be an empty sequence of Unicode characters.\n  var u = [];\n\n  // 5. While i < n:\n  while (i < n) {\n\n    // 1. Let c be the code unit in S at index i.\n    var c = s.charCodeAt(i);\n\n    // 2. Depending on the value of c:\n\n    // c < 0xD800 or c > 0xDFFF\n    if (c < 0xD800 || c > 0xDFFF) {\n      // Append to U the Unicode character with code point c.\n      u.push(c);\n    }\n\n    // 0xDC00  c  0xDFFF\n    else if (0xDC00 <= c && c <= 0xDFFF) {\n      // Append to U a U+FFFD REPLACEMENT CHARACTER.\n      u.push(0xFFFD);\n    }\n\n    // 0xD800  c  0xDBFF\n    else if (0xD800 <= c && c <= 0xDBFF) {\n      // 1. If i = n1, then append to U a U+FFFD REPLACEMENT\n      // CHARACTER.\n      if (i === n - 1) {\n        u.push(0xFFFD);\n      }\n      // 2. Otherwise, i < n1:\n      else {\n        // 1. Let d be the code unit in S at index i+1.\n        var d = string.charCodeAt(i + 1);\n\n        // 2. If 0xDC00  d  0xDFFF, then:\n        if (0xDC00 <= d && d <= 0xDFFF) {\n          // 1. Let a be c & 0x3FF.\n          var a = c & 0x3FF;\n\n          // 2. Let b be d & 0x3FF.\n          var b = d & 0x3FF;\n\n          // 3. Append to U the Unicode character with code point\n          // 2^16+2^10*a+b.\n          u.push(0x10000 + (a << 10) + b);\n\n          // 4. Set i to i+1.\n          i += 1;\n        }\n\n        // 3. Otherwise, d < 0xDC00 or d > 0xDFFF. Append to U a\n        // U+FFFD REPLACEMENT CHARACTER.\n        else  {\n          u.push(0xFFFD);\n        }\n      }\n    }\n\n    // 3. Set i to i+1.\n    i += 1;\n  }\n\n  // 6. Return U.\n  return u;\n}\n\n/**\n * @param {!Array.<number>} code_points Array of code points.\n * @return {string} string String of UTF-16 code units.\n */\nfunction codePointsToString(code_points) {\n  var s = '';\n  for (var i = 0; i < code_points.length; ++i) {\n    var cp = code_points[i];\n    if (cp <= 0xFFFF) {\n      s += String.fromCharCode(cp);\n    } else {\n      cp -= 0x10000;\n      s += String.fromCharCode((cp >> 10) + 0xD800,\n                               (cp & 0x3FF) + 0xDC00);\n    }\n  }\n  return s;\n}\n\n\n//\n// Implementation of Encoding specification\n// https://encoding.spec.whatwg.org/\n//\n\n//\n// 3. Terminology\n//\n\n/**\n * End-of-stream is a special token that signifies no more tokens\n * are in the stream.\n * @const\n */ var end_of_stream = -1;\n\n/**\n * A stream represents an ordered sequence of tokens.\n *\n * @constructor\n * @param {!(Array.<number>|Uint8Array)} tokens Array of tokens that provide the\n * stream.\n */\nfunction Stream(tokens) {\n  /** @type {!Array.<number>} */\n  this.tokens = [].slice.call(tokens);\n}\n\nStream.prototype = {\n  /**\n   * @return {boolean} True if end-of-stream has been hit.\n   */\n  endOfStream: function() {\n    return !this.tokens.length;\n  },\n\n  /**\n   * When a token is read from a stream, the first token in the\n   * stream must be returned and subsequently removed, and\n   * end-of-stream must be returned otherwise.\n   *\n   * @return {number} Get the next token from the stream, or\n   * end_of_stream.\n   */\n   read: function() {\n    if (!this.tokens.length)\n      return end_of_stream;\n     return this.tokens.shift();\n   },\n\n  /**\n   * When one or more tokens are prepended to a stream, those tokens\n   * must be inserted, in given order, before the first token in the\n   * stream.\n   *\n   * @param {(number|!Array.<number>)} token The token(s) to prepend to the stream.\n   */\n  prepend: function(token) {\n    if (Array.isArray(token)) {\n      var tokens = /**@type {!Array.<number>}*/(token);\n      while (tokens.length)\n        this.tokens.unshift(tokens.pop());\n    } else {\n      this.tokens.unshift(token);\n    }\n  },\n\n  /**\n   * When one or more tokens are pushed to a stream, those tokens\n   * must be inserted, in given order, after the last token in the\n   * stream.\n   *\n   * @param {(number|!Array.<number>)} token The tokens(s) to prepend to the stream.\n   */\n  push: function(token) {\n    if (Array.isArray(token)) {\n      var tokens = /**@type {!Array.<number>}*/(token);\n      while (tokens.length)\n        this.tokens.push(tokens.shift());\n    } else {\n      this.tokens.push(token);\n    }\n  }\n};\n\n//\n// 4. Encodings\n//\n\n// 4.1 Encoders and decoders\n\n/** @const */\nvar finished = -1;\n\n/**\n * @param {boolean} fatal If true, decoding errors raise an exception.\n * @param {number=} opt_code_point Override the standard fallback code point.\n * @return {number} The code point to insert on a decoding error.\n */\nfunction decoderError(fatal, opt_code_point) {\n  if (fatal)\n    throw TypeError('Decoder error');\n  return opt_code_point || 0xFFFD;\n}\n\n//\n// 7. API\n//\n\n/** @const */ var DEFAULT_ENCODING = 'utf-8';\n\n// 7.1 Interface TextDecoder\n\n/**\n * @constructor\n * @param {string=} encoding The label of the encoding;\n *     defaults to 'utf-8'.\n * @param {Object=} options\n */\nfunction TextDecoder(encoding, options) {\n  if (!(this instanceof TextDecoder)) {\n    return new TextDecoder(encoding, options);\n  }\n  encoding = encoding !== undefined ? String(encoding).toLowerCase() : DEFAULT_ENCODING;\n  if (encoding !== DEFAULT_ENCODING) {\n    throw new Error('Encoding not supported. Only utf-8 is supported');\n  }\n  options = ToDictionary(options);\n\n  /** @private @type {boolean} */\n  this._streaming = false;\n  /** @private @type {boolean} */\n  this._BOMseen = false;\n  /** @private @type {?Decoder} */\n  this._decoder = null;\n  /** @private @type {boolean} */\n  this._fatal = Boolean(options['fatal']);\n  /** @private @type {boolean} */\n  this._ignoreBOM = Boolean(options['ignoreBOM']);\n\n  Object.defineProperty(this, 'encoding', {value: 'utf-8'});\n  Object.defineProperty(this, 'fatal', {value: this._fatal});\n  Object.defineProperty(this, 'ignoreBOM', {value: this._ignoreBOM});\n}\n\nTextDecoder.prototype = {\n  /**\n   * @param {ArrayBufferView=} input The buffer of bytes to decode.\n   * @param {Object=} options\n   * @return {string} The decoded string.\n   */\n  decode: function decode(input, options) {\n    var bytes;\n    if (typeof input === 'object' && input instanceof ArrayBuffer) {\n      bytes = new Uint8Array(input);\n    } else if (typeof input === 'object' && 'buffer' in input &&\n               input.buffer instanceof ArrayBuffer) {\n      bytes = new Uint8Array(input.buffer,\n                             input.byteOffset,\n                             input.byteLength);\n    } else {\n      bytes = new Uint8Array(0);\n    }\n\n    options = ToDictionary(options);\n\n    if (!this._streaming) {\n      this._decoder = new UTF8Decoder({fatal: this._fatal});\n      this._BOMseen = false;\n    }\n    this._streaming = Boolean(options['stream']);\n\n    var input_stream = new Stream(bytes);\n\n    var code_points = [];\n\n    /** @type {?(number|!Array.<number>)} */\n    var result;\n\n    while (!input_stream.endOfStream()) {\n      result = this._decoder.handler(input_stream, input_stream.read());\n      if (result === finished)\n        break;\n      if (result === null)\n        continue;\n      if (Array.isArray(result))\n        code_points.push.apply(code_points, /**@type {!Array.<number>}*/(result));\n      else\n        code_points.push(result);\n    }\n    if (!this._streaming) {\n      do {\n        result = this._decoder.handler(input_stream, input_stream.read());\n        if (result === finished)\n          break;\n        if (result === null)\n          continue;\n        if (Array.isArray(result))\n          code_points.push.apply(code_points, /**@type {!Array.<number>}*/(result));\n        else\n          code_points.push(result);\n      } while (!input_stream.endOfStream());\n      this._decoder = null;\n    }\n\n    if (code_points.length) {\n      // If encoding is one of utf-8, utf-16be, and utf-16le, and\n      // ignore BOM flag and BOM seen flag are unset, run these\n      // subsubsteps:\n      if (['utf-8'].indexOf(this.encoding) !== -1 &&\n          !this._ignoreBOM && !this._BOMseen) {\n        // If token is U+FEFF, set BOM seen flag.\n        if (code_points[0] === 0xFEFF) {\n          this._BOMseen = true;\n          code_points.shift();\n        } else {\n          // Otherwise, if token is not end-of-stream, set BOM seen\n          // flag and append token to output.\n          this._BOMseen = true;\n        }\n      }\n    }\n\n    return codePointsToString(code_points);\n  }\n};\n\n// 7.2 Interface TextEncoder\n\n/**\n * @constructor\n * @param {string=} encoding The label of the encoding;\n *     defaults to 'utf-8'.\n * @param {Object=} options\n */\nfunction TextEncoder(encoding, options) {\n  if (!(this instanceof TextEncoder))\n    return new TextEncoder(encoding, options);\n  encoding = encoding !== undefined ? String(encoding).toLowerCase() : DEFAULT_ENCODING;\n  if (encoding !== DEFAULT_ENCODING) {\n    throw new Error('Encoding not supported. Only utf-8 is supported');\n  }\n  options = ToDictionary(options);\n\n  /** @private @type {boolean} */\n  this._streaming = false;\n  /** @private @type {?Encoder} */\n  this._encoder = null;\n  /** @private @type {{fatal: boolean}} */\n  this._options = {fatal: Boolean(options['fatal'])};\n\n  Object.defineProperty(this, 'encoding', {value: 'utf-8'});\n}\n\nTextEncoder.prototype = {\n  /**\n   * @param {string=} opt_string The string to encode.\n   * @param {Object=} options\n   * @return {Uint8Array} Encoded bytes, as a Uint8Array.\n   */\n  encode: function encode(opt_string, options) {\n    opt_string = opt_string ? String(opt_string) : '';\n    options = ToDictionary(options);\n\n    // NOTE: This option is nonstandard. None of the encodings\n    // permitted for encoding (i.e. UTF-8, UTF-16) are stateful,\n    // so streaming is not necessary.\n    if (!this._streaming)\n      this._encoder = new UTF8Encoder(this._options);\n    this._streaming = Boolean(options['stream']);\n\n    var bytes = [];\n    var input_stream = new Stream(stringToCodePoints(opt_string));\n    /** @type {?(number|!Array.<number>)} */\n    var result;\n    while (!input_stream.endOfStream()) {\n      result = this._encoder.handler(input_stream, input_stream.read());\n      if (result === finished)\n        break;\n      if (Array.isArray(result))\n        bytes.push.apply(bytes, /**@type {!Array.<number>}*/(result));\n      else\n        bytes.push(result);\n    }\n    if (!this._streaming) {\n      while (true) {\n        result = this._encoder.handler(input_stream, input_stream.read());\n        if (result === finished)\n          break;\n        if (Array.isArray(result))\n          bytes.push.apply(bytes, /**@type {!Array.<number>}*/(result));\n        else\n          bytes.push(result);\n      }\n      this._encoder = null;\n    }\n    return new Uint8Array(bytes);\n  }\n};\n\n//\n// 8. The encoding\n//\n\n// 8.1 utf-8\n\n/**\n * @constructor\n * @implements {Decoder}\n * @param {{fatal: boolean}} options\n */\nfunction UTF8Decoder(options) {\n  var fatal = options.fatal;\n\n  // utf-8's decoder's has an associated utf-8 code point, utf-8\n  // bytes seen, and utf-8 bytes needed (all initially 0), a utf-8\n  // lower boundary (initially 0x80), and a utf-8 upper boundary\n  // (initially 0xBF).\n  var /** @type {number} */ utf8_code_point = 0,\n      /** @type {number} */ utf8_bytes_seen = 0,\n      /** @type {number} */ utf8_bytes_needed = 0,\n      /** @type {number} */ utf8_lower_boundary = 0x80,\n      /** @type {number} */ utf8_upper_boundary = 0xBF;\n\n  /**\n   * @param {Stream} stream The stream of bytes being decoded.\n   * @param {number} bite The next byte read from the stream.\n   * @return {?(number|!Array.<number>)} The next code point(s)\n   *     decoded, or null if not enough data exists in the input\n   *     stream to decode a complete code point.\n   */\n  this.handler = function(stream, bite) {\n    // 1. If byte is end-of-stream and utf-8 bytes needed is not 0,\n    // set utf-8 bytes needed to 0 and return error.\n    if (bite === end_of_stream && utf8_bytes_needed !== 0) {\n      utf8_bytes_needed = 0;\n      return decoderError(fatal);\n    }\n\n    // 2. If byte is end-of-stream, return finished.\n    if (bite === end_of_stream)\n      return finished;\n\n    // 3. If utf-8 bytes needed is 0, based on byte:\n    if (utf8_bytes_needed === 0) {\n\n      // 0x00 to 0x7F\n      if (inRange(bite, 0x00, 0x7F)) {\n        // Return a code point whose value is byte.\n        return bite;\n      }\n\n      // 0xC2 to 0xDF\n      if (inRange(bite, 0xC2, 0xDF)) {\n        // Set utf-8 bytes needed to 1 and utf-8 code point to byte\n        //  0xC0.\n        utf8_bytes_needed = 1;\n        utf8_code_point = bite - 0xC0;\n      }\n\n      // 0xE0 to 0xEF\n      else if (inRange(bite, 0xE0, 0xEF)) {\n        // 1. If byte is 0xE0, set utf-8 lower boundary to 0xA0.\n        if (bite === 0xE0)\n          utf8_lower_boundary = 0xA0;\n        // 2. If byte is 0xED, set utf-8 upper boundary to 0x9F.\n        if (bite === 0xED)\n          utf8_upper_boundary = 0x9F;\n        // 3. Set utf-8 bytes needed to 2 and utf-8 code point to\n        // byte  0xE0.\n        utf8_bytes_needed = 2;\n        utf8_code_point = bite - 0xE0;\n      }\n\n      // 0xF0 to 0xF4\n      else if (inRange(bite, 0xF0, 0xF4)) {\n        // 1. If byte is 0xF0, set utf-8 lower boundary to 0x90.\n        if (bite === 0xF0)\n          utf8_lower_boundary = 0x90;\n        // 2. If byte is 0xF4, set utf-8 upper boundary to 0x8F.\n        if (bite === 0xF4)\n          utf8_upper_boundary = 0x8F;\n        // 3. Set utf-8 bytes needed to 3 and utf-8 code point to\n        // byte  0xF0.\n        utf8_bytes_needed = 3;\n        utf8_code_point = bite - 0xF0;\n      }\n\n      // Otherwise\n      else {\n        // Return error.\n        return decoderError(fatal);\n      }\n\n      // Then (byte is in the range 0xC2 to 0xF4) set utf-8 code\n      // point to utf-8 code point << (6  utf-8 bytes needed) and\n      // return continue.\n      utf8_code_point = utf8_code_point << (6 * utf8_bytes_needed);\n      return null;\n    }\n\n    // 4. If byte is not in the range utf-8 lower boundary to utf-8\n    // upper boundary, run these substeps:\n    if (!inRange(bite, utf8_lower_boundary, utf8_upper_boundary)) {\n\n      // 1. Set utf-8 code point, utf-8 bytes needed, and utf-8\n      // bytes seen to 0, set utf-8 lower boundary to 0x80, and set\n      // utf-8 upper boundary to 0xBF.\n      utf8_code_point = utf8_bytes_needed = utf8_bytes_seen = 0;\n      utf8_lower_boundary = 0x80;\n      utf8_upper_boundary = 0xBF;\n\n      // 2. Prepend byte to stream.\n      stream.prepend(bite);\n\n      // 3. Return error.\n      return decoderError(fatal);\n    }\n\n    // 5. Set utf-8 lower boundary to 0x80 and utf-8 upper boundary\n    // to 0xBF.\n    utf8_lower_boundary = 0x80;\n    utf8_upper_boundary = 0xBF;\n\n    // 6. Increase utf-8 bytes seen by one and set utf-8 code point\n    // to utf-8 code point + (byte  0x80) << (6  (utf-8 bytes\n    // needed  utf-8 bytes seen)).\n    utf8_bytes_seen += 1;\n    utf8_code_point += (bite - 0x80) << (6 * (utf8_bytes_needed - utf8_bytes_seen));\n\n    // 7. If utf-8 bytes seen is not equal to utf-8 bytes needed,\n    // continue.\n    if (utf8_bytes_seen !== utf8_bytes_needed)\n      return null;\n\n    // 8. Let code point be utf-8 code point.\n    var code_point = utf8_code_point;\n\n    // 9. Set utf-8 code point, utf-8 bytes needed, and utf-8 bytes\n    // seen to 0.\n    utf8_code_point = utf8_bytes_needed = utf8_bytes_seen = 0;\n\n    // 10. Return a code point whose value is code point.\n    return code_point;\n  };\n}\n\n/**\n * @constructor\n * @implements {Encoder}\n * @param {{fatal: boolean}} options\n */\nfunction UTF8Encoder(options) {\n  var fatal = options.fatal;\n  /**\n   * @param {Stream} stream Input stream.\n   * @param {number} code_point Next code point read from the stream.\n   * @return {(number|!Array.<number>)} Byte(s) to emit.\n   */\n  this.handler = function(stream, code_point) {\n    // 1. If code point is end-of-stream, return finished.\n    if (code_point === end_of_stream)\n      return finished;\n\n    // 2. If code point is in the range U+0000 to U+007F, return a\n    // byte whose value is code point.\n    if (inRange(code_point, 0x0000, 0x007f))\n      return code_point;\n\n    // 3. Set count and offset based on the range code point is in:\n    var count, offset;\n    // U+0080 to U+07FF:    1 and 0xC0\n    if (inRange(code_point, 0x0080, 0x07FF)) {\n      count = 1;\n      offset = 0xC0;\n    }\n    // U+0800 to U+FFFF:    2 and 0xE0\n    else if (inRange(code_point, 0x0800, 0xFFFF)) {\n      count = 2;\n      offset = 0xE0;\n    }\n    // U+10000 to U+10FFFF: 3 and 0xF0\n    else if (inRange(code_point, 0x10000, 0x10FFFF)) {\n      count = 3;\n      offset = 0xF0;\n    }\n\n    // 4.Let bytes be a byte sequence whose first byte is (code\n    // point >> (6  count)) + offset.\n    var bytes = [(code_point >> (6 * count)) + offset];\n\n    // 5. Run these substeps while count is greater than 0:\n    while (count > 0) {\n\n      // 1. Set temp to code point >> (6  (count  1)).\n      var temp = code_point >> (6 * (count - 1));\n\n      // 2. Append to bytes 0x80 | (temp & 0x3F).\n      bytes.push(0x80 | (temp & 0x3F));\n\n      // 3. Decrease count by one.\n      count -= 1;\n    }\n\n    // 6. Return bytes bytes, in order.\n    return bytes;\n  };\n}\n\nexports.TextEncoder = TextEncoder;\nexports.TextDecoder = TextDecoder;","import { DataFrame, FieldType, Field, Vector } from '../types';\r\nimport {\r\n  Table,\r\n  ArrowType,\r\n  Builder,\r\n  Vector as ArrowVector,\r\n  Float64,\r\n  DataType,\r\n  Utf8,\r\n  TimestampMillisecond,\r\n  Bool,\r\n  Column,\r\n} from 'apache-arrow';\r\n\r\nexport interface ArrowDataFrame extends DataFrame {\r\n  table: Table;\r\n}\r\n\r\nexport function base64StringToArrowTable(text: string): Table {\r\n  const b64 = atob(text);\r\n  const arr = Uint8Array.from(b64, c => {\r\n    return c.charCodeAt(0);\r\n  });\r\n  return Table.from(arr);\r\n}\r\n\r\nfunction valueOrUndefined(val?: string) {\r\n  return val ? val : undefined;\r\n}\r\n\r\nfunction parseOptionalMeta(str?: string): any {\r\n  if (str && str.length && str !== '{}') {\r\n    try {\r\n      return JSON.parse(str);\r\n    } catch (err) {\r\n      console.warn('Error reading JSON from arrow metadata: ', str);\r\n    }\r\n  }\r\n  return undefined;\r\n}\r\n\r\nexport function arrowTableToDataFrame(table: Table): ArrowDataFrame {\r\n  const fields: Field[] = [];\r\n\r\n  for (let i = 0; i < table.numCols; i++) {\r\n    const col = table.getColumnAt(i);\r\n    if (col) {\r\n      const schema = table.schema.fields[i];\r\n      let type = FieldType.other;\r\n      const values: Vector<any> = col;\r\n      switch ((schema.typeId as unknown) as ArrowType) {\r\n        case ArrowType.Decimal:\r\n        case ArrowType.Int:\r\n        case ArrowType.FloatingPoint: {\r\n          type = FieldType.number;\r\n          break;\r\n        }\r\n        case ArrowType.Bool: {\r\n          type = FieldType.boolean;\r\n          break;\r\n        }\r\n        case ArrowType.Timestamp: {\r\n          type = FieldType.time;\r\n          break;\r\n        }\r\n        case ArrowType.Utf8: {\r\n          type = FieldType.string;\r\n          break;\r\n        }\r\n        default:\r\n          console.log('UNKNOWN Type:', schema);\r\n      }\r\n\r\n      fields.push({\r\n        name: col.name,\r\n        type,\r\n        values,\r\n        config: parseOptionalMeta(col.metadata.get('config')) || {},\r\n        labels: parseOptionalMeta(col.metadata.get('labels')),\r\n      });\r\n    }\r\n  }\r\n  const meta = table.schema.metadata;\r\n  return {\r\n    fields,\r\n    length: table.length,\r\n    refId: valueOrUndefined(meta.get('refId')),\r\n    name: valueOrUndefined(meta.get('name')),\r\n    meta: parseOptionalMeta(meta.get('meta')),\r\n    table,\r\n  };\r\n}\r\n\r\nfunction toArrowVector(field: Field): ArrowVector {\r\n  // OR: Float64Vector.from([1, 2, 3]));\r\n\r\n  let type: DataType;\r\n  if (field.type === FieldType.number) {\r\n    type = new Float64();\r\n  } else if (field.type === FieldType.time) {\r\n    type = new TimestampMillisecond();\r\n  } else if (field.type === FieldType.boolean) {\r\n    type = new Bool();\r\n  } else if (field.type === FieldType.string) {\r\n    type = new Utf8();\r\n  } else {\r\n    type = new Utf8();\r\n  }\r\n  const builder = Builder.new({ type, nullValues: [null] });\r\n  field.values.toArray().forEach(builder.append.bind(builder));\r\n  return builder.finish().toVector();\r\n}\r\n\r\nexport function grafanaDataFrameToArrowTable(data: DataFrame): Table {\r\n  const table = Table.new(\r\n    data.fields.map(field => {\r\n      const column = Column.new(field.name, toArrowVector(field));\r\n      if (field.labels) {\r\n        column.metadata.set('labels', JSON.stringify(field.labels));\r\n      }\r\n      if (field.config) {\r\n        column.metadata.set('config', JSON.stringify(field.config));\r\n      }\r\n      return column;\r\n    })\r\n  );\r\n  const metadata = table.schema.metadata;\r\n  if (data.name) {\r\n    metadata.set('name', data.name);\r\n  }\r\n  if (data.refId) {\r\n    metadata.set('refId', data.refId);\r\n  }\r\n  if (data.meta) {\r\n    metadata.set('meta', JSON.stringify(data.meta));\r\n  }\r\n  return table;\r\n}\r\n\r\nexport function resultsToDataFrames(rsp: any): DataFrame[] {\r\n  const frames: DataFrame[] = [];\r\n  for (const res of Object.values(rsp.results)) {\r\n    for (const b of (res as any).dataframes) {\r\n      const t = base64StringToArrowTable(b as string);\r\n      frames.push(arrowTableToDataFrame(t));\r\n    }\r\n  }\r\n  return frames;\r\n}\r\n"],"mappings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aA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACtPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACziBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACh4EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChWA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACnHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACpRA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1eA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACllBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACjaA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC3HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACvIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC3IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACpXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACz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vBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACnPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AChCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACzHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC5IA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACxQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AC7JA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;AClMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACvFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACnIA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;ACrtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;ACjoBA;AACA;AAiBA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AACA;;AACA;AAAA;;AACA;AAAA;AACA;AACA;AACA;;;;;;;;;AACA;;;;;;;;;AACA;AACA;;;;;A","sourceRoot":""}